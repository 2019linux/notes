# Linux中断管理

## 一：概念

### 前沿

​	

对大部分外设中断比轮询效率高，但比如网卡驱动采取轮询比中断效率高。

这里重点关注ARM+Linux组合下中断管理，从底层硬件GIC+CPU，到Linux内核通用部分处理，再到GIC驱动以及中断注册，最后是中断下半部软中断、tasklet、workqueue，包括线程化部分。

按照从硬件到软件，软件从底层到上层的框架去介绍。

### 1.思考问题

- 发生硬件中断后，ARM处理器做了哪些事情？

> ​	SoC内部中断控制器会感知到中断信号，中断控制器里的仲裁单元(Distributor)会在众多CUP核心中选择一个，并把该中断分发给CPU核心。
>
> GIC控制器和CPU核心之间通过一个nIRQ信号来通知CPU。
>
> CPU核心感知到中断发生之后，硬件会自动做如下一些事情：
>
> - 保存中断发生时CPSR寄存器的内容到SPSR_irq寄存器中
>
> - 修改CPSR寄存器，让CPU进入处理器模式中的IRQ模式，即CPSR寄存器中的M域设置为IRQ Mode
>
> - 硬件自动关闭中断IRQ或FIQ，即CPSR中的IRQ位或FIQ位置1
>
> - 保存返回地址到LR_irq寄存器中
>
> - 硬件自动跳转到中断向量表的IRQ向量中
>
>   

- 硬件中断号和Linux内核的IRQ中断号是如何映射的？

> ​	硬件中断号的映射是在系统启动过程中接卸DTS，然后经由[irq_domain_alloc_irqs](http://www.cnblogs.com/arnoldlu/p/8659981.html#irq_domain_alloc_irqs)()完成映射到Linux中断号。
>
> 中断发生后，根据硬件中断号经由[irq_find_mapping](http://www.cnblogs.com/arnoldlu/p/8659981.html#irq_find_mapping)()找到Linux软中断号。

- 一个硬件中断发生后，Linux内核如何响应并处理该中断？

  > 一个硬件发生后，Linux软件的起点是中断向量表[vector_irq](http://www.cnblogs.com/arnoldlu/p/8659981.html#vector_irq)。
  >
  > vector_irq根据中断发生时状态决定是进入用户空间__irq_svc还是内核空间[__irq_svc](http://www.cnblogs.com/arnoldlu/p/8659981.html#irq_svc)。
  >
  > 两者主要工作都交给[irq_handler](http://www.cnblogs.com/arnoldlu/p/8659981.html#irq_handler)处理，irq_handler调用中断控制器处理函数[gic_handle_irq](http://www.cnblogs.com/arnoldlu/p/8659981.html#gic_handle_irq)()。
  >
  > gic_handle_irq()根据读取到的硬件中断号转换成Linux中断号，然后进行特定中断处理。
  >
  > 从中断返回时，还需要实现如下两个操作：
  >
  > - ​		从SPSR_irq寄存器中恢复数据到CPSR中
  > - ​		从LR_irq中回复内容到PC中，从而返回到中断点的下一个指令处执行。

- 为什么说中断上下文不能执行睡眠操作？

  > 所谓的睡眠，就是调用schedule()让出CPU，调度器选择另外一个进程继续执行，这个过程涉及进程栈空间的切换。
  >
  > 如果中断上下文中调用schedule()，此时获取的struct thread_info数据结构是发生中断是该进程栈信息，而不是中断上下文调用schedule()时任何信息。
  >
  > 这就导致再也无法返回中断上下文中调用schedule()的地方。
  >
  >  
  >
  > 另一个原因是，中断上下文处于关中断中，需要发送一个EOI通知GIC中断处理结束，GIC和CPU Interface才会进入下一次中断处理。如果中途schedule()，那么整个系统的中断都会被屏蔽掉。

- 软中断的回调函数执行过程中是否允许响应本地中断？

  > 软中断回调函数执行处于开中断环境下，所以允许响应本地中断。
  >
  > 具体参考[__do_softirq](http://www.cnblogs.com/arnoldlu/p/8659986.html#do_softirq__)()，在执行h->action()前打开本地中断，完成后关闭中断。

- 同一类型的软中断是否允许多个CPU并行执行？

  > 同一类型的软中断可以在多个CUP并发执行，因为软中断处理函数是可重入的，自身对数据进行了保护。

- 软中断上下文包括哪几种情况？

  > 中断上下文包括硬中断上下文和软中断上下文，当然也包括NMI上下文。
  >
  > 软中断上下文包括三部分：
  >
  > 一是在下半部执行的软中断处理包括tasklet，调用过程是irq_exit()->invoke_softirq()；
  >
  > 二是ksoftirqd内核线程执行的软中断，比如强制中断线程化force_threads，或者软中断执行时间太长仅为唤醒ksoftirqd内核线程；
  >
  > 三是进程上下文中调用local_bh_enable()时也会去执行软中断处理，调用过程是local_bh_enable()->do_softirq()。
  >
  > 一属于传统意义的中断上下文，二、三运行在进程上下文中，但三者统称为软中断上下文。

- 软中断上下文和进程上下文哪个优先级高？为什么？

  > 软中断上下文优先级高于进程上下文，因此软中断包括tasklet总是抢占进程的运行。参见[irq_exit](http://www.cnblogs.com/arnoldlu/p/8659981.html#irq_exit)()退出中断时优先执行softirq。
  >
  > 比如当进程A在运行时发生中断，在中断返回时如果不处于中断上下文且有pending的softirq时，优先执行软中断包括tasklet。
  >
  > 然后采取检查是否有高优先级任务需要签章中断点的进程。
  >
  >  
  >
  > 这样导致的危害是：如果执行软中断或者tasklet事件过长，那么高优先级任务就长时间得不到运行，严重影响系统的实时性。
  >
  > 这也是RT补丁强制将softirq处理函数线程化的原因。

- 是否允许同一个tasklet在多个CPU上并行执行？

  >  不允许同一个tasklet同时在多个CPU并发执行，taskelt必须固定在一个CPU上串行执行。
  >
  > 因为tasket被挂入到per-cpu的taskelt_vec中，并且设置TASKLET_STATE_SCHED标志位，那么只能由该CPU来执行。
  >
  > 直到执行完毕并清除了TASKLET_STATE_SCHED后，其它CPU才有机会

- workqueue试运行在中断上下文，还是进程上下文？其回调函数允许睡眠吗？

- 旧版本(Linux 2.6.25)的workqueue机制在实际过程中遇到了哪些问题和挑战？

- CMWQ机制如何动态管理工作线程池的线程呢？

- 如果有多个work挂入一个工作线程中执行，当某个work的回调函数执行了阻塞操作，那么剩下的work该怎么办？

## 二：Linux中断管理机制

### 		1.ARM中断控制器

#### 1.1 ARM支持中断类型

ARM GIC-v2支持三种类型的中断：

SGI：软件触发中断(Software Generated Interrupt)，通常用于多核间通讯，最多支持16个SGI中断，硬件中断号从ID0~ID15。SGI通常在Linux内核中被用作IPI中断(inter-processor interrupts)，并会送达到系统指定的CPU上。

PPI：私有外设中断(Private Peripheral Interrupt)，是每个CPU私有的中断。最多支持16个PPI中断，硬件中断号从ID16~ID31。PPI通常会送达到指定的CPU上，应用场景有CPU本地时钟。

SPI：公用外设中断(Shared Peripheral Interrupt)，最多可以支持988个外设中断，硬件中断号从ID32~ID1019。

#### 1.2 GIC检测中断流程

GIC主要由两部分组成，分别是仲裁单元(Distributor)和CPU接口模块。

GIC仲裁单元为每一个中断维护一个状态机，分别是：inactive、pending、active and pending、active。

下面是来自IHI0048B GIC-V2规格书3.2.4 Interrupt handling state machine截图：

![1563860743041](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1563860743041.png)

GIC检测中断流程如下：

(1) 当GIC检测到一个中断发生时，会将该中断标记为pending状态(**A1**)。

(2) 对处于pending状态的中断，仲裁单元回确定目标CPU，将中断请求发送到这个CPU上。

(3) 对于每个CPU，仲裁单元会从众多pending状态的中断中选择一个优先级最高的中断，发送到目标CPU的CPU Interface模块上。

(4) CPU Interface会决定这个中断是否可以发送给CPU。如果该终端优先级满足要求，GIC会发生一个中断信号给该CPU。

(5) 当一个CPU进入中断异常后，会去读取GICC_IAR寄存器来响应该中断(一般是Linux内核的中断处理程序来读寄存器)。寄存器会返回硬件中断号(hardware interrupt ID)，对于SGI中断来说是返回源CPU的ID。

​     当GIC感知到软件读取了该寄存器后，又分为如下情况：

​     \* 如果该中断源是pending状态，那么转改将变成active。**(C)**    

​     \* 如果该中断又重新产生，那么pending状态变成active and pending。**(D)**

​     \* 如果该中断是active状态，现在变成active and pending。**(A2)**

(6) 当处理器完成中断服务，必须发送一个完成信号EOI(End Of Interrupt)给GIC控制器。软件写GICC_EOIR寄存器，状态变成inactive。**(E1)**

补充：

(7) 对于level triggered类型中断来说，当触发电平消失，状态从active and pending变成active。**(B2)**

常用路径是A1->D->B2->E1。

##### 1.2.1 GIC中断抢占

GIC中断控制器支持中断优先级抢占，一个高优先级中断可以抢占一个低优先级且处于active状态的中断，即GIC仲裁单元会记录和比较当前优先级最高的pending状态，然后去抢占当前中断，并且发送这个最高优先级的中断请求给CPU，CPU应答了高优先级中断，暂停低优先级中断服务，进而去处理高优先级中断。

GIC会将pending状态优先级最高的中断请求发送给CPU。

##### 1.2.2 Linux对中断抢占处理

从GIC角度看，GIC会发送高优先级中断请求给CPU。

但是目前CPU处于关中断状态，需要等低优先级中断处理完毕，直到发送EOI给GIC。

然后CPU才会响应pending状态中优先级最高的中断进行处理。

所以Linux下：

1.高优先级中断无法抢占正在执行的低优先级中断。

2.同处于pending状态的中断，优先响应高优先级中断进行处理。

#### 1.3 GIC中断时序

![1563861402200](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1563861402200.png)

借助GIC-400 Figure B-2 Signaling physical interrupts理解GIC内部工作原理。

M和N都是SPI类型的外设中断，且通过FIQ来处理，高电平触发，N的优先级比M高，他们的目标CPU相同。

(1) T1时刻：GIC的总裁单元检测到中断M的电平变化。

(2) T2时刻：仲裁单元设置中断M的状态为pending。

(3) T17时刻：CPU Interface模块会拉低nFIQCPU[n]信号。在中断M的状态变成pending后，大概需要15个时钟周期后会拉低nFIQCPU[n]信号来向CPU报告中断请求(assertion)。仲裁单元需要这些时间来计算哪个是pending状态下优先级最高的中断。

(4) T42时刻：仲裁单元检测到另外一个优先级更高的中断N。

(5) T43时刻：仲裁单元用中断N替换中断M为当前pending状态下优先级最高的中断，并设置中断N为pending状态。

(6) T58时刻：经过tph个时钟后，CPU Interface拉低你FIOCPU[n]信号来通知CPU。因为此信号在T17时刻已经被拉低，CPU Interface模块会更新GICC_IAR寄存器的Interrupt ID域，该域的值变成中断N的硬件中断号。

(7) T61~T131时刻：Linux对中断N的服务程序--------------------------------------------------------------中断服务程序处理段，从GICC_IAR开始到GICC_EOIR结束。

　　T61时刻：CPU(Linux中断服务例程)读取GICC_IAR寄存器，即软件响应了中断N。这时仲裁单元把中断N的状态从pending变成active and pending。[读取GICC_IAR](https://www.cnblogs.com/arnoldlu/p/8659981.html#read_gicc_iar)

　　T64时刻：在中断N被Linux相应3个时钟内，CPU Interface模块完成对nFIQCPU[n]信号的deasserts，即拉高nFIQCPU[n]信号。

　　T126时刻：外设也deassert了该中断N。

　　T128时刻：仲裁单元移出了中断N的pending状态。

　　T131时刻：Linux服务程序把中断N的硬件ID号写入GICC_EOIR寄存器来完成中断N的全部处理过程。[写GICC_EOIR](https://www.cnblogs.com/arnoldlu/p/8659981.html#write_gicc_eoi)

(8) T146时刻：在向GICC_EOIR寄存器写入中断N中断号后的tph个时钟后，仲裁单元会选择下一个最高优先级中断，即中断M，发送中断请求给CPU Interface模块。CPU Interface会拉低nFIQCPU[n]信号来向CPU报告外设M的中断请求。

(9) T211时刻：Linux中断服务程序读取GICC_IAR寄存器来响应中断，仲裁单元设置中断M的状态为active and pending。

(10) T214时刻：在CPU响应中断后的3个时钟内，CPU Interface模块拉高nFIOCPU[n]信号来完成deassert动作。

那么GICC_IAR和GICC_EOIR分别在Linux什么地方触发的呢？

#### 1.4 Cortex A15 A7实例

### 2. 硬件中断号和Linux中断号的映射

#### 2.1 硬件中断号：一个串口中断实例

#### 2.2 中断控制器初始化

DTS中GIC定义于arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts：

```c
gic: interrupt-controller@2c001000 {
        compatible = "arm,cortex-a15-gic", "arm,cortex-a9-gic";------------此设备的标识符是"arm,cortex-a15-gic"
        #interrupt-cells = <3>;
        #address-cells = <0>;
        interrupt-controller;--------------------------------------表示此设备是一个中断控制器
        reg = <0 0x2c001000 0 0x1000>,
              <0 0x2c002000 0 0x1000>,
              <0 0x2c004000 0 0x2000>,
              <0 0x2c006000 0 0x2000>;
        interrupts = <1 9 0xf04>;
    };
```

struct irq_domain用于描述一个中断控制器。

GIC中断控制器在初始化时解析DTS信息中定义了几个GIC控制器，每个GIC控制器注册一个struct irq_domain数据结构。

```c
struct irq_domain {
    struct list_head link;-------------------------用于将irq_domain连接到全局链表irq_domain_list中。
    const char *name;------------------------------中断控制器名称
    const struct irq_domain_ops *ops;--------------irq domain映射操作使用的方法集合
    void *host_data;
    unsigned int flags;

/* Optional data */
struct device_node *of_node;------------------对应中断控制器的device node
struct irq_domain_chip_generic *gc;

#ifdef    CONFIG_IRQ_DOMAIN_HIERARCHY
    struct irq_domain *parent;
#endif

/* reverse map data. The linear map gets appended to the irq_domain */
irq_hw_number_t hwirq_max;--------------------该irq domain支持中断数量的最大值。
unsigned int revmap_direct_max_irq;
unsigned int revmap_size;---------------------线性映射的大小
struct radix_tree_root revmap_tree;-----------Radix Tree映射的根节点
unsigned int linear_revmap[];-----------------线性映射用到的lookup table
}
```

 struct irq_domain_ops定义了irq_domain方法集合，xlate从intspec中解析出硬件中断号和中断类型，intspec[0]和intspec[1]决定中断号，intspec[2]决定中断类型。

```c
struct irq_domain_ops {
    int (*match)(struct irq_domain *d, struct device_node *node);
    int (*map)(struct irq_domain *d, unsigned int virq, irq_hw_number_t hw);
    void (*unmap)(struct irq_domain *d, unsigned int virq);
    int (*xlate)(struct irq_domain *d, struct device_node *node,
             const u32 *intspec, unsigned int intsize,
             unsigned long *out_hwirq, unsigned int *out_type);

#ifdef    CONFIG_IRQ_DOMAIN_HIERARCHY
    /* extended V2 interfaces to support hierarchy irq_domains */
    int (*alloc)(struct irq_domain *d, unsigned int virq,
             unsigned int nr_irqs, void *arg);
    void (*free)(struct irq_domain *d, unsigned int virq,
             unsigned int nr_irqs);
    void (*activate)(struct irq_domain *d, struct irq_data *irq_data);
    void (*deactivate)(struct irq_domain *d, struct irq_data *irq_data);
#endif
};

static const struct irq_domain_ops gic_irq_domain_hierarchy_ops = {
    .xlate = gic_irq_domain_xlate,
    .alloc = gic_irq_domain_alloc,
    .free = irq_domain_free_irqs_top,
};

static int gic_irq_domain_xlate(struct irq_domain *d,
                struct device_node *controller,
                const u32 *intspec, unsigned int intsize,
                unsigned long *out_hwirq, unsigned int *out_type)
{

    /* Get the interrupt number and add 16 to skip over SGIs */
    *out_hwirq = intspec[1] + 16;--------------------------------------首先+16跳过SGI类型中断

/* For SPIs, we need to add 16 more to get the GIC irq ID number */
if (!intspec[0]) {-------------------------------------------------如果是SPI类型中断，还需要+16，跳过PPI类型中断。
    ret = gic_routable_irq_domain_ops->xlate(d, controller,
                         intspec,
                         intsize,
                         out_hwirq,
                         out_type);

    if (IS_ERR_VALUE(ret))
        return ret;
}

*out_type = intspec[2] & IRQ_TYPE_SENSE_MASK;---------------------中断触发类型，包括四种上升沿、下降沿、高电平、低电平。

return ret;

}

static int gic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,
                unsigned int nr_irqs, void *arg)
{
    int i, ret;
    irq_hw_number_t hwirq;
    unsigned int type = IRQ_TYPE_NONE;
    struct of_phandle_args *irq_data = arg;

ret = gic_irq_domain_xlate(domain, irq_data->np, irq_data->args,
               irq_data->args_count, &hwirq, &type);---------------首先根据args翻译出硬件中断号和中断类型。
if (ret)
    return ret;

for (i = 0; i < nr_irqs; i++)
    gic_irq_domain_map(domain, virq + i, hwirq + i);---------------执行软硬件的映射，并且根据中断类型设置struct irq_desc->handle_irq处理函数。

return 0;

}

void irq_domain_free_irqs_top(struct irq_domain *domain, unsigned int virq,
                  unsigned int nr_irqs)
{
    int i;

for (i = 0; i < nr_irqs; i++) {
    irq_set_handler_data(virq + i, NULL);
    irq_set_handler(virq + i, NULL);
}
irq_domain_free_irqs_common(domain, virq, nr_irqs);

}
```

针对SPI类型中断，需要进行+16位移

```c
static int gic_routable_irq_domain_xlate(struct irq_domain *d,
                struct device_node *controller,
                const u32 *intspec, unsigned int intsize,
                unsigned long *out_hwirq,
                unsigned int *out_type)
{
    *out_hwirq += 16;
    return 0;
}
```

 gic_irq_domain_map()入参有struct irq_domain和软硬件中断号，主要分SGI/PPI一组，SPI一组。

主要工作由irq_domain_set_info()处理，irq_domain_set_hwirq_and_chip()通过Linux中断号获取struct irq_data数据结构，设置关联硬件中断号和struct irq_chip gic_chip关联。

__irq_set_handler()设置中断描述符irq_desc->handler_irq回调函数，对SPI类型来说就是handle_fasteoi_irq()。

~~~c
static int gic_irq_domain_map(struct irq_domain *d, unsigned int irq,
                irq_hw_number_t hw)
{
    if (hw < 32) {
        irq_set_percpu_devid(irq);-------------------------------PerCPU类型的中断有自己的特殊flag。
        irq_domain_set_info(d, irq, hw, &gic_chip, d->host_data,
                    handle_percpu_devid_irq, NULL, NULL);
        set_irq_flags(irq, IRQF_VALID | IRQF_NOAUTOEN);
    } else {
        irq_domain_set_info(d, irq, hw, &gic_chip, d->host_data,
                    handle_fasteoi_irq, NULL, NULL);
        set_irq_flags(irq, IRQF_VALID | IRQF_PROBE);

```
    gic_routable_irq_domain_ops->map(d, irq, hw);
}
return 0;
```

}

void irq_domain_set_info(struct irq_domain *domain, unsigned int virq,
             irq_hw_number_t hwirq, struct irq_chip *chip,
             void *chip_data, irq_flow_handler_t handler,
             void *handler_data, const char *handler_name)
{
    irq_domain_set_hwirq_and_chip(domain, virq, hwirq, chip, chip_data);
    __irq_set_handler(virq, handler, 0, handler_name);
    irq_set_handler_data(virq, handler_data);
}

int irq_domain_set_hwirq_and_chip(struct irq_domain *domain, unsigned int virq,
                  irq_hw_number_t hwirq, struct irq_chip *chip,
                  void *chip_data)
{
    struct irq_data *irq_data = irq_domain_get_irq_data(domain, virq);

```
if (!irq_data)
    return -ENOENT;

irq_data->hwirq = hwirq;
irq_data->chip = chip ? chip : &no_irq_chip;
irq_data->chip_data = chip_data;

return 0;
```

}

void
__irq_set_handler(unsigned int irq, irq_flow_handler_t handle, int is_chained,
          const char *name)
{
    unsigned long flags;
    struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, 0);
...
    desc->handle_irq = handle;--------------------irq_desc->handler_irq和name赋值。
    desc->name = name;
...
}
~~~

drivers/irqchip/irq-gic.c定义了"arm,cortex-a15-gic"的处理函数gic_of_init，gic_of_init是GIC控制器的初始化函数。

~~~c
IRQCHIP_DECLARE(cortex_a15_gic, "arm,cortex-a15-gic", gic_of_init);

static int gic_cnt __initdata;

static int __init
gic_of_init(struct device_node *node, struct device_node *parent)
{
...
    gic_init_bases(gic_cnt, -1, dist_base, cpu_base, percpu_offset, node);
    if (!gic_cnt)
        gic_init_physaddr(node);

```
if (parent) {
    irq = irq_of_parse_and_map(node, 0);
    gic_cascade_irq(gic_cnt, irq);
}

if (IS_ENABLED(CONFIG_ARM_GIC_V2M))
    gicv2m_of_init(node, gic_data[gic_cnt].domain);

gic_cnt++;
return 0;
```

}
~~~

 gic_init_bases的gic_nr是GIC控制器的序号，主要调用irq_domain_add_linear()分配并函数注册一个irq_domain。

```
void __init gic_init_bases(unsigned int gic_nr, int irq_start,
               void __iomem *dist_base, void __iomem *cpu_base,
               u32 percpu_offset, struct device_node *node)
{
    irq_hw_number_t hwirq_base;
    struct gic_chip_data *gic;
    int gic_irqs, irq_base, i;
    int nr_routable_irqs;

​```
BUG_ON(gic_nr >= MAX_GIC_NR);---------------------------gic_nr不超过系统规定的MAX_GIC_NR

gic = &gic_data[gic_nr];--------------------------------struct gic_chip_data类型的全局变量gic_data，序号是GIC控制器序号
​```

...
/*
     * Initialize the CPU interface map to all CPUs.
     * It will be refined as each CPU probes its ID.
     */
    for (i = 0; i < NR_GIC_CPU_IF; i++)
        gic_cpu_map[i] = 0xff;

​```
/*
 * Find out how many interrupts are supported.
 * The GIC only supports up to 1020 interrupt sources.
 */
gic_irqs = readl_relaxed(gic_data_dist_base(gic) + GIC_DIST_CTR) & 0x1f;------------计算GIC控制器最多支持的中断源个数
gic_irqs = (gic_irqs + 1) * 32;
if (gic_irqs > 1020)----------------------------------------------------------------GIC支持的最大中断数据，此处为1020
    gic_irqs = 1020;
gic->gic_irqs = gic_irqs;

if (node) {        /* DT case */
    const struct irq_domain_ops *ops = &gic_irq_domain_hierarchy_ops;--------------GICv2的struct irq_domain_ops
​```

...
        gic->domain = irq_domain_add_linear(node, gic_irqs, ops, gic);-----------------注册irq_domain，操作函数使用gic_irq_domain_hierarchy_ops
    } else {        /* Non-DT case */
...
    }

​```
if (WARN_ON(!gic->domain))
    return;

if (gic_nr == 0) {
​```

#ifdef CONFIG_SMP
        set_smp_cross_call(gic_raise_softirq);
        register_cpu_notifier(&gic_cpu_notifier);
#endif
        set_handle_irq(gic_handle_irq);-------在irq_handler中调用handle_arch_irq，这里将handle_arch_irq指向gic_handle_irq，实现了平台中断和具体GIC中断的关联。
    }

​```
gic_chip.flags |= gic_arch_extn.flags;
gic_dist_init(gic);----------------------GIC Distributer部分初始化
gic_cpu_init(gic);-----------------------GIC CPU Interface部分初始化
gic_pm_init(gic);------------------------GIC PM相关初始化
​```

}
```

irq_domain_add_linear()->__irq_domain_add()分配并初始化struct irq_domain。

~~~c
struct irq_domain *__irq_domain_add(struct device_node *of_node, int size,
                    irq_hw_number_t hwirq_max, int direct_max,
                    const struct irq_domain_ops *ops,
                    void *host_data)
{
    struct irq_domain *domain;

```
domain = kzalloc_node(sizeof(*domain) + (sizeof(unsigned int) * size),
              GFP_KERNEL, of_node_to_nid(of_node));-------------domain大小为struct irq_domain加上gic_irqs个unsigned int。
if (WARN_ON(!domain))
    return NULL;

/* Fill structure */
INIT_RADIX_TREE(&domain->revmap_tree, GFP_KERNEL);
domain->ops = ops;
domain->host_data = host_data;
domain->of_node = of_node_get(of_node);
domain->hwirq_max = hwirq_max;
domain->revmap_size = size;
domain->revmap_direct_max_irq = direct_max;
irq_domain_check_hierarchy(domain);

mutex_lock(&irq_domain_mutex);
list_add(&domain->link, &irq_domain_list);----------------------将创建好的struct irq_domain加入全局链表irq_domain_list。
mutex_unlock(&irq_domain_mutex);

pr_debug("Added domain %s\n", domain->name);
return domain;
```

}
~~~

#### 2.3 系统初始化之中断号映射

 上一小节是中断控制器GIC的初始化，下面看看一个硬件中断是如何映射到Linux空间的中断的。

customize_machine()是arch_initcall阶段调用，很靠前。

>  customize_machine
>
>   ->of_platform_populate
>
> ​    ->of_platform_bus_create
>
> ​      ->of_amba_device_create
>
> ​        ->[of_amba_device_create](https://www.cnblogs.com/arnoldlu/p/8659981.html#of_amba_device_create)

下面结合dtsi文件看看来龙去脉，arch/arm/boot/dts/vexpress-v2m.dtsi。

~~~c
/dts-v1/;

/ {
    model = "V2P-CA9";
    arm,hbi = <0x191>;
    arm,vexpress,site = <0xf>;
    compatible = "arm,vexpress,v2p-ca9", "arm,vexpress";
    interrupt-parent = <&gic>;
    #address-cells = <1>;
    #size-cells = <1>;
...
    gic: interrupt-controller@1e001000 {
        compatible = "arm,cortex-a9-gic";
        #interrupt-cells = <3>;
        #address-cells = <0>;
        interrupt-controller;
        reg = <0x1e001000 0x1000>,
              <0x1e000100 0x100>;
    };
...
    smb {
        compatible = "simple-bus";

```
    #address-cells = <2>;
    #size-cells = <1>;
    ranges = <0 0 0x40000000 0x04000000>,
         <1 0 0x44000000 0x04000000>,
         <2 0 0x48000000 0x04000000>,
         <3 0 0x4c000000 0x04000000>,
         <7 0 0x10000000 0x00020000>;

    #interrupt-cells = <1>;
    interrupt-map-mask = <0 0 63>;
    interrupt-map = <0 0  0 &gic 0  0 4>,
            <0 0  1 &gic 0  1 4>,
```

...
/include/ "vexpress-v2m.dtsi"
    };
}

vexpress-v2m.dtsi文件：

```
motherboard {
    model = "V2M-P1";
    arm,hbi = <0x190>;
    arm,vexpress,site = <0>;
    compatible = "arm,vexpress,v2m-p1", "simple-bus";
    #address-cells = <2>; /* SMB chipselect number and offset */
    #size-cells = <1>;
    #interrupt-cells = <1>;
    ranges;
```

...
        iofpga@7,00000000 {
            compatible = "arm,amba-bus", "simple-bus";
            #address-cells = <1>;
            #size-cells = <1>;
            ranges = <0 7 0 0x20000>;
...
            v2m_serial0: uart@09000 {
                compatible = "arm,pl011", "arm,primecell";
                reg = <0x09000 0x1000>;
                interrupts = <5>;
                clocks = <&v2m_oscclk2>, <&smbclk>;
                clock-names = "uartclk", "apb_pclk";
            };
...
        };
    }
~~~

这里首先从根目录下查找"simple-bus"，从上面可以看出指向smb设备。

smb设备包含vexpress-v2m.dtsi文件，然后在of_platform_bus_create()中遍历所有设备。

~~~c
const struct of_device_id of_default_bus_match_table[] = {
    { .compatible = "simple-bus", },
#ifdef CONFIG_ARM_AMBA
    { .compatible = "arm,amba-bus", },
#endif /* CONFIG_ARM_AMBA */
    {} /* Empty terminated list */
};

static int __init customize_machine(void)
{
...
        of_platform_populate(NULL, of_default_bus_match_table,-----------------找到匹配"simple-bus"的设备，这里指向smb。
                    NULL, NULL);
...
}

int of_platform_populate(struct device_node *root,
            const struct of_device_id *matches,
            const struct of_dev_auxdata *lookup,
            struct device *parent)
{
...
    for_each_child_of_node(root, child) {
        rc = of_platform_bus_create(child, matches, lookup, parent, true);-----这里的root指向根目录，即"/"。
        if (rc)
            break;
    }
...
}

static int of_platform_bus_create(struct device_node *bus,
                  const struct of_device_id *matches,
                  const struct of_dev_auxdata *lookup,
                  struct device *parent, bool strict)
{
    const struct of_dev_auxdata *auxdata;
    struct device_node *child;
    struct platform_device *dev;
    const char *bus_id = NULL;
    void *platform_data = NULL;
    int rc = 0;

```
/* Make sure it has a compatible property */
if (strict && (!of_get_property(bus, "compatible", NULL))) {
    pr_debug("%s() - skipping %s, no compatible prop\n",
         __func__, bus->full_name);
    return 0;
}

auxdata = of_dev_lookup(lookup, bus);
if (auxdata) {
    bus_id = auxdata->name;
    platform_data = auxdata->platform_data;
}

if (of_device_is_compatible(bus, "arm,primecell")) {------当遇到匹配"arm,primecell"设备，创建amba设备。在ofpga@7,00000000中创建uart@09000设备。
    /*
     * Don't return an error here to keep compatibility with older
     * device tree files.
     */
    of_amba_device_create(bus, bus_id, platform_data, parent);
    return 0;
}

dev = of_platform_device_create_pdata(bus, bus_id, platform_data, parent);
if (!dev || !of_match_node(matches, bus))
    return 0;

for_each_child_of_node(bus, child) {----------------遍历smb下的所有"simple-bus"设备，这里可以嵌套几层。从smb->motherboard->iofpga@7,00000000。
    pr_debug("   create child: %s\n", child->full_name);
    rc = of_platform_bus_create(child, matches, lookup, &dev->dev, strict);
    if (rc) {
        of_node_put(child);
        break;
    }
}
of_node_set_flag(bus, OF_POPULATED_BUS);
return rc;
```

}
~~~

 of_amba_device_create创建ARM AMBA类型设备，其中中断部分交给irq_of_parse_and_map()处理。

```c
static struct amba_device *of_amba_device_create(struct device_node *node,
                         const char *bus_id,
                         void *platform_data,
                         struct device *parent)
{
...
    /* Decode the IRQs and address ranges */
    for (i = 0; i < AMBA_NR_IRQS; i++)
        dev->irq[i] = irq_of_parse_and_map(node, i);
...
}
```

以uart@09000为例，irq_of_parse_and_map中的of_irq_parse_one()解析设备中的"interrupts"、"regs"等参数，参数放入struct of_phandle_args中，oirq->args[1]中存放中断号5，oirq->np存放struct device_node。

irq_create_of_mapping()建立硬件中断号到Linux中断号的映射。

irq_create_of_mapping主要调用如下，主要工作交给__irq_domain_alloc_irqs()进行处理。

> [irq_create_of_mapping](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_create_of_mapping)
>
>   ->domain->ops->xlate---------------------------------
>
>   ->irq_find_mapping
>
>   ->irq_domain_alloc_irqs
>
> ​    ->__irq_domain_alloc_irqs
>
> ​      ->irq_domain_alloc_descs
>
> ​      ->irq_domain_alloc_irq_data
>
> ​      ->irq_domain_alloc_irqs_recursive
>
> ​        ->gic_irq_domain_alloc
>
> ​          ->gic_irq_domain_map-----------------------进行硬件中断号和软件中断号的映射
>
> ​            ->gic_irq_domain_set_info----------------设置重要参数到中断描述符中
>
> ​      ->irq_domain_insert_irq

~~~c
unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
{
    struct of_phandle_args oirq;

```
if (of_irq_parse_one(dev, index, &oirq))
    return 0;

return irq_create_of_mapping(&oirq);
```

}

unsigned int irq_create_of_mapping(struct of_phandle_args *irq_data)
{
    struct irq_domain *domain;
    irq_hw_number_t hwirq;
    unsigned int type = IRQ_TYPE_NONE;
    int virq;

```
domain = irq_data->np ? irq_find_host(irq_data->np) : irq_default_domain;---找到设备所属的struct irq_domain结构体。
```

...
    /* If domain has no translation, then we assume interrupt line */
    if (domain->ops->xlate == NULL)
        hwirq = irq_data->args[0];
    else {
        if (domain->ops->xlate(domain, irq_data->np, irq_data->args,-------调用gic_irq_domain_xlate()函数进行硬件中断号到Linux中断号的转换。
                    irq_data->args_count, &hwirq, &type))
            return 0;
    }

```
if (irq_domain_is_hierarchy(domain)) {-------------------------可以分层挂载
    /*
     * If we've already configured this interrupt,
     * don't do it again, or hell will break loose.
     */
    virq = irq_find_mapping(domain, hwirq);-------------------从已有的linear_revmap中寻找Linux中断号。
    if (virq)
        return virq;

    virq = irq_domain_alloc_irqs(domain, 1, NUMA_NO_NODE, irq_data);---------如果没有找到，重新分配中断映射。参数1表示每次只分配一个中断。
    if (virq <= 0)
        return 0;
} else {
```

...
    }

```
/* Set type if specified and different than the current one */
if (type != IRQ_TYPE_NONE &&
    type != irq_get_trigger_type(virq))
    irq_set_irq_type(virq, type);-----------------------------设置中断触发类型
return virq;
```

}
~~~

[struct irq_desc](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_desc)定义了中断描述符，irq_desc[]数组定义了NR_IRQS个中断描述符，数组下标表示IRQ中断号，通过IRQ中断号可以找到对应中断描述符。

struct irq_desc内置了[struct irq_data](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_data)结构体，struct irq_data的irq和hwirq分别对应软件中断号和硬件中断号。通过这两个成员，可以将硬件中断号和软件中断号映射起来。

struct irq_chip定义了中断控制器底层操作相关的方法集合。

~~~c
struct irq_desc {
    struct irq_data        irq_data;
    unsigned int __percpu    *kstat_irqs;
    irq_flow_handler_t    handle_irq;-----------------根据中断号分类，不同类型中断的处理handle。0~31对应handle_percpu_devid_irq；32~对应handle_fasteoi_irq。
#ifdef CONFIG_IRQ_PREFLOW_FASTEOI
    irq_preflow_handler_t    preflow_handler;
#endif
    struct irqaction    *action;    /* IRQ action list */
    unsigned int        status_use_accessors;
    unsigned int        core_internal_state__do_not_mess_with_it;
    unsigned int        depth;        /* nested irq disables */
    unsigned int        wake_depth;    /* nested wake enables */
    unsigned int        irq_count;    /* For detecting broken IRQs */
    unsigned long        last_unhandled;    /* Aging timer for unhandled count */
    unsigned int        irqs_unhandled;
    atomic_t        threads_handled;
    int            threads_handled_last;
    raw_spinlock_t        lock;
    struct cpumask        *percpu_enabled;
#ifdef CONFIG_SMP
    const struct cpumask    *affinity_hint;
    struct irq_affinity_notify *affinity_notify;
#ifdef CONFIG_GENERIC_PENDING_IRQ
    cpumask_var_t        pending_mask;
#endif
#endif
    unsigned long        threads_oneshot;-------------是一个位图，每个比特位代表正在处理的共享oneshot类型中断的中断线程。
    atomic_t        threads_active;-------------------表示正在运行的中断线程个数
    wait_queue_head_t       wait_for_threads;
#ifdef CONFIG_PM_SLEEP
    unsigned int        nr_actions;
    unsigned int        no_suspend_depth;
    unsigned int        cond_suspend_depth;
    unsigned int        force_resume_depth;
#endif
#ifdef CONFIG_PROC_FS
    struct proc_dir_entry    *dir;
#endif
    int            parent_irq;
    struct module        *owner;
    const char        *name;
}

struct irq_data {
    u32            mask;
    unsigned int        irq;-----------------Linux软件中断号
    unsigned long        hwirq;--------------硬件中断号
    unsigned int        node;
    unsigned int        state_use_accessors;
    struct irq_chip        *chip;
    struct irq_domain    *domain;
#ifdef    CONFIG_IRQ_DOMAIN_HIERARCHY
    struct irq_data        *parent_data;
#endif
    void            *handler_data;
    void            *chip_data;
    struct msi_desc        *msi_desc;
    cpumask_var_t        affinity;
}

struct irq_chip {
    const char    *name;
    unsigned int    (*irq_startup)(struct irq_data *data);-------------初始化中断
    void        (*irq_shutdown)(struct irq_data *data);----------------结束中断
    void        (*irq_enable)(struct irq_data *data);------------------使能中断
    void        (*irq_disable)(struct irq_data *data);-----------------关闭中断

```
void        (*irq_ack)(struct irq_data *data);---------------------应答中断
void        (*irq_mask)(struct irq_data *data);--------------------屏蔽中断
void        (*irq_mask_ack)(struct irq_data *data);----------------应答并屏蔽中断
void        (*irq_unmask)(struct irq_data *data);------------------解除中断屏蔽
void        (*irq_eoi)(struct irq_data *data);---------------------发送EOI信号，表示硬件中断处理已经完成。

int        (*irq_set_affinity)(struct irq_data *data, const struct cpumask *dest, bool force);--------绑定中断到某个CPU
int        (*irq_retrigger)(struct irq_data *data);----------------重新发送中断到CPU
int        (*irq_set_type)(struct irq_data *data, unsigned int flow_type);----------------------------设置触发类型
int        (*irq_set_wake)(struct irq_data *data, unsigned int on);-----------------------------------使能/关闭中断在电源管理中的唤醒功能。

void        (*irq_bus_lock)(struct irq_data *data);
void        (*irq_bus_sync_unlock)(struct irq_data *data);

void        (*irq_cpu_online)(struct irq_data *data);
void        (*irq_cpu_offline)(struct irq_data *data);

void        (*irq_suspend)(struct irq_data *data);
void        (*irq_resume)(struct irq_data *data);
void        (*irq_pm_shutdown)(struct irq_data *data);
```

...
    unsigned long    flags;
}
~~~

gic_chip是特定中断控制器的硬件操作函数集，对于GICv2有屏蔽/去屏蔽、EOI、设置中断触发类型、以及设置或者当前芯片状态。

~~~c
static const struct irq_chip gic_chip = {
    .irq_mask        = gic_mask_irq,
    .irq_unmask        = gic_unmask_irq,
    .irq_eoi        = gic_eoi_irq,
    .irq_set_type        = gic_set_type,
    .irq_get_irqchip_state    = gic_irq_get_irqchip_state,
    .irq_set_irqchip_state    = gic_irq_set_irqchip_state,
    .flags            = IRQCHIP_SET_TYPE_MASKED |
                  IRQCHIP_SKIP_SET_WAKE |
                  IRQCHIP_MASK_ON_SUSPEND,
};

static void gic_mask_irq(struct irq_data *d)
{
    gic_poke_irq(d, GIC_DIST_ENABLE_CLEAR);
}

static void gic_unmask_irq(struct irq_data *d)
{
    gic_poke_irq(d, GIC_DIST_ENABLE_SET);
}

static void gic_eoi_irq(struct irq_data *d)
{
    writel_relaxed(gic_irq(d), gic_cpu_base(d) + GIC_CPU_EOI);
}

static int gic_set_type(struct irq_data *d, unsigned int type)
{
    void __iomem *base = gic_dist_base(d);
    unsigned int gicirq = gic_irq(d);

```
/* Interrupt configuration for SGIs can't be changed */
if (gicirq < 16)
    return -EINVAL;

/* SPIs have restrictions on the supported types */
if (gicirq >= 32 && type != IRQ_TYPE_LEVEL_HIGH &&
            type != IRQ_TYPE_EDGE_RISING)
    return -EINVAL;

return gic_configure_irq(gicirq, type, base, NULL);
```

}

static int gic_irq_set_irqchip_state(struct irq_data *d,
                     enum irqchip_irq_state which, bool val)
{
    u32 reg;

```
switch (which) {
case IRQCHIP_STATE_PENDING:
    reg = val ? GIC_DIST_PENDING_SET : GIC_DIST_PENDING_CLEAR;
    break;

case IRQCHIP_STATE_ACTIVE:
    reg = val ? GIC_DIST_ACTIVE_SET : GIC_DIST_ACTIVE_CLEAR;
    break;

case IRQCHIP_STATE_MASKED:
    reg = val ? GIC_DIST_ENABLE_CLEAR : GIC_DIST_ENABLE_SET;
    break;

default:
    return -EINVAL;
}

gic_poke_irq(d, reg);
return 0;
```

}

static int gic_irq_get_irqchip_state(struct irq_data *d,
                      enum irqchip_irq_state which, bool *val)
{
    switch (which) {
    case IRQCHIP_STATE_PENDING:
        *val = gic_peek_irq(d, GIC_DIST_PENDING_SET);
        break;

```
case IRQCHIP_STATE_ACTIVE:
    *val = gic_peek_irq(d, GIC_DIST_ACTIVE_SET);
    break;

case IRQCHIP_STATE_MASKED:
    *val = !gic_peek_irq(d, GIC_DIST_ENABLE_SET);
    break;

default:
    return -EINVAL;
}

return 0;
```

}
~~~

irq_domain_alloc_irqs()调用__irq_domain_alloc_irqs()进行struct irq_desc、struct irq_data以及中断映射的处理。

这里的参数nr_irqs一般为1，每次只处理一个中断。

irq_domain_alloc_descs()->irq_alloc_descs()->__irq_alloc_descs()进行struct irq_desc的分配，返回的参数是Linux中断号。

~~~c
int __irq_domain_alloc_irqs(struct irq_domain *domain, int irq_base,
                unsigned int nr_irqs, int node, void *arg,
                bool realloc)
{
...
    if (realloc && irq_base >= 0) {
        virq = irq_base;
    } else {
        virq = irq_domain_alloc_descs(irq_base, nr_irqs, 0, node);-------从allocated_irqs位图中查找第一个nr_irqs个空闲的比特位，最终调用__irq_alloc_descs。
        if (virq < 0) {
            pr_debug("cannot allocate IRQ(base %d, count %d)\n",
                 irq_base, nr_irqs);
            return virq;
        }
    }

```
if (irq_domain_alloc_irq_data(domain, virq, nr_irqs)) {--------------分配struct irq_data数据结构。
    pr_debug("cannot allocate memory for IRQ%d\n", virq);
    ret = -ENOMEM;
    goto out_free_desc;
}

mutex_lock(&irq_domain_mutex);
ret = irq_domain_alloc_irqs_recursive(domain, virq, nr_irqs, arg);----调用struct irq_domain中的alloc回调函数进行硬件中断号和软件中断号的映射。
if (ret < 0) {
    mutex_unlock(&irq_domain_mutex);
    goto out_free_irq_data;
}
for (i = 0; i < nr_irqs; i++)
    irq_domain_insert_irq(virq + i);
mutex_unlock(&irq_domain_mutex);

return virq;
```

...
}

int __ref

__irq_alloc_descs(int irq, unsigned int from, unsigned int cnt, int node,
          struct module *owner)
{
...
    mutex_lock(&sparse_irq_lock);

```
start = bitmap_find_next_zero_area(allocated_irqs, IRQ_BITMAP_BITS,
                   from, cnt, 0);-------------------在allocated_irqs位图中查找第一个连续cnt个为0的比特位区域。
```

...
    bitmap_set(allocated_irqs, start, cnt);-------------bitmap_set()设置这些比特位，表示这些比特位已经被占用。
    mutex_unlock(&sparse_irq_lock);
    return alloc_descs(start, cnt, node, owner);--------这里要看是否定义了CONFIG_SPARSE_IRQ，如果定义了需要动态分配一个struct irq_desc数据结构，以Radix Tree方式存储；没有的话则从irq_desc全局变量中加上偏移即可。

err:
    mutex_unlock(&sparse_irq_lock);
    return ret;
}
​~~~

 irq_domain_alloc_irqs_recursive()会根据实际情况决定中断控制器的递归处理，

static int irq_domain_alloc_irqs_recursive(struct irq_domain *domain,
                       unsigned int irq_base,
                       unsigned int nr_irqs, void *arg)
{
    int ret = 0;
    struct irq_domain *parent = domain->parent;
    bool recursive = irq_domain_is_auto_recursive(domain);

```
BUG_ON(recursive && !parent);
if (recursive)
    ret = irq_domain_alloc_irqs_recursive(parent, irq_base,
                          nr_irqs, arg);
if (ret >= 0)
    ret = domain->ops->alloc(domain, irq_base, nr_irqs, arg);
if (ret < 0 && recursive)
    irq_domain_free_irqs_recursive(parent, irq_base, nr_irqs);

return ret;
```

}
~~~

 irq_domain_alloc_irqs_recursive()会根据实际情况决定中断控制器的递归处理，

~~~c
static int irq_domain_alloc_irqs_recursive(struct irq_domain *domain,
                       unsigned int irq_base,
                       unsigned int nr_irqs, void *arg)
{
    int ret = 0;
    struct irq_domain *parent = domain->parent;
    bool recursive = irq_domain_is_auto_recursive(domain);

```
BUG_ON(recursive && !parent);
if (recursive)
    ret = irq_domain_alloc_irqs_recursive(parent, irq_base,
                          nr_irqs, arg);
if (ret >= 0)
    ret = domain->ops->alloc(domain, irq_base, nr_irqs, arg);
if (ret < 0 && recursive)
    irq_domain_free_irqs_recursive(parent, irq_base, nr_irqs);

return ret;
```

}
~~~

至此完成了中断DeviceTree的解析，各数据结构的初始化，以及最主要的硬件中断号到Linux中断号的映射。

### 3. ARM底层中断处理

 ARM底层中断处理的范围是从中断异常触发，到irq_handler。

#### 3.1 中断硬件行为

外设有事件需要报告SoC时，通过和SoC链接的中断管脚发送中断信号，可能是边沿触发信号也可能是电平触发信号。

中断控制器会感知中断信号，中断控制器仲裁单元选择优先级最高的中断发送到CPU Interface，CPU Interface决定将中断分发到哪个CPU核心。

GIC控制器和CPU核心之间通过一个nIRQ(IRQ request input line)信号来通知CPU。

CPU核心感知到中断发生之后，硬件会做如下工作：

- 保存中断发生时CPSR寄存器内容到SPSR_irq寄存器中
- 修改CPSR寄存器，让CPU进入处理器模式(processor mode)中的IRQ模式，即修改CPSR寄存器中的M域设置为IRQ Mode。
- 硬件自动关闭中断IRQ或FIQ，即CPSR中的IRQ位或FIQ位置1。------------硬件自动关中断
- 保存返回地址到LR_irq寄存器中。
- 硬件自动调转到中断向量表的IRQ向量。-------------------------------------------从此处开始进入软件领域

当从中断返回时需要软件实现如下操作：

- 从SPSR_irq寄存器中恢复数据到CPSR中。
- 从LR_irq中恢复内容到PC中，从而返回到中断点的下一个指令处执行。

#### 3.2 中断异常向量

##### 3.2.1 中断异常向量代码段初始化

内核编译时，异常向量表存放在可执行文件的__init段中：arch/arm/kernel/vmlinux.lds.S。

__vectors_start和__vectors_end指向vectors段的开始和结束地址，__stubs_start和__stubs_end存放异常向量stubs代码段。两者都是页面对齐，大小都为一个页面。

```c
__vectors_start = .;
    .vectors 0 : AT(__vectors_start) {
        *(.vectors)----------------------------------保存.vectors段数据
    }
    . = __vectors_start + SIZEOF(.vectors);
    __vectors_end = .;

__stubs_start = .;
.stubs 0x1000 : AT(__stubs_start) {
    *(.stubs)------------------------------------存放.stubs段数据
}
. = __stubs_start + SIZEOF(.stubs);

__stubs_end = .;
```

系统初始化时会把上述两个段复制到高端地址处，即ixffff_0000：start_kernel->setup_arch->paging_init->devicemap_init。

~~~c
static void __init devicemaps_init(const struct machine_desc *mdesc)
{
    struct map_desc map;
    unsigned long addr;
    void *vectors;

```
/*
 * Allocate the vector page early.
 */
vectors = early_alloc(PAGE_SIZE * 2);-------------------------------分配两个页面用于映射到high vectors高端地址。

early_trap_init(vectors);-------------------------------------------实现异常向量表的复制动作。...
/*
 * Create a mapping for the machine vectors at the high-vectors
 * location (0xffff0000).  If we aren't using high-vectors, also
 * create a mapping at the low-vectors virtual address.
 */
map.pfn = __phys_to_pfn(virt_to_phys(vectors));---------------------vectors物理页面号
map.virtual = 0xffff0000;-------------------------------------------待映射到的虚拟地址0xffff_0000~0xffff_0fff
map.length = PAGE_SIZE;---------------------------------------------映射区间大小
```

#ifdef CONFIG_KUSER_HELPERS
    map.type = MT_HIGH_VECTORS;-----------------------------------------映射到high vector
#else
    map.type = MT_LOW_VECTORS;
#endif
    create_mapping(&map);

```
if (!vectors_high()) {
    map.virtual = 0;
    map.length = PAGE_SIZE * 2;
    map.type = MT_LOW_VECTORS;
    create_mapping(&map);
}

/* Now create a kernel read-only mapping */
map.pfn += 1;
map.virtual = 0xffff0000 + PAGE_SIZE;------------------------------映射到0xffff_1000~0xffff_1ffff
map.length = PAGE_SIZE;
map.type = MT_LOW_VECTORS;
create_mapping(&map);
```

...
}
```

early_trap_init分别将__vectors_start和__stubs_start两个页面复制到分配的两个页面中。

void __init early_trap_init(void *vectors_base)
{
...
    unsigned long vectors = (unsigned long)vectors_base;
    extern char __stubs_start[], __stubs_end[];
    extern char __vectors_start[], __vectors_end[];
    unsigned i;

```
vectors_page = vectors_base;

/*
 * Poison the vectors page with an undefined instruction.  This
 * instruction is chosen to be undefined for both ARM and Thumb
 * ISAs.  The Thumb version is an undefined instruction with a
 * branch back to the undefined instruction.
 */
for (i = 0; i < PAGE_SIZE / sizeof(u32); i++)
    ((u32 *)vectors_base)[i] = 0xe7fddef1;---------------------------第一个页面全部填充未定义指令0xe7fddef1。

/*
 * Copy the vectors, stubs and kuser helpers (in entry-armv.S)
 * into the vector page, mapped at 0xffff0000, and ensure these
 * are visible to the instruction stream.
 */
memcpy((void *)vectors, __vectors_start, __vectors_end - __vectors_start);
memcpy((void *)vectors + 0x1000, __stubs_start, __stubs_end - __stubs_start);
```

...
}
~~~

##### 3.2.2 中断异常向量

中断发生后，软件跳转到中断向量表开始vector_irq执行，vector_irq在结尾的时候根据中断发生点所在模式，决定跳转到__irq_usr或者__irq_svc。

vector_irq在arch/arm/kernel/entry-armv.S由宏[vector_stub](https://www.cnblogs.com/arnoldlu/p/8659981.html#vector_stub)定义。

 关于correction==4，需要减去4字节才是返回地址？

vector_stub宏参数correction为4,。

正在执行指令A时发生了中断，由于ARM流水线和指令预取等原因，pc指向A+8B处，那么必须等待指令A执行完毕才能处理该中断，这时PC已经更新到A+12B处。

进入中断响应前夕，pc寄存器的内容被装入lr寄存器中，lr=pc-4，即A+8B地址处。

因此返回时要pc=lr-4，才是被中断时要执行的下一条指令。所以lr要回退4B。

~~~c
.section .vectors, "ax", %progbits
__vectors_start:
    W(b)    vector_rst
    W(b)    vector_und
    W(ldr)    pc, __vectors_start + 0x1000
    W(b)    vector_pabt
    W(b)    vector_dabt
    W(b)    vector_addrexcptn
    W(b)    vector_irq---------------------------------------------------------------跳转到vector_irq
    W(b)    vector_fiq

/*

- Interrupt dispatcher
  */
  vector_stub    irq, IRQ_MODE, 4------------------------------------------------vector_stub宏定义了vector_irq

  .long    __irq_usr            @  0  (USR_26 / USR_32)
  .long    __irq_invalid            @  1  (FIQ_26 / FIQ_32)
  .long    __irq_invalid            @  2  (IRQ_26 / IRQ_32)
  .long    __irq_svc            @  3  (SVC_26 / SVC_32)----------------------------svc模式数值是0b10011，与上0xf后就是3。
  .long    __irq_invalid            @  4
  .long    __irq_invalid            @  5
  .long    __irq_invalid            @  6
  .long    __irq_invalid            @  7
  .long    __irq_invalid            @  8
  .long    __irq_invalid            @  9
  .long    __irq_invalid            @  a
  .long    __irq_invalid            @  b
  .long    __irq_invalid            @  c
  .long    __irq_invalid            @  d
  .long    __irq_invalid            @  e
  .long    __irq_invalid            @  f



```
  .macro vector_stub, name, mode, correction=0------------------------------------vector_stub宏定义
.align 5
```

vector_\name:
    .if \correction
    sub    lr, lr, #\correction-------------------------------------------------------correction==4解释
    .endif

```
@
@ Save r0, lr_<exception> (parent PC) and spsr_<exception>
@ (parent CPSR)
@
stmia    sp, {r0, lr}        @ save r0, lr
mrs    lr, spsr
str    lr, [sp, #8]        @ save spsr

@
@ Prepare for SVC32 mode.  IRQs remain disabled.
@
mrs    r0, cpsr
eor    r0, r0, #(\mode ^ SVC_MODE | PSR_ISETSTATE)---------------------------------修改CPSR寄存器的控制域为SVC模式，为了使中断处理在SVC模式下执行。
msr    spsr_cxsf, r0

@
@ the branch table must immediately follow this code
@
and    lr, lr, #0x0f--------------------------------------------------------------低4位反映了进入中断前CPU的运行模式，9为USR，3为SVC模式。
```

 THUMB(    adr    r0, 1f            )
 THUMB(    ldr    lr, [r0, lr, lsl #2]    )-------------------------------------------根据中断发生点所在的模式，给lr寄存器赋值，__irq_usr或者__irq_svc标签处。
    mov    r0, spk
 ARM(    ldr    lr, [pc, lr, lsl #2]    )---------------------------------------------得到的lr就是".long __irq_svc"
    movs    pc, lr            @ branch to handler in SVC mode-------------------------把lr的值赋给pc指针，跳转到__irq_usr或者__irq_svc。
ENDPROC(vector_\name)
~~~

#### 3.3 内核空间中断处理__irq_svc

__irq_svc处理发生在内核空间的中断，主要svc_entry保护中断现场；irq_handler执行中断处理；如果打开抢占功能，检查是否可以抢占；最后svc_exit执行中断退出处理。

~~~c
__irq_svc:
    svc_entry
    irq_handler

#ifdef CONFIG_PREEMPT-----------------------------------------------------中断处理结束后，发生抢占的地方♥
    get_thread_info tsk
    ldr    r8, [tsk, #TI_PREEMPT]        @ get preempt count--------------获取thread_info->preempt_cpunt变量;preempt_count为0，说明可以抢占进程；preempt_count大于0，表示不能抢占。
    ldr    r0, [tsk, #TI_FLAGS]        @ get flags------------------------获取thread_info->flags变量
    teq    r8, #0                @ if preempt count != 0
    movne    r0, #0                @ force flags to 0
    tst    r0, #_TIF_NEED_RESCHED-----------------------------------------判断是否设置了_TIF_NEED_RESCHED标志位
    blne    svc_preempt
#endif

```
svc_exit r5, irq = 1            @ return from exception
```

 UNWIND(.fnend        )
ENDPROC(__irq_svc)
~~~

svc_entry将中断现场保存到内核栈中，主要是struct pt_regs中的寄存器。

~~~c
.macro    svc_entry, stack_hole=0, trace=1
 UNWIND(.fnstart        )
 UNWIND(.save {r0 - pc}        )
    sub    sp, sp, #(S_FRAME_SIZE + \stack_hole - 4)
#ifdef CONFIG_THUMB2_KERNEL
 SPFIX(    str    r0, [sp]    )    @ temporarily saved
 SPFIX(    mov    r0, sp        )
 SPFIX(    tst    r0, #4        )    @ test original stack alignment
 SPFIX(    ldr    r0, [sp]    )    @ restored
#else
 SPFIX(    tst    sp, #4        )
#endif
 SPFIX(    subeq    sp, sp, #4    )
    stmia    sp, {r1 - r12}

```
ldmia    r0, {r3 - r5}
add    r7, sp, #S_SP - 4    @ here for interlock avoidance
mov    r6, #-1            @  ""  ""      ""       ""
add    r2, sp, #(S_FRAME_SIZE + \stack_hole - 4)
```

 SPFIX(    addeq    r2, r2, #4    )
    str    r3, [sp, #-4]!        @ save the "real" r0 copied
                    @ from the exception stack

```
mov    r3, lr

@
@ We are now ready to fill in the remaining blanks on the stack:
@
@  r2 - sp_svc
@  r3 - lr_svc
@  r4 - lr_<exception>, already fixed up for correct return/restart
@  r5 - spsr_<exception>
@  r6 - orig_r0 (see pt_regs definition in ptrace.h)
@
stmia    r7, {r2 - r6}

.if \trace
```

#ifdef CONFIG_TRACE_IRQFLAGS
    bl    trace_hardirqs_off
#endif
    .endif
    .endm
~~~

svc_exit准备返回中断现场，然后通过ldmia指令从栈中恢复15个寄存器，包括pc内容，至此整个中断完成并返回。

```c
    .macro    svc_exit, rpsr, irq = 0...
    msr    spsr_cxsf, \rpsr
    ldmia    sp, {r0 - pc}^            @ load r0 - pc, cpsr
    .endm
```

irq_handler进入高层中断处理

### 4. 高层中断处理

irq_handler汇编宏是ARCH层和高层中断处理分割线，在这里从汇编跳转到C进行GIC相关处理。

前面介绍了一个中断是如何从硬件中断号映射到Linux中断号的，那么当一个中断产生后它从应将到软件识别中断号，再到转换成Linux中断号是什么路径呢？

这里就从irq_handler开始分析流程：

> [irq_handler](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_handler)()
>
>   ->handle_arch_irq()->[gic_handle_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#gic_handle_irq)()
>
> ​    ->handle_domain_irq()->[__handle_domain_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_domain_irq)()-------------读取IAR寄存器，响应中断，获取硬件中断号
>
> ​      ->[irq_find_mapping](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_find_mapping)()------------------------------------------------将硬件中断号转变成Linux中断号
>
> ​      ->[generic_handle_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#generic_handle_irq)()---------------------------------------------之后的操作都是Linux中断号
>
> ​        ->[handle_percpu_devid_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_percpu_devid_irq)()-----------------------------------SGI/PPI类型中断处理
>
> ​        ->[handle_fasteoi_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_fasteoi_irq)()--------------------------------------------SPI类型中断处理
>
> ​          ->handle_irq_event()->[handle_irq_event_percpu](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_irq_event_percpu)()------执行中断处理核心函数
>
> ​            ->action->handler-----------------------------------------------执行primary handler。
>
> ​            ->[__irq_wake_thread](https://www.cnblogs.com/arnoldlu/p/8659981.html#irq_wake_thread)()----------------------------------------根据需要唤醒中断内核线程

#### 4.1 irq_handler

 irq_handler宏调用handle_arch_irq函数，这个函数set_handle_irq注册，GICv2对应gic_handle_irq。

```c
.macro    irq_handler
#ifdef CONFIG_MULTI_IRQ_HANDLER
    ldr    r1, =handle_arch_irq
    mov    r0, sp
    adr    lr, BSYM(9997f)
    ldr    pc, [r1]
#else
    arch_irq_handler_default
#endif
9997:
    .endm
```

#### 4.2 gic_handle_irq

git_init_bases设置handle_arch_irq为gic_handle_irq。

~~~c
void __init gic_init_bases(unsigned int gic_nr, int irq_start,
               void __iomem *dist_base, void __iomem *cpu_base,
               u32 percpu_offset, struct device_node *node)
{
...
    if (gic_nr == 0) {
...
        set_handle_irq(gic_handle_irq);
    }
...
}

void __init set_handle_irq(void (*handle_irq)(struct pt_regs *))
{
    if (handle_arch_irq)
        return;

```
handle_arch_irq = handle_irq;
```

}
~~~

 gic_handle_irq对将中断分为两组：SGI、PPI/SPI。

SGI类型中断交给handle_IPI()处理；PPI/SPI类型交给handle_domain_irq处理。

~~~c
static void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)
{
    u32 irqstat, irqnr;
    struct gic_chip_data *gic = &gic_data[0];
    void __iomem *cpu_base = gic_data_cpu_base(gic);

```
do {
    irqstat = readl_relaxed(cpu_base + GIC_CPU_INTACK);---读取IAR寄存器，表示响应中断。
    irqnr = irqstat & GICC_IAR_INT_ID_MASK;-----------------GICC_IAR_INT_ID_MASK为0x3ff，即低10位，所以中断最多从0~1023。

    if (likely(irqnr > 15 && irqnr < 1021)) {
        handle_domain_irq(gic->domain, irqnr, regs);
        continue;
    }
    if (irqnr < 16) {---------------------------------------SGI类型的中断是CPU核间通信所用，只有定义了CONFIG_SMP才有意义。
        writel_relaxed(irqstat, cpu_base + GIC_CPU_EOI);----直接写EOI寄存器，表示结束中断。
```

#ifdef CONFIG_SMP
            handle_IPI(irqnr, regs);----------------------------irqnr表示SGI中断类型
#endif
            continue;
        }
        break;
    } while (1);
}
~~~

handle_domain_irq调用__handle_domain_irq，其中lookup置为true。

irq_enter显式告诉Linux内核现在要进入中断上下文了，在处理完中断后调用irq_exit告诉Linux已经完成中断处理过程。

```
int __handle_domain_irq(struct irq_domain *domain, unsigned int hwirq,
            bool lookup, struct pt_regs *regs)
{
    struct pt_regs *old_regs = set_irq_regs(regs);
    unsigned int irq = hwirq;
    int ret = 0;

​```
irq_enter();-----------------------------------------------通过显式增加hardirq域计数，通知Linux进入中断上下文
​```

#ifdef CONFIG_IRQ_DOMAIN
    if (lookup)
        irq = irq_find_mapping(domain, hwirq);-----------------根据硬件中断号找到对应的软件中断号
#endif

​```
/*
 * Some hardware gives randomly wrong interrupts.  Rather
 * than crashing, do something sensible.
 */
if (unlikely(!irq || irq >= nr_irqs)) {
    ack_bad_irq(irq);
    ret = -EINVAL;
} else {
    generic_handle_irq(irq);--------------------------------开始具体某一个中断的处理，此处irq已经是Linux中断号。
}

irq_exit();-------------------------------------------------退出中断上下文
set_irq_regs(old_regs);
return ret;
​```

}
```

irq_find_mapping在struct irq_domain中根据hwirq找到Linux环境的irq。

```c
unsigned int irq_find_mapping(struct irq_domain *domain,
                  irq_hw_number_t hwirq)
{
    struct irq_data *data;
...
    /* Check if the hwirq is in the linear revmap. */
    if (hwirq < domain->revmap_size)
        return domain->linear_revmap[hwirq];----------------linear_revmap[]在__irq_domain_alloc_irqs()->irq_domain_insert_irq()时赋值。
...
}
```

generic_handle_irq参数是irq号，irq_to_desc()根据irq号找到对应的struct irq_desc。

然后调用irq_desc->handle_irq处理对应的中断。

~~~c
int generic_handle_irq(unsigned int irq)
{
    struct irq_desc *desc = irq_to_desc(irq);

```
if (!desc)
    return -EINVAL;
generic_handle_irq_desc(irq, desc);
return 0;
```

}

static inline void generic_handle_irq_desc(unsigned int irq, struct irq_desc *desc)
{
    desc->handle_irq(irq, desc);
}
~~~

关于desc->handle_irq来历，在每个中断注册的时候，由gic_irq_domain_map根据hwirq号决定。

在[gic_irq_domain_map](https://www.cnblogs.com/arnoldlu/p/8659981.html#gic_irq_domain_map)的时候根据hw号决定handle，hw硬件中断号小于32指向[handle_percpu_devid_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_percpu_devid_irq)，其他情况指向[handle_fasteoi_irq](https://www.cnblogs.com/arnoldlu/p/8659981.html#handle_fasteoi_irq)。

```c
void
__irq_set_handler(unsigned int irq, irq_flow_handler_t handle, int is_chained,
          const char *name)
{
...
    desc->handle_irq = handle;
    desc->name = name;
...
}
```

handle_percpu_devid_irq处理0~31的SGI/PPI类型中断，首先响应IAR，然后执行handler，最后发送EOI。

~~~c
void handle_percpu_devid_irq(unsigned int irq, struct irq_desc *desc)
{
    struct irq_chip *chip = irq_desc_get_chip(desc);
    struct irqaction *action = desc->action;
    void *dev_id = raw_cpu_ptr(action->percpu_dev_id);
    irqreturn_t res;

```
kstat_incr_irqs_this_cpu(irq, desc);

if (chip->irq_ack)
    chip->irq_ack(&desc->irq_data);

trace_irq_handler_entry(irq, action);
res = action->handler(irq, dev_id);
trace_irq_handler_exit(irq, action, res);

if (chip->irq_eoi)
    chip->irq_eoi(&desc->irq_data);-------------------调用gic_eoi_irq()函数
```

}  
~~~

irq_enter和irq_exit显式地处理hardirq域计数，两者之间的部分属于中断上下文。

~~~c
/*

- Enter an interrupt context.
  */
  void irq_enter(void)
  {
  rcu_irq_enter();
  if (is_idle_task(current) && !in_interrupt()) {
      /*
       * Prevent raise_softirq from needlessly waking up ksoftirqd
       * here, as softirq will be serviced on return from interrupt.
       */
      local_bh_disable();
      tick_irq_enter();
      _local_bh_enable();
  }

  __irq_enter();---------------------------------------------显式增加hardirq域计数
  }

#define __irq_enter()                    \
    do {                        \
        account_irq_enter_time(current);    \
        preempt_count_add(HARDIRQ_OFFSET);    \----------------显式增加hardirq域计数
        trace_hardirq_enter();            \
    } while (0)

void irq_exit(void)
{
#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED
    local_irq_disable();
#else
    WARN_ON_ONCE(!irqs_disabled());
#endif

```
account_irq_exit_time(current);
preempt_count_sub(HARDIRQ_OFFSET);---------------------------显式减少hardirq域计数
if (!in_interrupt() && local_softirq_pending())--------------当前不处于中断上下文，且有pending的softirq，进行softirq处理。
    invoke_softirq();

tick_irq_exit();
rcu_irq_exit();
trace_hardirq_exit(); /* must be last! */
```

}
~~~

##### 4.2.1 中断上下文

判断当前进程是处于中断上下文，还是进程上下文依赖于preempt_count，这个变量在struct thread_info中。

preempt_count计数共32bit，从低到高依次是：

```c
#define PREEMPT_BITS	8
#define SOFTIRQ_BITS	8
#define HARDIRQ_BITS	4
#define NMI_BITS	1
```

 *       ```c
#define hardirq_count()    (preempt_count() & HARDIRQ_MASK)-----------------硬件中断计数
#define softirq_count()    (preempt_count() & SOFTIRQ_MASK)-----------------软中断计数
#define irq_count()    (preempt_count() & (HARDIRQ_MASK | SOFTIRQ_MASK \----包括NMI、硬中断、软中断三者计数
                 | NMI_MASK))
         ```

/*

         - Are we doing bottom half or hardware interrupt processing?
           *
         - in_irq()       - We're in (hard) IRQ context
         - in_softirq()   - We have BH disabled, or are processing softirqs
         - in_interrupt() - We're in NMI,IRQ,SoftIRQ context or have BH disabled
         - in_serving_softirq() - We're in softirq context
         - in_nmi()       - We're in NMI context
         - in_task()      - We're in task context
           *
         - Note: due to the BH disabled confusion: in_softirq(),in_interrupt() really
         - should not be used in new code.
            */
           #define in_irq()        (hardirq_count())----------------------------判断是否正在硬件中断上下文
           #define in_softirq()        (softirq_count())------------------------判断是否正在处理软中断或者禁止BH。
           #define in_interrupt()        (irq_count())--------------------------判断是否处于NMI、硬中断、软中断三者之一或者兼有上下文
           #define in_serving_softirq()    (softirq_count() & SOFTIRQ_OFFSET)---判断是否处于软中断上下文。
           #define in_nmi()        (preempt_count() & NMI_MASK)-----------------判断是否处于NMI上下文
           #define in_task()        (!(preempt_count() & \
                     (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))------判断是否处于进程上下文
         ```
         
         思考：in_softirq()和in_serving_softirq()区别？in_interrupt()和in_task()中关于SOFTIRQ_MASK和SOFTIRQ_OFFSET区别？

#### 4.3 handle_fasteoi_irq

handle_fsteoi_irq处理SPI类型的中断，将主要工作交给handle_irq_event()。

handle_irq_event_percpu()首先处理action->handler，有需要则唤醒中断内核线程，执行action->thread_fn。

~~~c
void
handle_fasteoi_irq(unsigned int irq, struct irq_desc *desc)
{
    struct irq_chip *chip = desc->irq_data.chip;

```
raw_spin_lock(&desc->lock);

if (!irq_may_run(desc))
    goto out;

desc->istate &= ~(IRQS_REPLAY | IRQS_WAITING);
kstat_incr_irqs_this_cpu(irq, desc);

/*
 * If its disabled or no action available
 * then mask it and get out of here:
 */
if (unlikely(!desc->action || irqd_irq_disabled(&desc->irq_data))) {---如果该中断没有指定action描述符或该中断被关闭了IRQD_IRQ_DISABLED，设置该中断状态为IRQS_PENDING，且mask_irq()屏蔽该中断。
    desc->istate |= IRQS_PENDING;
    mask_irq(desc);
    goto out;
}

if (desc->istate & IRQS_ONESHOT)----------------------------------------如果中断是IRQS_ONESHOT，不支持中断嵌套，那么应该调用mask_irq()来屏蔽该中断源。
    mask_irq(desc);

preflow_handler(desc);--------------------------------------------------取决于是否定义了freflow_handler()
handle_irq_event(desc);

cond_unmask_eoi_irq(desc, chip);----------------------------------------根据不同条件执行unmask_irq()解除中断屏蔽，或者执行irq_chip->irq_eoi发送EOI信号，通知GIC中断处理完毕。

raw_spin_unlock(&desc->lock);
return;
```

out:
    if (!(chip->flags & IRQCHIP_EOI_IF_HANDLED))
        chip->irq_eoi(&desc->irq_data);
    raw_spin_unlock(&desc->lock);
}
~~~

handle_irq_event调用handle_irq_event_percpu，执行action->handler()，如有需要唤醒内核中断线程执行action->thread_fn。

~~~c
irqreturn_t handle_irq_event(struct irq_desc *desc)
{
    struct irqaction *action = desc->action;
    irqreturn_t ret;

```
desc->istate &= ~IRQS_PENDING;--------------------------清除IRQS_PENDING标志位
irqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);---------设置IRQD_IRQ_INPROGRESS标志位，表示正在处理硬件中断。
raw_spin_unlock(&desc->lock);

ret = handle_irq_event_percpu(desc, action);

raw_spin_lock(&desc->lock);
irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);-------清除IRQD_IRQ_INPROGRESS标志位，表示中断处理结束。
return ret;
```

}

irqreturn_t
handle_irq_event_percpu(struct irq_desc *desc, struct irqaction *action)
{
    irqreturn_t retval = IRQ_NONE;
    unsigned int flags = 0, irq = desc->irq_data.irq;

```
do {----------------------------------------------------遍历中断描述符中的action链表，依次执行每个action元素中的primary handler回调函数action->handler。
    irqreturn_t res;

    trace_irq_handler_entry(irq, action);
    res = action->handler(irq, action->dev_id);---------执行struct irqaction的handler函数。
    trace_irq_handler_exit(irq, action, res);

    if (WARN_ONCE(!irqs_disabled(),"irq %u handler %pF enabled interrupts\n",
              irq, action->handler))
        local_irq_disable();---------------------------

    switch (res) {
    case IRQ_WAKE_THREAD:-------------------------------去唤醒内核中断线程
        /*
         * Catch drivers which return WAKE_THREAD but
         * did not set up a thread function
         */
        if (unlikely(!action->thread_fn)) {
            warn_no_thread(irq, action);----------------输出一个打印表示没有中断处理函数
            break;
        }

        __irq_wake_thread(desc, action);----------------唤醒此中断对应的内核线程

        /* Fall through to add to randomness */
    case IRQ_HANDLED:-----------------------------------已经处理完毕，可以结束。
        flags |= action->flags;
        break;

    default:
        break;
    }

    retval |= res;
    action = action->next;
} while (action);

add_interrupt_randomness(irq, flags);

if (!noirqdebug)
    note_interrupt(irq, desc, retval);
return retval;
```

}
~~~

##### 4.3.1 唤醒中断内核线程

~~~c
__irq_wake_thread唤醒对应中断的内核线程。

void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)
{
    /*
     * In case the thread crashed and was killed we just pretend that
     * we handled the interrupt. The hardirq handler has disabled the
     * device interrupt, so no irq storm is lurking.
     */
    if (action->thread->flags & PF_EXITING)
        return;

```
/*
 * Wake up the handler thread for this action. If the
 * RUNTHREAD bit is already set, nothing to do.
 */
if (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))--------------若已经对IRQF_RUNTHREAD置位，表示已经处于唤醒中，该函数直接返回。
    return;

desc->threads_oneshot |= action->thread_mask;--------------------thread_mask在共享中断中，每一个action有一个比特位来表示。thread_oneshot每个比特位表示正在处理的共享oneshot类型中断的中断线程。

atomic_inc(&desc->threads_active);-------------------------------活跃中断线程计数

wake_up_process(action->thread);---------------------------------唤醒action的thread内核线程
```

}
~~~

##### 4.3.2 创建内核中断线程

irq_thread在中断注册的时候，如果条件满足同时创建rq/xx-xx内核中断线程，线程优先级是49(99-50)，调度策略是SCHED_FIFO。

~~~c
static int
__setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
{
...
    /*
     * Create a handler thread when a thread function is supplied
     * and the interrupt does not nest into another interrupt
     * thread.
     */
    if (new->thread_fn && !nested) {
        struct task_struct *t;
        static const struct sched_param param = {
            .sched_priority = MAX_USER_RT_PRIO/2,-------------------------------设置irq内核线程的优先级，在/proc/xxx/sched中看到的prio为MAX_RT_PRIO-1-sched_priority。
        };

```
    t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
               new->name);--------------------------------------------------创建线程名为irq/xxx-xxx的内核线程，线程执行函数是irq_thread。
```

...
        sched_setscheduler_nocheck(t, SCHED_FIFO, &param);----------------------设置进程调度策略为SCHED_FIFO。

```
    /*
     * We keep the reference to the task struct even if
     * the thread dies to avoid that the interrupt code
     * references an already freed task_struct.
     */
    get_task_struct(t);
    new->thread = t;-------------------------------------------------------将当前线程和irq_action关联起来

    set_bit(IRQTF_AFFINITY, &new->thread_flags);--------------------------对中断线程设置CPU亲和性
}
```

...
}
~~~

##### 4.3.3 内核中断线程执行

irq_thread是中断线程的执行函数，在irq_wait_for_interrupt()中等待。

irq_wait_for_interrupt()中判断IRQTF_RUNTHREAD标志位，没有置位则schedule()换出CPU，进行睡眠。

直到__irq_wake_thread()置位了IRQTF_RUNTHREAD，并且wake_up_process()后，irq_wait_for_interrupt()返回0。

~~~c
static int irq_thread(void *data)
{
    struct callback_head on_exit_work;
    struct irqaction *action = data;
    struct irq_desc *desc = irq_to_desc(action->irq);
    irqreturn_t (*handler_fn)(struct irq_desc *desc,
            struct irqaction *action);

```
if (force_irqthreads && test_bit(IRQTF_FORCED_THREAD,
                &action->thread_flags))
    handler_fn = irq_forced_thread_fn;
else
    handler_fn = irq_thread_fn;

init_task_work(&on_exit_work, irq_thread_dtor);
task_work_add(current, &on_exit_work, false);

irq_thread_check_affinity(desc, action);

while (!irq_wait_for_interrupt(action)) {
    irqreturn_t action_ret;

    irq_thread_check_affinity(desc, action);

    action_ret = handler_fn(desc, action);-----------执行中断内核线程函数
    if (action_ret == IRQ_HANDLED)
        atomic_inc(&desc->threads_handled);----------增加threads_handled计数

    wake_threads_waitq(desc);------------------------唤醒wait_for_threads等待队列
}

/*
 * This is the regular exit path. __free_irq() is stopping the
 * thread via kthread_stop() after calling
 * synchronize_irq(). So neither IRQTF_RUNTHREAD nor the
 * oneshot mask bit can be set. We cannot verify that as we
 * cannot touch the oneshot mask at this point anymore as
 * __setup_irq() might have given out currents thread_mask
 * again.
 */
task_work_cancel(current, irq_thread_dtor);
return 0;
```

}

static int irq_wait_for_interrupt(struct irqaction *action)
{
    set_current_state(TASK_INTERRUPTIBLE);

```
while (!kthread_should_stop()) {

    if (test_and_clear_bit(IRQTF_RUNTHREAD,
                   &action->thread_flags)) {------------判断thread_flags是否设置IRQTF_RUNTHREAD标志位，如果设置则设置当前状态TASK_RUNNING并返回0。此处和__irq_wake_thread中设置IRQTF_RUNTHREAD对应。
        __set_current_state(TASK_RUNNING);
        return 0;
    }
    schedule();-----------------------------------------换出CPU，在此等待睡眠
    set_current_state(TASK_INTERRUPTIBLE);
}
__set_current_state(TASK_RUNNING);
return -1;
```

}

static irqreturn_t irq_thread_fn(struct irq_desc *desc,
        struct irqaction *action)
{
    irqreturn_t ret;

```
ret = action->thread_fn(action->irq, action->dev_id);---执行中断内核线程函数，为request_threaded_irq注册中断参数thread_fn。
irq_finalize_oneshot(desc, action);---------------------针对oneshot类型中断收尾处理，主要是去屏蔽中断。
return ret;
```

}
~~~

irq_finalize_oneshot()对ontshot类型的中断进行收尾操作。

~~~c
static void irq_finalize_oneshot(struct irq_desc *desc,
                 struct irqaction *action)
{
    if (!(desc->istate & IRQS_ONESHOT) ||
        action->handler == irq_forced_secondary_handler)
        return;
again:
    chip_bus_lock(desc);
    raw_spin_lock_irq(&desc->lock);

```
/*
 * Implausible though it may be we need to protect us against
 * the following scenario:
 *
 * The thread is faster done than the hard interrupt handler
 * on the other CPU. If we unmask the irq line then the
 * interrupt can come in again and masks the line, leaves due
 * to IRQS_INPROGRESS and the irq line is masked forever.
 *
 * This also serializes the state of shared oneshot handlers
 * versus "desc->threads_onehsot |= action->thread_mask;" in
 * irq_wake_thread(). See the comment there which explains the
 * serialization.
 */
if (unlikely(irqd_irq_inprogress(&desc->irq_data))) {-----------必须等待硬件中断处理程序清除IRQD_IRQ_INPROGRESS标志位，见handle_irq_event()。因为该标志位表示硬件中断处理程序正在处理硬件中断，直到硬件中断处理完毕才会清除该标志。
    raw_spin_unlock_irq(&desc->lock);
    chip_bus_sync_unlock(desc);
    cpu_relax();
    goto again;
}

/*
 * Now check again, whether the thread should run. Otherwise
 * we would clear the threads_oneshot bit of this thread which
 * was just set.
 */
if (test_bit(IRQTF_RUNTHREAD, &action->thread_flags))
    goto out_unlock;

desc->threads_oneshot &= ~action->thread_mask;

if (!desc->threads_oneshot && !irqd_irq_disabled(&desc->irq_data) &&
    irqd_irq_masked(&desc->irq_data))
    unmask_threaded_irq(desc);----------------------------------执行EOI或者去中断屏蔽。
```

out_unlock:
    raw_spin_unlock_irq(&desc->lock);
    chip_bus_sync_unlock(desc);
}
~~~

至此一个中断的执行完毕。 

#### 4.4 如何保证IRQS_ONESHOT不嵌套？

### 5. 注册中断

#### 5.1 中断、线程、中断线程化

 中断处理程序包括上半部硬件中断处理程序，下半部处理机制，包括软中断、tasklet、workqueue、中断线程化。

当一个外设中断发生后，内核会执行一个函数来响应该中断，这个函数通常被称为中断处理程序或中断服务例程。

上半部硬件中断处理运行在中断上下文中，要求快速完成并且退出中断。

 

中断线程化是实时Linux项目开发的一个新特性，目的是降低中断处理对系统实时延迟的影响。

在LInux内核里，中断具有最高优先级，只要有中断发生，内核会暂停手头的工作转向中断处理，等到所有挂起等待的中断和软终端处理完毕后才会执行进程调度，因此这个过程会造成实时任务得不到及时处理。

中断上下文总是抢占进程上下文，中断上下文不仅是中断处理程序，还包括softirq、tasklet等，中断上下文成了优化Linux实时性的最大挑战之一。

#### 5.2 中断注册接口

IRQF_*描述的中断标志位用于[request_threaded_irq()](https://www.cnblogs.com/arnoldlu/p/8659981.html#request_threaded_irq)申请中断时描述该中断的特性。

IRQS_*的中断标志位是位于struct irq_desc数据结构的istate成员，也即[core_internal_state__do_not_mess_with_it](https://www.cnblogs.com/arnoldlu/p/8659981.html#core_internal_state__do_not_mess_with_it)。

IRQD_*是struct irq_data数据结构中的[state_use_accessors](https://www.cnblogs.com/arnoldlu/p/8659981.html#state_use_accessors)成员一组中断标志位，通常用于描述底层中断状态。

关于IRQF_ONESHOT特别解释：必须在硬件中断处理结束之后才能重新使能中断；线程化中断处理过程中保持中断线处于关闭状态，直到该中断线上所有thread_fn执行完毕。

```c
#define IRQF_TRIGGER_NONE    0x00000000
#define IRQF_TRIGGER_RISING    0x00000001---------------------------上升沿触发
#define IRQF_TRIGGER_FALLING    0x00000002--------------------------下降沿触发
#define IRQF_TRIGGER_HIGH    0x00000004-----------------------------高电平触发
#define IRQF_TRIGGER_LOW    0x00000008------------------------------地电平触发
#define IRQF_TRIGGER_MASK    (IRQF_TRIGGER_HIGH | IRQF_TRIGGER_LOW | \
                 IRQF_TRIGGER_RISING | IRQF_TRIGGER_FALLING)--------四种触发类型
#define IRQF_TRIGGER_PROBE    0x00000010

#define IRQF_SHARED        0x00000080-------------------------------多个设备共享一个中断号
#define IRQF_PROBE_SHARED    0x00000100-----------------------------中断处理程序允许sharing mismatch发生
#define __IRQF_TIMER        0x00000200------------------------------标记一个时钟中断
#define IRQF_PERCPU        0x00000400-------------------------------属于某个特定CPU的中断
#define IRQF_NOBALANCING    0x00000800------------------------------禁止在多CPU之间做中断均衡
#define IRQF_IRQPOLL        0x00001000------------------------------中断被用作轮询
#define IRQF_ONESHOT        0x00002000------------------------------一次性触发中断，不允许嵌套。
#define IRQF_NO_SUSPEND        0x00004000---------------------------在系统睡眠过程中不要关闭该中断
#define IRQF_FORCE_RESUME    0x00008000-----------------------------在系统唤醒过程中必须抢孩子打开该中断
#define IRQF_NO_THREAD        0x00010000----------------------------表示该中断不会给线程化
#define IRQF_EARLY_RESUME    0x00020000
#define IRQF_COND_SUSPEND    0x00040000

#define IRQF_TIMER        (__IRQF_TIMER | IRQF_NO_SUSPEND | IRQF_NO_THREAD)

enum {
    IRQS_AUTODETECT        = 0x00000001,-------------------处于自动侦测状态
    IRQS_SPURIOUS_DISABLED    = 0x00000002,----------------被视为“伪中断”并被禁用
    IRQS_POLL_INPROGRESS    = 0x00000008,------------------正处于轮询调用action
    IRQS_ONESHOT        = 0x00000020,----------------------表示只执行一次，由IRQF_ONESHOT转换而来，在中断线程化执行完成后需要小心对待，见irq_finalize_oneshot()。
    IRQS_REPLAY        = 0x00000040,-----------------------重新发送一次中断
    IRQS_WAITING        = 0x00000080,----------------------处于等待状态
    IRQS_PENDING        = 0x00000200,----------------------该中断被挂起
    IRQS_SUSPENDED        = 0x00000800,--------------------该中断被暂停
};

enum {
    IRQD_TRIGGER_MASK        = 0xf,-------------------------该中断触发类型
    IRQD_SETAFFINITY_PENDING    = (1 <<  8),
    IRQD_NO_BALANCING        = (1 << 10),
    IRQD_PER_CPU            = (1 << 11),
    IRQD_AFFINITY_SET        = (1 << 12),
    IRQD_LEVEL            = (1 << 13),
    IRQD_WAKEUP_STATE        = (1 << 14),
    IRQD_MOVE_PCNTXT        = (1 << 15),
    IRQD_IRQ_DISABLED        = (1 << 16),--------------------该中断处于关闭状态
    IRQD_IRQ_MASKED            = (1 << 17),------------------该中断被屏蔽中
    IRQD_IRQ_INPROGRESS        = (1 << 18),------------------该中断正在被处理中
    IRQD_WAKEUP_ARMED        = (1 << 19),
    IRQD_FORWARDED_TO_VCPU        = (1 << 20),
};
```

struct irqaction是每个中断的irqaction描述符。

```c
struct irqaction {
    irq_handler_t        handler;-----------primary handler函数指针
    void            *dev_id;----------------传递给中断处理程序的参数
    void __percpu        *percpu_dev_id;
    struct irqaction    *next;
    irq_handler_t        thread_fn;---------中断线程处理程序的函数指针
    struct task_struct    *thread;----------中断线程的task_struct数据结构
    unsigned int        irq;----------------Linux软件中断号
    unsigned int        flags;--------------注册中断时用的中断标志位，IRQF_*。
    unsigned long        thread_flags;------中断线程相关标志位
    unsigned long        thread_mask;-------在共享中断中，每一个action有一个比特位来表示。
    const char        *name;----------------中断线程名称
    struct proc_dir_entry    *dir;
} ____cacheline_internodealigned_in_smp;
```

request_irq调用request_threaded_irq进行中断注册，只是少了一个thread_fn参数。这也是两则的区别所在，request_irq不能注册线程化中断。

irq：Linux软件中断号，不是硬件中断号。

handler：指primary handler，也即request_irq的中断处理函数handler。

thread_fn：中断线程化的处理函数。

irqflags：中断标志位，见IRQF_*解释。

devname：中断名称。

dev_id：传递给中断处理程序的参数。

handler和thread_fn分别被赋给action->handler和action->thread_fn，组合如下：

|      | handler | thread_fn |                                        |
| ---- | ------- | --------- | -------------------------------------- |
| 1    | √       | √         | 先执行handler，然后条件执行thread_fn。 |
| 2    | √       | ×         | 等同于request_irq()                    |
| 3    | ×       | √         | handler=irq_default_primary_handler    |
| 4    | ×       | ×         | 返回-EINVAL                            |

很多request_threaded_irq()使用第3种组合，irq_default_primary_handler()返回IRQ_WAKE_THREAD，将工作交给thread_fn进行处理。

第2种组合相当于request_irq()。

第4种组合不被允许，因为中断得不到任何处理。

第1种组合较复杂，在handler根据实际情况返回IRQ_WAKE_THREAD(唤醒内核中断线程)或者IRQ_HANDLED(中断已经处理完毕，不需要唤醒中断内核线程)。

request_threaded_irq()对参数进行检查之后，分配struct irqaction并填充，然后将注册工作交给__setup_irq()。

```
static inline int __must_check
request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,
        const char *name, void *dev)
{
    return request_threaded_irq(irq, handler, NULL, flags, name, dev);
}

int request_threaded_irq(unsigned int irq, irq_handler_t handler,
             irq_handler_t thread_fn, unsigned long irqflags,
             const char *devname, void *dev_id)
{
...
    if (((irqflags & IRQF_SHARED) && !dev_id) ||-----------------------------共享中断设备必须传递啊dev_id参数来区分是哪个共享外设的中断
        (!(irqflags & IRQF_SHARED) && (irqflags & IRQF_COND_SUSPEND)) ||
        ((irqflags & IRQF_NO_SUSPEND) && (irqflags & IRQF_COND_SUSPEND)))
        return -EINVAL;

​```
desc = irq_to_desc(irq);--------------------------------------------------通过Linux中断号找到对应中断描述符struct irq_desc。
if (!desc)
    return -EINVAL;
​```

...
    if (!handler) {
        if (!thread_fn)
            return -EINVAL;---------------------------------------------------handler和thread_fn不能同时为NULL
        handler = irq_default_primary_handler;--------------------------------没有设置handler，irq_default_primary_handler()默认返回IRQ_WAKE_THREAD。
    }

​```
action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);-------------------分配struct irqaction，并填充相应成员
if (!action)
    return -ENOMEM;

action->handler = handler;
action->thread_fn = thread_fn;
action->flags = irqflags;
action->name = devname;
action->dev_id = dev_id;

chip_bus_lock(desc);-------------------------------------------------------调用desc->irq_data.chip->irq_bus_lock()进行加锁保护
retval = __setup_irq(irq, desc, action);
chip_bus_sync_unlock(desc);

if (retval)
    kfree(action);
​```

...
    return retval;
}
```

#### 5.3 __setup_irq

**一张图**

 __setup_irq()首先做参数检查，然后根据需要创建中断内核线程，这期间处理中断嵌套、oneshot、中断共享等问题。

还设置了中断触发类型设置，中断使能等工作。最后根据需要唤醒中断内核线程，并创建此中断相关sysfs节点。

 * ~~~c
    /*
    ~~~

- Internal function to register an irqaction - typically used to

    - allocate special interrupts that are part of the architecture.
      */
      static int
      __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
  {
      struct irqaction *old, **old_ptr;
      unsigned long flags, thread_mask = 0;
  int ret, nested, shared = 0;
      cpumask_var_t mask;
    
      if (!desc)
          return -EINVAL;

      if (desc->irq_data.chip == &no_irq_chip)----------------------表示没有正确初始化中断控制器，对于GICv2在gic_irq_domain_alloc()中指定chip为gic_chip。
          return -ENOSYS;
      if (!try_module_get(desc->owner))
          return -ENODEV;
    
      /*
    
      - Check whether the interrupt nests into another interrupt
      - thread.
        */
        nested = irq_settings_is_nested_thread(desc);-----------------对于设置了_IRQ_NESTED_THREAD嵌套类型的中断描述符，必须指定thread_fn。
        if (nested) {
        if (!new->thread_fn) {
            ret = -EINVAL;
            goto out_mput;
        }
        /*
        - Replace the primary handler which was provided from
        - the driver for non nested interrupt handling by the
        - dummy function which warns when called.
        */
          new->handler = irq_nested_primary_handler;
          } else {
          if (irq_settings_can_thread(desc))-----------------------判断该中断是否可以被线程化，如果没有设置_IRQ_NOTHREAD表示可以被强制线程化。
          irq_setup_forced_threading(new);
          }
    
      /*
    
      - Create a handler thread when a thread function is supplied
    
  - and the interrupt does not nest into another interrupt
    
      - thread.
        */
        if (new->thread_fn && !nested) {-----------------------------对不支持嵌套的线程化中断创建一个内核线程，实时SCHED_FIFO，优先级为50的实时线程。
        struct task_struct *t;
        static const struct sched_param param = {
        .sched_priority = MAX_USER_RT_PRIO/2,
        };

        t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
                   new->name);-----------------------------------由irq、中断号、中断名组成的中断线程名，处理函数是irq_thread()。
    if (IS_ERR(t)) {
            ret = PTR_ERR(t);
            goto out_mput;
    }
    
        sched_setscheduler_nocheck(t, SCHED_FIFO, &param);
    
        get_task_struct(t);
    new->thread = t;
    
        set_bit(IRQTF_AFFINITY, &new->thread_flags);
        }
    
      if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {
          ret = -ENOMEM;
          goto out_thread;
      }
    
      /*
    
  - Drivers are often written to work w/o knowledge about the
      - underlying irq chip implementation, so a request for a
      - threaded irq without a primary hard irq context handler
      - requires the ONESHOT flag to be set. Some irq chips like
      - MSI based interrupts are per se one shot safe. Check the
  - chip flags, so we can avoid the unmask dance at the end of
      - the threaded handler for those.
        */
        if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)----------表示该中断控制器不支持中断嵌套，所以flags去掉IRQF_ONESHOT。
        new->flags &= ~IRQF_ONESHOT;
      
      
      raw_spin_lock_irqsave(&desc->lock, flags);
      old_ptr = &desc->action;
      old = *old_ptr;
      if (old) {-----------------------------------------------------old指向desc->action指向的链表，old不为空说明已经有中断添加到中断描述符irq_desc中，说明这是一个共享中断。shared=1。
      ...
          /* add new interrupt at end of irq queue */
          do {
              /*
           * Or all existing action->thread_mask bits,
               * so we can find the next zero bit for this
               * new action.
               */
              thread_mask |= old->thread_mask;
              old_ptr = &old->next;
              old = *old_ptr;
          } while (old);
          shared = 1;
    }
      
    /*
      
    - Setup the thread mask for this irqaction for ONESHOT. For
    
  - !ONESHOT irqs the thread mask is 0 so we can avoid a
    
  - conditional in irq_wake_thread().
        */
        if (new->flags & IRQF_ONESHOT) {
    /*
    
        - Unlikely to have 32 resp 64 irqs sharing one line,
        - but who knows.
          */
          if (thread_mask == ~0UL) {
      ret = -EBUSY;
          goto out_mask;
          }
    
        new->thread_mask = 1 << ffz(thread_mask);
    
      } else if (new->handler == irq_default_primary_handler &&---------非IRQF_ONESHOT类型中断，且handler使用默认irq_default_primary_handler(),如果中断触发类型是LEVEL，如果中断出发后不清中断容易引发中断风暴。提醒驱动开发者，没有primary handler且中断控制器不支持硬件oneshot，必须显式指定IRQF_ONESHOT表示位。
           !(desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)) {
  
      ```
  pr_err("Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
             irq);
      ret = -EINVAL;
      goto out_mask;
    ```
  
      }
    
      if (!shared) {-------------------------------------------------非共享中断情况
      ret = irq_request_resources(desc);
          if (ret) {
              pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
                     new->name, irq, desc->irq_data.chip->name);
          goto out_mask;
          }
    
      ```
      init_waitqueue_head(&desc->wait_for_threads);
  
      /* Setup the type (level, edge polarity) if configured: */
      if (new->flags & IRQF_TRIGGER_MASK) {
      ret = __irq_set_trigger(desc, irq,-------------------调用gic_chip->irq_set_type设置中断触发类型。
                  new->flags & IRQF_TRIGGER_MASK);
      
          if (ret)
              goto out_mask;
      }
  
      desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
                IRQS_ONESHOT | IRQS_WAITING);
      irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);---------清IRQD_IRQ_INPROGRESS标志位
      
      if (new->flags & IRQF_PERCPU) {
      irqd_set(&desc->irq_data, IRQD_PER_CPU);
          irq_settings_set_per_cpu(desc);
      }
  
      if (new->flags & IRQF_ONESHOT)
      desc->istate |= IRQS_ONESHOT;
      
      ```
  
  if (irq_settings_can_autoenable(desc))
          irq_startup(desc, true);
      else
      /* Undo nested disables: */
          desc->depth = 1;
  
      /* Exclude IRQ from balancing if requested */
      if (new->flags & IRQF_NOBALANCING) {
          irq_settings_set_no_balancing(desc);
      irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
      }
      
      /* Set default affinity mask once everything is setup */
      setup_affinity(irq, desc, mask);
      ```
        
      } else if (new->flags & IRQF_TRIGGER_MASK) {
      ..
  }
  
  new->irq = irq;
      *old_ptr = new;
  
      irq_pm_install_action(desc, new);
        
      /* Reset broken irq detection when installing new handler */
      desc->irq_count = 0;
  desc->irqs_unhandled = 0;
  
      /*
        
      - Check whether we disabled the irq via the spurious handler
  - before. Reenable it and give it another chance.
        */
    if (shared && (desc->istate & IRQS_SPURIOUS_DISABLED)) {
  desc->istate &= ~IRQS_SPURIOUS_DISABLED;
     __enable_irq(desc, irq);
   }
  
 raw_spin_unlock_irqrestore(&desc->lock, flags);
  
   /*
  
   - Strictly no need to wake it up, but hung_task complains
   - when no hard interrupt wakes the thread up.
   */
     if (new->thread)
     wake_up_process(new->thread);------------------------------如果该中断被线程化，那么就唤醒该内核线程。这里每个中断对应一个线程。
  
   register_irq_proc(irq, desc);----------------------------------创建/proc/irq/xxx/目录及其节点。
 new->dir = NULL;
   register_handler_proc(irq, new);-------------------------------以action->name创建目录
   free_cpumask_var(mask);
  
   return 0;
   ...
   }
 ~~~
 
 irq_setup_forced_threading()判断是否强制当前中断线程化，然后对thread_flags置位IRQTF_FORCED_THREAD表示此中断被强制线程化。
 
 将原来的primary handler弄到中断线程中去执行，原来的primary handler换成irq_default_primary_handler。
 
 并设置secondary的primary handler指向irq_forced_secondary_handler()，原来的thread_fn移到secondary的中线程中执行。
 
 ~~~c
 static int irq_setup_forced_threading(struct irqaction *new)
   {
       if (!force_irqthreads)---------------------------------------------如果内核启动参数包含threadirqs，则支持强制线程化。或者CONFIG_PREEMPT_RT_BASE实时补丁打开，这里也强制线程化。
           return 0;
       if (new->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))----和线程化矛盾的标志位。
           return 0;
 
   ```
   new->flags |= IRQF_ONESHOT;----------------------------------------强制线程化的中断都置位IRQF_ONESHOT。
   
   if (new->handler != irq_default_primary_handler && new->thread_fn) {
       /* Allocate the secondary action */
       new->secondary = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
       if (!new->secondary)
           return -ENOMEM;
       new->secondary->handler = irq_forced_secondary_handler;
       new->secondary->thread_fn = new->thread_fn;
       new->secondary->dev_id = new->dev_id;
       new->secondary->irq = new->irq;
       new->secondary->name = new->name;
   }
   /* Deal with the primary handler */
   set_bit(IRQTF_FORCED_THREAD, &new->thread_flags);
   new->thread_fn = new->handler;
   new->handler = irq_default_primary_handler;
   return 0;
   ```
 
   }
 
 ## 
 ~~~

 setup_irq()、request_threaded_irq()、request_irq()都是对__setup_irq()的包裹。

 request_irq()调用request_threaded_irq()，只是少了thread_fn。

 request_thraded_irq()和setup_irq()的区别在于，setup_irq()入参是struct irqaction ，而request_threaded_irq()在内部组装struct irqaction。

### 6.一个中断的生命

经过上面的分析可以看出一个中断从产生、执行，到最终结束的流程。这里我们用树形代码路径来简要分析一下一个中断的生命周期。

> vector_irq()->vector_irq()->__irq_svc()
>
>   ->svc_entry()--------------------------------------------------------------------------保护中断现场
>
>   ->irq_handler()->gic_handle_irq()------------------------------------------------具体到GIC中断控制器对应的就是gic_handle_irq()，此处从架构相关进入了GIC相关处理。
>
> ​    ->GIC_CPU_INTACK--------------------------------------------------------------读取IAR寄存器，响应中断。
>
> ​    ->handle_domain_irq()
>
> ​      ->irq_enter()------------------------------------------------------------------------进入硬中断上下文
>
> ​      ->generic_handle_irq()
>
> ​        ->generic_handle_irq_desc()->handle_fasteoi_irq()--------------------根据中断号分辨不同类型的中断，对应不同处理函数，这里中断号取大于等于32。
>
> ​          ->handle_irq_event()->handle_irq_event_percpu()
>
> ​            ->action->handler()-----------------------------------------------------------对应到特定中断的处理函数，即**上半部**。
>
> ​              ->__irq_wake_thread()-----------------------------------------------------如果中断函数处理返回IRQ_WAKE_THREAD，则唤醒中断线程进行处理，但不是立即执行中断线程。
>
> ​      ->irq_exit()---------------------------------------------------------------------------退出硬中断上下文。视情况处理软中断。
>
> ​        ->invoke_softirq()-----------------------------------------------------------------处理**软中断**，超出一定条件任务就会交给软中断线程处理。
>
> ​    ->GIC_CPU_EOI--------------------------------------------------------------------写EOI寄存器，表示结束中断。至此GIC才会接收新的硬件中断，此前一直是屏蔽硬件中断的。
>
>   ->svc_exit-------------------------------------------------------------------------------恢复中断现场

 从上面的分析可以看出：

- 中断上半部的处理是关硬件中断的，这里的关硬件中断是GIC就不接收中断处理。直到写EOI之后，GIC仲裁单元才会重新选择中断进行处理。
- 软中断运行于软中断上下文中，但是仍然是关硬件中断的，这里需要特别注意，软中断需要快速处理并且不能睡眠。
- 不是所有软中断都运行于软中断上下文中，部分软中断任务可能会交给ksoftirqd线程处理。
- 包括IRQ_WAKE_THREAD、ksoftirqd、woker等唤醒线程的情况，都不会在中断上下文中进行处理。中断上下文中所做的处理只是唤醒，执行时机交给系统调度。
- 如果要提高Linux实时性，有两个要点：一是将上半部线程化；另一个是将软中断都交给ksoftirqd线程处理。

## 三：软中断和tasklet

关键词：TASKLET_SOFTIRQ、HI_SOFTIRQ、softirq_action、ksoftirqd、tasklet、BH。

 

软中断以及基于软中断的tasklet、工作队列，包括中断线程化都属于下半部机制，为什么需要下半部机制呢？

1.硬件中断处理程序以异步方式执行，会打断其它重要代码执行，因此为了避免打断事件太久，硬件中断程序需要尽快执行完成。

2.硬件中断处理程序通常在关中断情况下执行，即关闭了本地CPU所有中断响应。关中断之后，本地CPU不能再响应中断，因此硬件中断处理程序必须尽快执行完成。

### 1. SoftIRQ软中断

#### 1.1 软中断数据结构

软中断是预留给系统中对时间要求最为严格最重要的下半部使用的，系统静态定义了若干软终端类型，并且Linux内核开发者不希望用户扩充新的软终端类型。

这里的优先级对应在[__do_softirq()](https://www.cnblogs.com/arnoldlu/p/8659986.html#do_softirq__)中执行action的顺序，低位优先得到执行。

~~~c
enum
{
    HI_SOFTIRQ=0,------------------------最高优先级的软中断类型
    TIMER_SOFTIRQ,-----------------------Timer定时器软中断
    NET_TX_SOFTIRQ,----------------------发送网络数据包软中断
    NET_RX_SOFTIRQ,----------------------接收网络数据包软中断
    BLOCK_SOFTIRQ,
    BLOCK_IOPOLL_SOFTIRQ,----------------块设备软中断
    TASKLET_SOFTIRQ,---------------------专门为tasklet机制准备的软中断
    SCHED_SOFTIRQ,-----------------------进程调度以及负载均衡软中断
    HRTIMER_SOFTIRQ,---------------------高精度定时器软中断
    RCU_SOFTIRQ,    /* Preferable RCU should always be the last softirq */----RCU服务软中断

```
NR_SOFTIRQS
```

};
~~~

struct softirq_action数据结构用于描述软中断，并且定义了[softirq_vec[\]](https://www.cnblogs.com/arnoldlu/p/8659986.html#softirq_vec)来表示每一个软中断对应的描述符，软中断所以号就是该数组的索引。

NR_SOFTIRQS是系统支持的软中断最大数量。

__cacheline_aligned_in_smp用于将softirq_vec数据结构和L1缓存行对齐。

```c
struct softirq_action
{
    void    (*action)(struct softirq_action *);----------------------只有一个action函数指针，当触发了该软中断，就会调用action回调函数来处理这个软中断。
};

static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
```

irq_cpustat_t用来描述软件中断状态信息，可以理解为“软中断状态寄存器”，其实是一个unsigned int类型变量__softirq_pending。

irq_cpustat_t irq_stat[NR_CPUS]相当于每个CPU有一个软中断状态信息变量。

local_softirq_pending()读取当前CPU软中断状态，如果不为0说明有软中断未处理。

or_softirq_pending()用于设置当前CPU的特定软中断处于pending状态，在__raise_softirq_irqoff()中设置。

set_softirq_pending()可以个整个CPU软中断状态复位，常在__do_softirq()函数中执行。四：workqueue工作队列

```
typedef struct {
    unsigned int __softirq_pending;
} ____cacheline_aligned irq_cpustat_t;

extern irq_cpustat_t irq_stat[];        /* defined in asm/hardirq.h */
#define __IRQ_STAT(cpu, member)    (irq_stat[cpu].member)

  /* arch independent irq_stat fields */
#define local_softirq_pending() \
    __IRQ_STAT(smp_processor_id(), __softirq_pending)----------------------获取当前CPU的软中断状态

#define set_softirq_pending(x) (local_softirq_pending() = (x))
#define or_softirq_pending(x)  (local_softirq_pending() |= (x))
```

#### 1.2 软中断注册和触发

通过调用[open_softirq()](https://www.cnblogs.com/arnoldlu/p/8659986.html#open_softirq)函数可以注册一个软中断，其中参数nr是软中断的序号。

```C
void open_softirq(int nr, void (*action)(struct softirq_action *))
{
    softirq_vec[nr].action = action;
}
```

[raise_softirq()](https://www.cnblogs.com/arnoldlu/p/8659986.html#raise_softirq)函数主动触发一个软中断API接口函数，首先设置__softirq_pending置软中断对应位，然后如果in_interrupt()为0，则唤醒ksoftirqd内核线程。

~~~c
/*

- This function must run with irqs disabled!
  */
  inline void raise_softirq_irqoff(unsigned int nr)
  {
  __raise_softirq_irqoff(nr);
  if (!in_interrupt())
      wakeup_softirqd();-------------------------------------如果不处于中断上下文中，则尽快执行软中断处理。
  }

void raise_softirq(unsigned int nr)
{
    unsigned long flags;

```
local_irq_save(flags);
raise_softirq_irqoff(nr);
local_irq_restore(flags);
```

}

void __raise_softirq_irqoff(unsigned int nr)
{
    trace_softirq_raise(nr);
    or_softirq_pending(1UL << nr);-----------------------------置位nr位的软中断，表示此软中断处于pending状态。
}
~~~

#### 1.3 软中断执行

软中断执行机会：

一个是在irq_exit的时候：irq_exit()->[invoke_softirq](https://www.cnblogs.com/arnoldlu/p/8659986.html#invoke_softirq)()->wakeup_softirq()->唤醒ksoftirqd内核线程

一个是在local_bh_enable的时候：[local_bh_enable](https://www.cnblogs.com/arnoldlu/p/8659986.html#local_bh_enable)()->__local_bh_enable()->do_softirq()->__do_softirq(CONFIG_PREEMPT_RT_FULL)-->wkeup_softirq(在长时间执行softirq后，启动ksoftirq)

还有一种是ksoftirqd内核线程执行函数[run_ksoftirqd](https://www.cnblogs.com/arnoldlu/p/8659986.html#run_ksoftirqd)()中调用__do_softirq()，一般有wake_up_process()唤醒。

 

软中断的执行一个重要场景是在中断退出时irq_exit()，[irq_exit()](https://www.cnblogs.com/arnoldlu/p/8659986.html#irq_exit)首先检查是否处于进程上下文中且有pending状态的软中断，然后将工作交给[invoke_softirq()](https://www.cnblogs.com/arnoldlu/p/8659986.html#invoke_softirq)。

```c
int __handle_domain_irq(struct irq_domain *domain, unsigned int hwirq,
            bool lookup, struct pt_regs *regs)
{
...
    irq_enter();
...
    irq_exit();
    set_irq_regs(old_regs);
    return ret;
}

void irq_exit(void)
{
...
    if (!in_interrupt() && local_softirq_pending())-------------------------in_interrupt()为0表示当前不处于中断上下文，处于进程上下文中。local_softirq_pending()非0，表示有pending软中断。
        invoke_softirq();
...
}

static inline void invoke_softirq(void)
{
    if (!force_irqthreads) {
        /*
         * We can safely execute softirq on the current stack if
         * it is the irq stack, because it should be near empty
         * at this stage.
         */
        __do_softirq();-----------------------------------------------------首先遍历执行处于pending状态的软中断函数；如果超出一定条件，将工作交给ksoftirqd处理。
    } else {
        wakeup_softirqd();--------------------------------------------------强制线程化情况，唤醒ksoftirqd内核线程处理。
    }
}
```

__do_softirq是软中断处理的核心，主要分为两部分。

第一部分，尽量处理pending状态的softirq函数。

第二部分，在处理完当前pending状态softirq之后，在处理过程中又产生了新的软中断，会重新restart进行处理；但如果超出一定条件，则交给ksoftirqd内核线程去处理。

~~~c
asmlinkage __visible void __do_softirq(void)
{
    unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    unsigned long old_flags = current->flags;
    int max_restart = MAX_SOFTIRQ_RESTART;
    struct softirq_action *h;
    bool in_hardirq;
    __u32 pending;
    int softirq_bit;

```
/*
 * Mask out PF_MEMALLOC s current task context is borrowed for the
 * softirq. A softirq handled such as network RX might set PF_MEMALLOC
 * again if the socket is related to swap
 */
current->flags &= ~PF_MEMALLOC;

pending = local_softirq_pending();------------------------------获取当前CPU的软中断寄存器__softirq_pending值到局部变量pending。
account_irq_enter_time(current);

__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);----------------增加preempt_count中的softirq域计数，表明当前在软中断上下文中。
in_hardirq = lockdep_softirq_start();
```

restart:
    /* Reset the pending bitmask before enabling irqs */
    set_softirq_pending(0);-----------------------------------------清除软中断寄存器__softirq_pending。

```
local_irq_enable();---------------------------------------------打开本地中断

h = softirq_vec;------------------------------------------------指向softirq_vec第一个元素，即软中断HI_SOFTIRQ对应的处理函数。

while ((softirq_bit = ffs(pending))) {--------------------------ffs()找到pending中第一个置位的比特位，返回值是第一个为1的位序号。这里的位是从低位开始，这也和优先级相吻合，低位优先得到执行。如果没有则返回0，退出循环。
    unsigned int vec_nr;
    int prev_count;

    h += softirq_bit - 1;---------------------------------------根据sofrirq_bit找到对应的软中断描述符，即软中断处理函数。

    vec_nr = h - softirq_vec;-----------------------------------软中断序号
    prev_count = preempt_count();

    kstat_incr_softirqs_this_cpu(vec_nr);

    trace_softirq_entry(vec_nr);
    h->action(h);-----------------------------------------------执行对应软中断函数
    trace_softirq_exit(vec_nr);
    if (unlikely(prev_count != preempt_count())) {
        pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
               vec_nr, softirq_to_name[vec_nr], h->action,
               prev_count, preempt_count());
        preempt_count_set(prev_count);
    }
    h++;-------------------------------------------------------h递增，指向下一个软中断
    pending >>= softirq_bit;-----------------------------------pending右移softirq_bit位
}

rcu_bh_qs();
local_irq_disable();-------------------------------------------关闭本地中断

pending = local_softirq_pending();-----------------------------再次检查是否有软中断产生，在上一次检查至此这段时间有新软中断产生。
if (pending) {
    if (time_before(jiffies, end) && !need_resched() &&
        --max_restart)-----------------------------------------再次触发软中断执行的三个条件：1.软中断处理时间不超过2jiffies，200Hz的系统对应10ms；2.当前没有有进程需要调度，即!need_resched()；3.这种循环不超过10次。
        goto restart;

    wakeup_softirqd();-----------------------------------------如果上面的条件不满足，则唤醒ksoftirq内核线程来处理软中断。
}

lockdep_softirq_end(in_hardirq);
account_irq_exit_time(current);
__local_bh_enable(SOFTIRQ_OFFSET);----------------------------减少preempt_count的softirq域计数,和前面增加计数呼应。表示这段代码处于软中断上下文。
WARN_ON_ONCE(in_interrupt());
tsk_restore_flags(current, old_flags, PF_MEMALLOC);
```

}
~~~

wakeup_softirq()首先获取当前CPU的ksoftirqd线程的task_struct。

如果当前task不处于TASK_RUNNING，则去唤醒此进程。 

~~~c
static void wakeup_softirqd(void)
{
    /* Interrupts are disabled: no need to stop preemption */
    struct task_struct *tsk = __this_cpu_read(ksoftirqd);

```
if (tsk && tsk->state != TASK_RUNNING)
    wake_up_process(tsk);
```

}
~~~

#### 1.4 ksoftirqd内核线程的创建

spawn_ksoftirqd创建于SMP初始化之前，借助smpboot_register_percpu_thread创建了每CPU内核线程ksoftirqd/xx。

~~~c
static struct notifier_block cpu_nfb = {
    .notifier_call = cpu_callback
};

static struct smp_hotplug_thread softirq_threads = {
    .store            = &ksoftirqd,
    .thread_should_run    = ksoftirqd_should_run,
    .thread_fn        = run_ksoftirqd,
    .thread_comm        = "ksoftirqd/%u",
};

static __init int spawn_ksoftirqd(void)
{
    register_cpu_notifier(&cpu_nfb);

```
BUG_ON(smpboot_register_percpu_thread(&softirq_threads));

return 0;
```

}
early_initcall(spawn_ksoftirqd);
~~~

在[smpboot_thread_fn()](https://www.cnblogs.com/arnoldlu/p/8659986.html#smpboot_thread_fn)函数中首先判断thread_should_run()，然后再决定是否需要执行thread_fn()。

此处的thread_should_run()即为[ksoftirqd_should_run](https://www.cnblogs.com/arnoldlu/p/8659986.html#ksoftirqd_should_run)()，返回1表示有softirq处于pending，那么就会执行[run_ksoftirqd](https://www.cnblogs.com/arnoldlu/p/8659986.html#run_ksoftirqd)()。

~~~c
static int
__smpboot_create_thread(struct smp_hotplug_thread *ht, unsigned int cpu)
{
...
    tsk = kthread_create_on_cpu(smpboot_thread_fn, td, cpu,
                    ht->thread_comm);
...
}

static int smpboot_thread_fn(void *data)
{
    struct smpboot_thread_data *td = data;
    struct smp_hotplug_thread *ht = td->ht;

```
while (1) {
    set_current_state(TASK_INTERRUPTIBLE);
```

...
        if (!ht->thread_should_run(td->cpu)) {
            preempt_enable_no_resched();
            schedule();
        } else {
            __set_current_state(TASK_RUNNING);
            preempt_enable();
            ht->thread_fn(td->cpu);
        }
    }
}
~~~

[run_ksoftirqd](https://www.cnblogs.com/arnoldlu/p/8659986.html#run_ksoftirqd)()在此判断是否有softirq处于pending状态，然后调用[__do_softirq](https://www.cnblogs.com/arnoldlu/p/8659986.html#do_softirq__)()处理软中断。

```c
static int ksoftirqd_should_run(unsigned int cpu)
{
    return local_softirq_pending();
}

static void run_ksoftirqd(unsigned int cpu)
{
    local_irq_disable();
    if (local_softirq_pending()) {
        /*
         * We can safely run softirq on inline stack, as we are not deep
         * in the task stack here.
         */
        __do_softirq();
        local_irq_enable();
        cond_resched_rcu_qs();
        return;
    }
    local_irq_enable();
}
```

### 2. tasklet

tasklet是利用软中断实现的一种下半部机制，本质上是一个软中断变种，运行在软中断上下文中。

#### 2.1 tasklet数据结构

struct tasklet_struct是tasklet描述符。

```c
struct tasklet_struct
{
    struct tasklet_struct *next;------------------多个tasklet串成一个链表。
    unsigned long state;--------------------------TASKLET_STATE_SCHED表示tasklet已经被调度，正准备运行；TASKLET_STATE_RUN表示tasklet正在运行中。
    atomic_t count;-------------------------------0表示tasklet处于激活状态；非0表示该tasklet被禁止，不允许执行。
    void (*func)(unsigned long);------------------该tasklet处理程序
    unsigned long data;---------------------------传递给tasklet处理函数的参数
};
```

每个CPU维护着两个tasklet链表，tasklet_vec用于普通优先级，tasklet_hi_vec用于高优先级；它们都是per-CPU变量。

```c
struct tasklet_head {
    struct tasklet_struct *head;
    struct tasklet_struct **tail;
};

static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);
```

#### 2.2 tasklet初始化

tasklet初始化在start_kernel()->[softirq_init](https://www.cnblogs.com/arnoldlu/p/8659986.html#softirq_init)()中进行，初始化tasklet_vec和tasklet_hi_vec两个链表，并注册TASKLET_SOFTIRQ和HI_SOFTIRQ两个软中断。

那么软中断TASKLET_SOFTIRQ/HI_SOFTIRQ和tasklet_vec/tasklet_hi_vec有什么关系呢？

他们通过[tasklet_action](https://www.cnblogs.com/arnoldlu/p/8659986.html#tasklet_action)()/[tasklet_hi_action](https://www.cnblogs.com/arnoldlu/p/8659986.html#tasklet_hi_action)()联系起来

~~~c
asmlinkage __visible void __init start_kernel(void)
{
...
    softirq_init();
...
}

void __init softirq_init(void)
{
    int cpu;

```
for_each_possible_cpu(cpu) {
    per_cpu(tasklet_vec, cpu).tail =
        &per_cpu(tasklet_vec, cpu).head;
    per_cpu(tasklet_hi_vec, cpu).tail =
        &per_cpu(tasklet_hi_vec, cpu).head;
}

open_softirq(TASKLET_SOFTIRQ, tasklet_action);
open_softirq(HI_SOFTIRQ, tasklet_hi_action);
```

}
~~~

两种静态初始化、一种动态初始化方法

```c
#define DECLARE_TASKLET(name, func, data) \
struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }----count初始化为0，表示tasklet处于激活状态

#define DECLARE_TASKLET_DISABLED(name, func, data) \--------------------count初始化为1，表示tasklet处于关闭状态
struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }

void tasklet_init(struct tasklet_struct *t,
          void (*func)(unsigned long), unsigned long data)
{
    t->next = NULL;
    t->state = 0;
    atomic_set(&t->count, 0);-------------------------------------------这里count为0，表示tasklet处于激活状态
    t->func = func;
    t->data = data;
}
```

#### 2.3 tasklet调度和执行

tasklet_schedule()被调用的时机大多在中断上半部中，然后将工作交给__tasklet_schedule()处理。

__tasklet_schedule()锁中断情况下插入当前taskelt到tasklet_vec中，并触发TASKLET_SOFTIRQ软中断。

tasklet_scheduler()中设置了当前tasklet的TASKLET_STATE_SCHED标志位，只要该tasklet没有被执行，那么即使驱动程序多次调用tasklet_schedule()也不起作用。

因此一旦该tasklet挂入到某个CPU的tasklet_vec后，就必须在该CPU的软中断上下文中执行，直到执行完毕并清除了TASKLET_STATE_SCHED标志位，才有机会到其他CPU上运行。

~~~c
static inline void tasklet_schedule(struct tasklet_struct *t)
{
    if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))-----------置TASKLET_STATE_SCHED位，如果原来未被置位，则调用__tasklet_schedule()。
        __tasklet_schedule(t);
}

void __tasklet_schedule(struct tasklet_struct *t)
{
    unsigned long flags;

```
local_irq_save(flags);
t->next = NULL;
*__this_cpu_read(tasklet_vec.tail) = t;-------------------------将t挂入到tasklet_vec链表中
__this_cpu_write(tasklet_vec.tail, &(t->next));
raise_softirq_irqoff(TASKLET_SOFTIRQ);
local_irq_restore(flags);
```

}
~~~

软中断执行时会按照软中断状态__softirq_pending来依次执行pending状态的软中断，当执行到TASKLET_SOFTIRQ软中断时，调用tasklet_action()。

~~~c
static void tasklet_action(struct softirq_action *a)
{
    struct tasklet_struct *list;

```
local_irq_disable();
list = __this_cpu_read(tasklet_vec.head);--------------------在关中断情况下读取tasklet_vec立案表头作为临时链表list
__this_cpu_write(tasklet_vec.head, NULL);--------------------重新初始化tasklet_vec
__this_cpu_write(tasklet_vec.tail, this_cpu_ptr(&tasklet_vec.head));
local_irq_enable();

while (list) {-----------------------------------------------开中断情况下遍历tasklet_vec链表,所以tasklet是开中断的
    struct tasklet_struct *t = list;

    list = list->next;

    if (tasklet_trylock(t)) {--------------------------------如果返回false，表示当前tasklet已经在其他CPU上运行，这一轮将会跳过此tasklet。确保同一个tasklet只能在一个CPU上运行。
        if (!atomic_read(&t->count)) {-----------------------表示当前tasklet处于激活状态
            if (!test_and_clear_bit(TASKLET_STATE_SCHED,
                        &t->state))--------------------------清TASKLET_STATE_SCHED位；如果原来没有被置位，则返回0，触发BUG()。
                BUG();
            t->func(t->data);--------------------------------执行当前tasklet处理函数
            tasklet_unlock(t);
            continue;----------------------------------------跳到while继续遍历余下的tasklet
        }
        tasklet_unlock(t);
    }

    local_irq_disable();------------------------------------此种情况说明即将要执行tasklet时，发现该tasklet已经在别的CPU上运行。
    t->next = NULL;
    *__this_cpu_read(tasklet_vec.tail) = t;-----------------把当前tasklet挂入到当前CPU的tasklet_vec中，等待下一次触发时再执行。
    __this_cpu_write(tasklet_vec.tail, &(t->next));
    __raise_softirq_irqoff(TASKLET_SOFTIRQ);----------------再次置TASKLET_SOFTIRQ位
    local_irq_enable();
}
```

}
~~~

 HI_SOFTIRQ类型的tasklet和上面基本对称，只是tasklet_vec换成了tasklet_hi_vec，TASKLET_SOFTIRQ换成了HI_SOFTIRQ。

~~~c
static inline void tasklet_hi_schedule(struct tasklet_struct *t)
{
    if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))
        __tasklet_hi_schedule(t);
}

void __tasklet_hi_schedule(struct tasklet_struct *t)
{
    unsigned long flags;

```
local_irq_save(flags);
t->next = NULL;
*__this_cpu_read(tasklet_hi_vec.tail) = t;
__this_cpu_write(tasklet_hi_vec.tail,  &(t->next));
raise_softirq_irqoff(HI_SOFTIRQ);
local_irq_restore(flags);
```

}
~~~

~~~c
static void tasklet_hi_action(struct softirq_action *a)
{
    struct tasklet_struct *list;

```
local_irq_disable();
list = __this_cpu_read(tasklet_hi_vec.head);
__this_cpu_write(tasklet_hi_vec.head, NULL);
__this_cpu_write(tasklet_hi_vec.tail, this_cpu_ptr(&tasklet_hi_vec.head));
local_irq_enable();

while (list) {
    struct tasklet_struct *t = list;

    list = list->next;

    if (tasklet_trylock(t)) {
        if (!atomic_read(&t->count)) {
            if (!test_and_clear_bit(TASKLET_STATE_SCHED,
                        &t->state))
                BUG();
            t->func(t->data);
            tasklet_unlock(t);
            continue;
        }
        tasklet_unlock(t);
    }

    local_irq_disable();
    t->next = NULL;
    *__this_cpu_read(tasklet_hi_vec.tail) = t;
    __this_cpu_write(tasklet_hi_vec.tail, &(t->next));
    __raise_softirq_irqoff(HI_SOFTIRQ);
    local_irq_enable();
}
```

}
~~~

### 3. local_bh_disable/local_bh_enable

local_bh_disable和local_bh_enable是内核中提供的关闭软中断的锁机制，它们组成临界区禁止本地CPU在中断返回前夕执行软终端，这个临界区称为BH临界区(Bottom Half critical region)。

由于local_bh_disable()和local_bh_enable()之间的区域属于软中断上下文，因此当在临界区发生了中断，中断返回前irq_exit()判断当前软中断上下文，因而不能调用和执行pending状态的软中断。

这样驱动代码构造的BH临界区，就不会有新的软中断来骚扰。

```c
static inline void local_bh_disable(void)
{
    __local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);-----------------增加softirq域计数，表示内核状态进入了软中断上下文(softirq context)
}

static __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)
{
	preempt_count_add(cnt);-----------------------------------------------增加softirq域计数
	barrier();------------------------------------------------------------防止编译器做优化
}
#define SOFTIRQ_OFFSET (1UL << SOFTIRQ_SHIFT)
#define SOFTIRQ_DISABLE_OFFSET (2 * SOFTIRQ_OFFSET)
```

local_bh_enable关闭BH临界区，并判断是否可以执行软中断处理。

~~~c
static inline void local_bh_enable(void)
{
    __local_bh_enable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);
}

void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)
{
    WARN_ON_ONCE(in_irq() || irqs_disabled());-----------------------------中断中不能构造BH临界区，irqs_disabled()返回true说明处于关中断状态，也不适合BH操作。
#ifdef CONFIG_TRACE_IRQFLAGS
    local_irq_disable();
#endif
    /*
     * Are softirqs going to be turned on now:
     */
    if (softirq_count() == SOFTIRQ_DISABLE_OFFSET)
        trace_softirqs_on(ip);
    /*
     * Keep preemption disabled until we are done with
     * softirq processing:
     */
    preempt_count_sub(cnt - 1);------计数减去SOFTIRQ_DISABLE_OFFSET-1，留1表示关闭本地CPU抢占，接下来调用do_softirq()时不希望被其他高优先级任务抢占了或者当前任务被迁移到其它CPU上。

```
if (unlikely(!in_interrupt() && local_softirq_pending())) {
    /*
     * Run softirq if any pending. And do it in its own stack
     * as we may be calling this deep in a task call stack already.
     */
    do_softirq();-------------------------------------------------------非中断上下文环境中执行软中断
}

preempt_count_dec();----------------------------------------------------打开抢占
```

#ifdef CONFIG_TRACE_IRQFLAGS
    local_irq_enable();
#endif
    preempt_check_resched();
}
~~~

local_bh_disabled()/local_bh_enable()是关BH接口API，运行在进程上下文中。

### 4. 小结 

tasklet基于softirq，但是tasklet和softirq又存在一些区别。

|        | softirq                                                      | tasklet                                                      |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 分配   | softirq是静态定义的                                          | tasklet既可以静态定义，也可以通过tasklet_init()动态创建。    |
| 并发性 | softirq是可重入的，同一类型的软中断可以在多个CPU上并发执行。 | tasklet是不可重入的，tasklet必须串行执行，同一个tasklet不可能同时在两个CPU上运行。tasklet通过TASKLET_STATE_SCHED和TASKLET_STATE_RUN保证串行 |
| 运行   | softirq运行在开中断环境下。软中断回调函数不能睡眠，因为软中断可能处于中断上下文中，睡眠导致Linux无法调度。软中断的执行时机可能在中断返回时，即退出中断上下文时。或者local_bh_enable()中。 | taskelt执行时机在softirq中                                   |



## 四：workqueue工作队列

关键词：

工作队列的原理是把work(需要推迟执行的函数)交由一个内核线程来执行，它总是在进程上下文中执行。

工作队列的优点是利用进程上下文来执行中断下半部操作，因此工作队列允许重新调度和睡眠，是异步执行的进程上下文，它还能解决软中断和tasklet执行时间过长导致系统实时性下降等问题。

 

当驱动程序或者内核子系统在进程上下文中有异步执行的工作任务时，可以使用work item来描述工作任务，包括该工作任务的执行回调函数，把work item添加到一个队列中，然后一个内核线程回去执行这个工作任务的回调函数。

这里work item被称为工作，队列被称为workqueue，即工作队列，内核线程被称为worker。

 

CMWQ(Concurrency Managed Workqueues)

执行work item任务的线程被称为worker或者工作线程。工作线程会串行化地执行挂入到队列中所有的work item。如果队列中没有work，那么该工作线程就会变成idle态。

为了管理众多工作线程，CMWQ提出了工作线程池(worker-pool)概念，worker-pool有两种：

一是bound型，可以理解为Per-CPU类型，每个CPU都有worker-pool；

另一种是unbound型，即不和具体CPU绑定。

这两种worker-pool都会定义两个线程池，一个给普通优先级的work使用，另一个给高优先级的work使用。

### 1. 初始化工作队列

#### 1.1 工作、工作队列、工作线程池、工作线程数据结构

workqueue机制最小的调度单元是[work_struct](https://www.cnblogs.com/arnoldlu/p/8659988.html#work_struct)，即工作任务。

```
struct work_struct {
    atomic_long_t data;---------------低比特位部分是work的标志位，剩余比特位通常用于存放上一次运行的worker_pool ID或pool_workqueue的指针。存放的内容有WORK_STRUCT_PWQ标志位来决定
    struct list_head entry;-----------用于把work挂到其他队列上。
    work_func_t func;-----------------工作任务的处理函数
#ifdef CONFIG_LOCKDEP
    struct lockdep_map lockdep_map;
#endif
}
```

工作队列由struct workqueue_struct数据结构描述：

~~~c
struct workqueue_struct {
    struct list_head    pwqs;        /* WR: all pwqs of this wq */--------------------该workqueue所在的所有pool_workqueue链表
    struct list_head    list;        /* PL: list of all workqueues */-----------------系统所有workqueue_struct的全局链表

```
struct mutex        mutex;        /* protects this wq */
int            work_color;    /* WQ: current work color */
int            flush_color;    /* WQ: current flush color */
atomic_t        nr_pwqs_to_flush; /* flush in progress */
struct wq_flusher    *first_flusher;    /* WQ: first flusher */
struct list_head    flusher_queue;    /* WQ: flush waiters */
struct list_head    flusher_overflow; /* WQ: flush overflow list */

struct list_head    maydays;    /* MD: pwqs requesting rescue */-------------------所有rescue状态下的pool_workqueue数据结构链表
struct worker        *rescuer;    /* I: rescue worker */---------------------------rescue内核线程，内存紧张时创建新的工作线程可能会失败，如果创建workqueue是设置了WQ_MEM_RECLAIM，那么rescuer线程会接管这种情况。

int            nr_drainers;    /* WQ: drain in progress */
int            saved_max_active; /* WQ: saved pwq max_active */

struct workqueue_attrs    *unbound_attrs;    /* WQ: only for unbound wqs */---------UNBOUND类型属性
struct pool_workqueue    *dfl_pwq;    /* WQ: only for unbound wqs */----------------unbound类型的pool_workqueue
```

#ifdef CONFIG_SYSFS
    struct wq_device    *wq_dev;    /* I: for sysfs interface */
#endif
#ifdef CONFIG_LOCKDEP
    struct lockdep_map    lockdep_map;
#endif
    char            name[WQ_NAME_LEN]; /* I: workqueue name */--------------------------该workqueue的名字

```
/* hot fields used during command issue, aligned to cacheline */
unsigned int        flags ____cacheline_aligned; /* WQ: WQ_* flags */---------------经常被不同CUP访问，因此要和cache line对齐。
struct pool_workqueue __percpu *cpu_pwqs; /* I: per-cpu pwqs */---------------------指向per-cpu类型的pool_workqueue
struct pool_workqueue __rcu *numa_pwq_tbl[]; /* FR: unbound pwqs indexed by node */
```

}
~~~

运行work_struct的内核线程被称为worker，即工作线程。

 * ```c
 /*

    - The poor guys doing the actual heavy lifting.  All on-duty workers are
    
    - either serving the manager role, on idle list or on busy hash.  For
    
    - details on the locking annotation (L, I, X...), refer to workqueue.c.
  *
    
    - Only to be used in workqueue and async.
      */
      struct worker {
      /* on idle list while idle, on busy hash table while busy */
  union {
          struct list_head    entry;    /* L: while idle */
      struct hlist_node    hentry;    /* L: while busy */
      };
    
      struct work_struct    *current_work;    /* L: work being processed */----当前正在处理的work
      work_func_t        current_func;    /* L: current_work's fn */-----------当前正在执行的work回调函数
      struct pool_workqueue    *current_pwq; /* L: current_work's pwq */-------当前work所属的pool_workqueue
  bool            desc_valid;    /* ->desc is valid */
      struct list_head    scheduled;    /* L: scheduled works */---------------所有被调度并正准备执行的work_struct都挂入该链表中
    
      /* 64 bytes boundary on 64bit, 32 on 32bit */

      struct task_struct    *task;        /* I: worker task */-----------------该工作线程的task_struct数据结构
      struct worker_pool    *pool;        /* I: the associated pool */---------该工作线程所属的worker_pool
                          /* L: for rescuers */
      struct list_head    node;        /* A: anchored at pool->workers */------可以把该worker挂入到worker_pool->workers链表中
                          /* A: runs through worker->node */

      unsigned long        last_active;    /* L: last active timestamp */
      unsigned int        flags;        /* X: flags */
  int            id;        /* I: worker id */
 
   /*
 
   - Opaque string set with work_set_desc().  Printed out with task
   - dump for debugging - WARN, BUG, panic or sysrq.
     */
     char            desc[WORKER_DESC_LEN];
 
   /* used only by rescuers to point to the target workqueue */
   struct workqueue_struct    *rescue_wq;    /* I: the workqueue to rescue */
   }
 ```
 
 CMWQ提出了工作线程池的概念，struct worker_pool数据结构用于描述工作线程池。
 
 worker_pool是per-cpu变量，每个CPU都有worker_pool，而且有两个worker_pool。
 
 一个用于普通优先级工作线程，另一个用于高优先级工作线程。
 
 ```
 struct worker_pool {
     spinlock_t        lock;        /* the pool lock */-----------------------用于保护worker_pool的自旋锁
     int            cpu;        /* I: the associated cpu */-------------------对于unbound类型为-1；对于bound类型workqueue表示绑定的CPU ID。
     int            node;        /* I: the associated node ID */
     int            id;        /* I: pool ID */-------------------------------该worker_pool的ID号
     unsigned int        flags;        /* X: flags */
 
 ​```
 struct list_head    worklist;    /* L: list of pending works */----------挂入pending状态的work_struct
 int            nr_workers;    /* L: total number of workers */-----------工作线程的数量
 
 /* nr_idle includes the ones off idle_list for rebinding */
 int            nr_idle;    /* L: currently idle ones */------------------处于idle状态的工作线程的数量
 
 struct list_head    idle_list;    /* X: list of idle workers */----------处于idle状态的工作线程链表
 struct timer_list    idle_timer;    /* L: worker idle timeout */
 struct timer_list    mayday_timer;    /* L: SOS timer for workers */
 
 /* a workers is either on busy_hash or idle_list, or the manager */
 DECLARE_HASHTABLE(busy_hash, BUSY_WORKER_HASH_ORDER);
                     /* L: hash of busy workers */
 
 /* see manage_workers() for details on the two manager mutexes */
 struct mutex        manager_arb;    /* manager arbitration */
 struct mutex        attach_mutex;    /* attach/detach exclusion */
 struct list_head    workers;    /* A: attached workers */---------------该worker_pool管理的工作线程链表
 struct completion    *detach_completion; /* all workers detached */
 
 struct ida        worker_ida;    /* worker IDs for task name */
 
 struct workqueue_attrs    *attrs;        /* I: worker attributes */-----工作线程属性
 struct hlist_node    hash_node;    /* PL: unbound_pool_hash node */
 int            refcnt;        /* PL: refcnt for unbound pools */
 
 /*
  * The current concurrency level.  As it's likely to be accessed
  * from other CPUs during try_to_wake_up(), put it in a separate
  * cacheline.
  */
 atomic_t        nr_running ____cacheline_aligned_in_smp;----------------用于管理worker的创建和销毁的统计计数，表示运行中的worker数量。该变量可能被多CPU同时访问，因此独占一个缓存行，避免多核读写造成“颠簸”现象。
 
 /*
  * Destruction of pool is sched-RCU protected to allow dereferences
  * from get_work_pool().
  */
 struct rcu_head        rcu;---------------------------------------------RCU锁
 ​```
 
 }
 ```
 
 struct pool_workqueue用于链接workqueue和worker_pool。
 
 ```
 struct pool_workqueue {
     struct worker_pool    *pool;        /* I: the associated pool */-----------指向worker_pool结构
     struct workqueue_struct *wq;        /* I: the owning workqueue */----------指向workqueue_struct结构
     int            work_color;    /* L: current color */
     int            flush_color;    /* L: flushing color */
     int            refcnt;        /* L: reference count */
     int            nr_in_flight[WORK_NR_COLORS];
                         /* L: nr of in_flight works */
     int            nr_active;    /* L: nr of active works */------------------活跃的work_strcut数量
     int            max_active;    /* L: max active works */-------------------最大活跃work_struct数量
     struct list_head    delayed_works;    /* L: delayed works */--------------延迟执行work_struct链表
     struct list_head    pwqs_node;    /* WR: node on wq->pwqs */
     struct list_head    mayday_node;    /* MD: node on wq->maydays */
 
 ​```
 /*
  * Release of unbound pwq is punted to system_wq.  See put_pwq()
  * and pwq_unbound_release_workfn() for details.  pool_workqueue
  * itself is also sched-RCU protected so that the first pwq can be
  * determined without grabbing wq->mutex.
  */
 struct work_struct    unbound_release_work;
 struct rcu_head        rcu;------------------------------------------------RCU锁
 ​```
 
 }
 ```
 
 上面几个数据结构的关系图？

#### 1.2 初始化工作队列

首先看一下对创建工作队列有重要影响的flags。

 * ```
 /*

    - Workqueue flags and constants.  For details, please refer to
    
    - Documentation/workqueue.txt.
      */
      enum {
      WQ_UNBOUND        = 1 << 1, /* not bound to any cpu */-----------------绑定到某一个CPU执行
  WQ_FREEZABLE        = 1 << 2, /* freeze during suspend */--------------在suspend进行进程冻结的时候，需要让工作线程完成当前所有的work才完成进程冻结，并且这个过程不会再新开始一个work的执行，知道进程被解冻。
      WQ_MEM_RECLAIM        = 1 << 3, /* may be used for memory reclaim */---在内存紧张导致创建新进程失败，系统通过rescuer内核线程去接管这种情况。
  WQ_HIGHPRI        = 1 << 4, /* high priority */------------------------属于高于高优先级的worker_pool
      WQ_CPU_INTENSIVE    = 1 << 5, /* cpu intensive workqueue */------------属于特别消耗CPU资源的一类work，这个work执行会得到调度器的监管，排在这类work后的non-CPU-intensive类型work可能会推迟执行
      WQ_SYSFS        = 1 << 6, /* visible in sysfs, see wq_sysfs_register() */
    
  WQ_POWER_EFFICIENT    = 1 << 7,-----------------根据wq_power_efficient来决定此类型的工作队列是bound还是unbound类型，bound型可能导致处于idle的CPU被唤醒，而unbound型则不会必然唤醒idle的CPU。
    
      __WQ_DRAINING        = 1 << 16, /* internal: workqueue is draining */
      
  __WQ_ORDERED        = 1 << 17, /* internal: workqueue is ordered */----表示同一时间只能执行一个work_item。
   __WQ_ORDERED_EXPLICIT    = 1 << 19, /* internal: alloc_ordered_workqueue() */
 
   WQ_MAX_ACTIVE        = 512,      /* I like 512, better ideas? */
   WQ_MAX_UNBOUND_PER_CPU    = 4,      /* 4 * #cpus for unbound wq */
   WQ_DFL_ACTIVE        = WQ_MAX_ACTIVE / 2,
   };
 ```
 
 内核启动的时候，调用[init_workqueues](https://www.cnblogs.com/arnoldlu/p/8659988.html#init_workqueues)()创建工作线程，同时创建了一些常用的工作队列。
 
 init_workqueues()由early_initcall(init_workqueues)在early阶段调用。

##### 1.2.1 谁？都创建了哪些工作线程？

对于4核SMP系统来说，必然创建的工作线程有：每个CPU的kworker/x:0、kworker/x:0H、以及unbound类型的kworker/u8:0。

init_workqueues()创建CPU0以及unbound工作线程

kworker/0:0和kworker/0:0H以及kworker/u8:0都是由init_workqueues创建的，调用轨迹如下。

kworker/0:0、kworker/0:0H：kernel_init()->kernel_init_freeable()->do_one_initcall()->[init_workqueues](https://www.cnblogs.com/arnoldlu/p/8659988.html#init_workqueues)()->create_worker()

 

kworker/u8:0:kernel_init()->kernel_init_freeable()->do_one_inicall->init_workqueues()->__alloc_workqueue_key()->apply_workqueue_attrs()->alloc_unbound_pwq()->create_worker()

对于unbound工作线程的创建是因为init_workqueues()中创建了一系列的workqueue，调用alloc_workqueue()->__allow_workqueue_key()->alloc_and_link_pwqs()->apply_workqueue_attrs()->alloc_unbound_pwq()导致的。

这里的init_workqueues()为什么不将CPU1~3的工作线程一起创建了？

虽然此处[init_workqueues](https://www.cnblogs.com/arnoldlu/p/8659988.html#init_workqueues)()是在do_one_initcall中执行，但是此处的do_one_initcall较特殊。

~~~c
static noinline void __init kernel_init_freeable(void)
{
...
    smp_prepare_cpus(setup_max_cpus);

```
do_pre_smp_initcalls();-------------------------------------此处调用的initcall是在__initcall_start~__initcall0_start之间的函数，也即early_initcall()。所以init_workqueues()在smp_init之前被调用。
lockup_detector_init();

smp_init();
sched_init_smp();-------------------------------------------将剩余CPU1~3进行up操作。

do_basic_setup();-------------------------------------------执行__initcall_0start之后的initcall函数
```

...
}
~~~

在初始化pool的时候，是按照possible的CPU来进行初始化的。而在创建工作线程的时候是按照online的CPU来创建的。

在init_workqueues()的时刻，CPU1~3还没有online。所以会先创建kworker/0:0、kworker/0:0H、kworker/u8:0三个工作线程。

unbound工作线程的pool->id为8也就不难理解了，因为前面4和分配个0~7。

 

workqueue_cpu_up_callback()创建了其他CPU工作线程

kernel_init()->kernel_init_freeable()->smp_init()->cpu_up()->_cpu_up()->__raw_notifier_call_chain()->[workqueue_cpu_up_callback](https://www.cnblogs.com/arnoldlu/p/8659988.html#workqueue_cpu_up_callback)()->create_worker()

在init_workqueues()开头就注册了CPU_PRI_WORKQUEUE_UP处理函数，所以在smp_init()->cpu_up()将CPU启动之后就会为每个CPU创建两个工作线程

##### 1.2.2 init_workqueues()初始化worker_pool、worker、workqueue

~~~c
static int __init init_workqueues(void)
{
    int std_nice[NR_STD_WORKER_POOLS] = { 0, HIGHPRI_NICE_LEVEL };---------------这里HIGHPRI_NICE_LEVEL为-20，对应的prio为100，是普通进程里面的最高优先级。
    int i, cpu;

```
WARN_ON(__alignof__(struct pool_workqueue) < __alignof__(long long));

pwq_cache = KMEM_CACHE(pool_workqueue, SLAB_PANIC);

cpu_notifier(workqueue_cpu_up_callback, CPU_PRI_WORKQUEUE_UP);--------------跟随CPU_UP/CPU_DOWN动态创建工作线程的接口。
hotcpu_notifier(workqueue_cpu_down_callback, CPU_PRI_WORKQUEUE_DOWN);

wq_numa_init();

/* initialize CPU pools */
for_each_possible_cpu(cpu) {------------------------------------------------遍历每个possible状态的CPU
    struct worker_pool *pool;

    i = 0;
    for_each_cpu_worker_pool(pool, cpu) {-----------------------------------每个CPU两个worker_poo，分别对应per-cpu变量cpu_worker_pool[0]和cpu_worker_pool[1]
        BUG_ON(init_worker_pool(pool));-------------------------------------初始化worker_pool
        pool->cpu = cpu;
        cpumask_copy(pool->attrs->cpumask, cpumask_of(cpu));
        pool->attrs->nice = std_nice[i++];----------------------------------设置nice值
        pool->node = cpu_to_node(cpu);

        /* alloc pool ID */
        mutex_lock(&wq_pool_mutex);
        BUG_ON(worker_pool_assign_id(pool));
        mutex_unlock(&wq_pool_mutex);
    }
}

/* create the initial worker */
for_each_online_cpu(cpu) {--------------------------------------------------遍历所有online状态CPU，对于SMP多核CPU，支队boot cpu创建了工作线程。其他CPU工作线程稍后再cpu_up中创建。
    struct worker_pool *pool;

    for_each_cpu_worker_pool(pool, cpu) {-----------------------------------使用create_worker对每个worker_pool创建两个内核线程对应cpu_worker_pool[0]和cpu_worker_pool[1]
        pool->flags &= ~POOL_DISASSOCIATED;
        BUG_ON(!create_worker(pool));
    }
}

/* create default unbound and ordered wq attrs */
for (i = 0; i < NR_STD_WORKER_POOLS; i++) {
    struct workqueue_attrs *attrs;

    BUG_ON(!(attrs = alloc_workqueue_attrs(GFP_KERNEL)));
    attrs->nice = std_nice[i];
    unbound_std_wq_attrs[i] = attrs;---------------------------------------设置Unbound类型workqueue的属性

    /*
     * An ordered wq should have only one pwq as ordering is
     * guaranteed by max_active which is enforced by pwqs.
     * Turn off NUMA so that dfl_pwq is used for all nodes.
     */
    BUG_ON(!(attrs = alloc_workqueue_attrs(GFP_KERNEL)));
    attrs->nice = std_nice[i];
    attrs->no_numa = true;
    ordered_wq_attrs[i] = attrs;-------------------------------------------设置ordered类型workqueue的属性，ordered类型workqueue同一时刻只能有一个work item在运行。
}

system_wq = alloc_workqueue("events", 0, 0);-------------------------------普通优先级bound类型工作队列system_wq
system_highpri_wq = alloc_workqueue("events_highpri", WQ_HIGHPRI, 0);------高优先级bound类型工作队列system_highpri_wq
system_long_wq = alloc_workqueue("events_long", 0, 0);---------------------
system_unbound_wq = alloc_workqueue("events_unbound", WQ_UNBOUND,----------普通优先级unbound类型工作队列system_unbound_wq
                    WQ_UNBOUND_MAX_ACTIVE);
system_freezable_wq = alloc_workqueue("events_freezable",------------------freezable类型工作队列system_freezable_wq
                      WQ_FREEZABLE, 0);
system_power_efficient_wq = alloc_workqueue("events_power_efficient",------省电类型的工作队列system_power_efficient_wq
                      WQ_POWER_EFFICIENT, 0);
system_freezable_power_efficient_wq = alloc_workqueue("events_freezable_power_efficient",
                      WQ_FREEZABLE | WQ_POWER_EFFICIENT,-------------------freezable并且省电类型的工作队列system_freezable_power_efficient_wq
                      0);
BUG_ON(!system_wq || !system_highpri_wq || !system_long_wq ||
       !system_unbound_wq || !system_freezable_wq ||
       !system_power_efficient_wq ||
       !system_freezable_power_efficient_wq);
return 0;
```

}
~~~

~~~c
static int workqueue_cpu_up_callback(struct notifier_block *nfb,
                           unsigned long action,
                           void *hcpu)
{
    int cpu = (unsigned long)hcpu;
    struct worker_pool *pool;
    struct workqueue_struct *wq;
    int pi;

```
switch (action & ~CPU_TASKS_FROZEN) {
case CPU_UP_PREPARE:
    for_each_cpu_worker_pool(pool, cpu) {
        if (pool->nr_workers)
            continue;
        if (!create_worker(pool))
            return NOTIFY_BAD;
    }
    break;

case CPU_DOWN_FAILED:
case CPU_ONLINE:
    mutex_lock(&wq_pool_mutex);

    for_each_pool(pool, pi) {
        mutex_lock(&pool->attach_mutex);

        if (pool->cpu == cpu)
            rebind_workers(pool);
        else if (pool->cpu < 0)
            restore_unbound_workers_cpumask(pool, cpu);

        mutex_unlock(&pool->attach_mutex);
    }

    /* update NUMA affinity of unbound workqueues */
    list_for_each_entry(wq, &workqueues, list)
        wq_update_unbound_numa(wq, cpu, true);

    mutex_unlock(&wq_pool_mutex);
    break;
}
return NOTIFY_OK;
```

}

static int workqueue_cpu_down_callback(struct notifier_block *nfb,
                         unsigned long action,
                         void *hcpu)
{
    int cpu = (unsigned long)hcpu;
    struct work_struct unbind_work;
    struct workqueue_struct *wq;

```
switch (action & ~CPU_TASKS_FROZEN) {
case CPU_DOWN_PREPARE:
    /* unbinding per-cpu workers should happen on the local CPU */
    INIT_WORK_ONSTACK(&unbind_work, wq_unbind_fn);
    queue_work_on(cpu, system_highpri_wq, &unbind_work);

    /* update NUMA affinity of unbound workqueues */
    mutex_lock(&wq_pool_mutex);
    list_for_each_entry(wq, &workqueues, list)
        wq_update_unbound_numa(wq, cpu, false);
    mutex_unlock(&wq_pool_mutex);

    /* wait for per-cpu unbinding to finish */
    flush_work(&unbind_work);
    destroy_work_on_stack(&unbind_work);
    break;
}
return NOTIFY_OK;
```

}
~~~

init_worker_pool()初始化一个worker_pool。

~~~c
static int init_worker_pool(struct worker_pool *pool)
{
    spin_lock_init(&pool->lock);
    pool->id = -1;
    pool->cpu = -1;---------------------------------------------初始值-1表示当前worker_pool是unbound型的
    pool->node = NUMA_NO_NODE;
    pool->flags |= POOL_DISASSOCIATED;
    INIT_LIST_HEAD(&pool->worklist);
    INIT_LIST_HEAD(&pool->idle_list);
    hash_init(pool->busy_hash);

```
init_timer_deferrable(&pool->idle_timer);
pool->idle_timer.function = idle_worker_timeout;-------------销毁多余worker，每IDLE_WORKER_TIMEOUT(300秒)执行一次。
pool->idle_timer.data = (unsigned long)pool;

setup_timer(&pool->mayday_timer, pool_mayday_timeout,
        (unsigned long)pool);--------------------------------设置mayday_timer，周期为MAYDAY_INTERVAL，即100ms。

mutex_init(&pool->manager_arb);
mutex_init(&pool->attach_mutex);
INIT_LIST_HEAD(&pool->workers);

ida_init(&pool->worker_ida);
INIT_HLIST_NODE(&pool->hash_node);
pool->refcnt = 1;

/* shouldn't fail above this point */
pool->attrs = alloc_workqueue_attrs(GFP_KERNEL);
if (!pool->attrs)
    return -ENOMEM;
return 0;
```

}
~~~

create_worker()创建内核的工作线程。

~~~c
static struct worker *create_worker(struct worker_pool *pool)
{
    struct worker *worker = NULL;
    int id = -1;
    char id_buf[16];

```
/* ID is needed to determine kthread name */
id = ida_simple_get(&pool->worker_ida, 0, 0, GFP_KERNEL);----------------从当前worker_pool->worker_ida获取一个空闲id。
if (id < 0)
    goto fail;

worker = alloc_worker(pool->node);---------------------------------------分配一个woker结构体
if (!worker)
    goto fail;

worker->pool = pool;-----------------------------------------------------woker_pool关联到worker
worker->id = id;---------------------------------------------------------递增的id

if (pool->cpu >= 0)------------------------------------------------------初始值为-1表示unbound，当>=0的时候就指定了cpu，说明是bound型的。
    snprintf(id_buf, sizeof(id_buf), "%d:%d%s", pool->cpu, id,
         pool->attrs->nice < 0  ? "H" : "");-----------------------------nice为0表示普通优先级，nice为-20是高优先级。
else
    snprintf(id_buf, sizeof(id_buf), "u%d:%d", pool->id, id);

worker->task = kthread_create_on_node(worker_thread, worker, pool->node,
                      "kworker/%s", id_buf);----------------------------woker和创建的内核工作线程关联上，线程处理函数是worker_thread。
if (IS_ERR(worker->task))
    goto fail;

set_user_nice(worker->task, pool->attrs->nice);-------------------------设置内核工作线程的优先级相关

/* prevent userland from meddling with cpumask of workqueue workers */
worker->task->flags |= PF_NO_SETAFFINITY;-------------------------------阻止用户修改其CPU亲和性

/* successful, attach the worker to the pool */
worker_attach_to_pool(worker, pool);------------------------------------将worker附着到worker_pool上

/* start the newly created worker */
spin_lock_irq(&pool->lock);
worker->pool->nr_workers++;---------------------------------------------统计当前worker对应worker_pool中工作线程数目
worker_enter_idle(worker);----------------------------------------------让该工作线程进入idle状态。
wake_up_process(worker->task);------------------------------------------唤醒刚创建的工作线程
spin_unlock_irq(&pool->lock);

return worker;
```

fail:
    if (id >= 0)
        ida_simple_remove(&pool->worker_ida, id);
    kfree(worker);
    return NULL;
}
~~~

woker_attact_to_pool()主要是将worker工作线程加入到woker_pool->workers链表中。

~~~c
static void worker_attach_to_pool(struct worker *worker,
                   struct worker_pool *pool)
{
    mutex_lock(&pool->attach_mutex);

```
set_cpus_allowed_ptr(worker->task, pool->attrs->cpumask);
if (pool->flags & POOL_DISASSOCIATED)------------------表示worker_pool没有绑定到某个CPU上，所以worker也不会绑定到某个CPU。
    worker->flags |= WORKER_UNBOUND;

list_add_tail(&worker->node, &pool->workers);----------将当前worker加入到worker_pool末尾。

mutex_unlock(&pool->attach_mutex);
```

}
~~~

##### 1.2.3 工作线程执行函数

worker_thread()是工作线程的处理函数，不管其所在worker_pool是bound还是unbound型。

worker_thread()处理了大部分work_item，除了属于rescuer的work_item由rescuer_thread()进行处理。

通过worker找到对应的worker_pool，然后遍历worker_pool中的work_struct。

~~~c
static int worker_thread(void *__worker)
{
    struct worker *worker = __worker;
    struct worker_pool *pool = worker->pool;

```
/* tell the scheduler that this is a workqueue worker */
worker->task->flags |= PF_WQ_WORKER;------------------PF_WQ_WORKER告诉调度器这是一个woker类型的线程。
```

woke_up:
    spin_lock_irq(&pool->lock);

```
/* am I supposed to die? */
if (unlikely(worker->flags & WORKER_DIE)) {-----------WORKER_DIE表示此工作线程将要被销毁。
    spin_unlock_irq(&pool->lock);
    WARN_ON_ONCE(!list_empty(&worker->entry));
    worker->task->flags &= ~PF_WQ_WORKER;

    set_task_comm(worker->task, "kworker/dying");
    ida_simple_remove(&pool->worker_ida, worker->id);
    worker_detach_from_pool(worker, pool);
    kfree(worker);
    return 0;
}

worker_leave_idle(worker);----------------------------清除WORKER_IDLE标志位，并退出idle状态链表
```

recheck:
    /* no more worker necessary? */
    if (!need_more_worker(pool))--------------------------如果当前worker_pool->worklist中没有pending任务，并且当前pool中没有正在运行的线程，need_more_worker()返回true。
        goto sleep;

```
/* do we need to manage? */
if (unlikely(!may_start_working(pool)) && manage_workers(worker))------may_start_working()判断pool中是否有idle状态工作线程。如果没有，那么manage_workers()创建一些工作线程。
    goto recheck;------------------------------------------------------manage_worker()创建新工作线程之后，还需要跳转到recheck标签处再检查一遍，有可能在创建工作线程过程中整个线程池发生了变化。

/*
 * ->scheduled list can only be filled while a worker is
 * preparing to process a work or actually processing it.
 * Make sure nobody diddled with it while I was sleeping.
 */
WARN_ON_ONCE(!list_empty(&worker->scheduled));-------------------------scheduled链表表示工作线程准备处理一个work或者正在执行一个work时才会有work添加到该链表中。

/*
 * Finish PREP stage.  We're guaranteed to have at least one idle
 * worker or that someone else has already assumed the manager
 * role.  This is where @worker starts participating in concurrency
 * management if applicable and concurrency management is restored
 * after being rebound.  See rebind_workers() for details.
 */
worker_clr_flags(worker, WORKER_PREP | WORKER_REBOUND);--------因为马上就要开始执行work的回调函数了，对于bound类型增加worker_pool->nr_running计数

do {-----------------------------------------------------------遍历当前worker_pool->worklist中的工作，调用process_one_work()进行处理。
    struct work_struct *work =
        list_first_entry(&pool->worklist,
                 struct work_struct, entry);

    if (likely(!(*work_data_bits(work) & WORK_STRUCT_LINKED))) {
        /* optimization path, not strictly necessary */
        process_one_work(worker, work);------------------------单独处理一个work
        if (unlikely(!list_empty(&worker->scheduled)))
            process_scheduled_works(worker);-------------------处理worker_pool->scheduled链表上的work_struct。
    } else {---------------------------------------------------如果当前work_struct置位WORK_STRUCT_LINKED表示work后面还串上其它work，把这些work迁移到woeker_pool->scheduled中，然后一并再用process_one_work()函数处理。
        move_linked_works(work, &worker->scheduled, NULL);
        process_scheduled_works(worker);
    }
} while (keep_working(pool));----------------------------------判断当前worker_pool->worklist不为空，且工作线程池活跃线程小于等于1，那么保持当前工作线程继续工作，以防止工作线程泛滥。

worker_set_flags(worker, WORKER_PREP);
```

sleep:
    /*

- pool->lock is held and there's no work to process and no need to
   manage, sleep.  Workers are woken up only while holding
  - pool->lock or from local cpu, so setting the current state
     before releasing pool->lock is enough to prevent losing any
    - event.
      /
          worker_enter_idle(worker);
          __set_current_state(TASK_INTERRUPTIBLE);
          spin_unlock_irq(&pool->lock);
          schedule();
          goto woke_up;
      }
~~~



manage_workers()函数动态管理创建工作线程的函数。

maybo_create_worker()函数中while首先调用create_worker()来创建新的工作线程。

~~~c
static bool manage_workers(struct worker *worker)
{
    struct worker_pool *pool = worker->pool;

```
if (pool->flags & POOL_MANAGER_ACTIVE)
    return false;

pool->flags |= POOL_MANAGER_ACTIVE;
pool->manager = worker;

maybe_create_worker(pool);

pool->manager = NULL;
pool->flags &= ~POOL_MANAGER_ACTIVE;
wake_up(&wq_manager_wait);
return true;
```

}

static void maybe_create_worker(struct worker_pool *pool)
__releases(&pool->lock)

__acquires(&pool->lock)
{
restart:
    spin_unlock_irq(&pool->lock);

```
/* if we don't make progress in MAYDAY_INITIAL_TIMEOUT, call for help */
mod_timer(&pool->mayday_timer, jiffies + MAYDAY_INITIAL_TIMEOUT);

while (true) {
    if (create_worker(pool) || !need_to_create_worker(pool))-----------------create_worker()创建成功则退出while循环；或者通过need_to_create_worker()判断是否需要继续创建新线程。
        break;

    schedule_timeout_interruptible(CREATE_COOLDOWN);

    if (!need_to_create_worker(pool))----------------------------------------再次判断是否需要继续创建新线程。
        break;
}

del_timer_sync(&pool->mayday_timer);
spin_lock_irq(&pool->lock);
/*
 * This is necessary even after a new worker was just successfully
 * created as @pool->lock was dropped and the new worker might have
 * already become busy.
 */
if (need_to_create_worker(pool))
    goto restart;
```

}
~~~

process_scheduled_works()专门处理worker->scheduled上面的工作，具体处理还是交给process_one_work()。

~~~c
static void process_scheduled_works(struct worker *worker)
{
    while (!list_empty(&worker->scheduled)) {
        struct work_struct *work = list_first_entry(&worker->scheduled,
                        struct work_struct, entry);
        process_one_work(worker, work);
    }
}

static void process_one_work(struct worker *worker, struct work_struct *work)
__releases(&pool->lock)
__acquires(&pool->lock)
{
    struct pool_workqueue *pwq = get_work_pwq(work);
    struct worker_pool *pool = worker->pool;
    bool cpu_intensive = pwq->wq->flags & WQ_CPU_INTENSIVE;----------------判断当前的workqueue是否是CPU_INTENSIVE，会对其所在工作线程进行特殊设置。
    int work_color;
    struct worker *collision;
#ifdef CONFIG_LOCKDEP
    /*
     * It is permissible to free the struct work_struct from
     * inside the function that is called from it, this we need to
     * take into account for lockdep too.  To avoid bogus "held
     * lock freed" warnings as well as problems when looking into
     * work->lockdep_map, make a copy and use that here.
     */
    struct lockdep_map lockdep_map;

```
lockdep_copy_map(&lockdep_map, &work->lockdep_map);
```

#endif
    /* ensure we're on the correct CPU */
    WARN_ON_ONCE(!(pool->flags & POOL_DISASSOCIATED) &&
             raw_smp_processor_id() != pool->cpu);

```
/*
 * A single work shouldn't be executed concurrently by
 * multiple workers on a single cpu.  Check whether anyone is
 * already processing the work.  If so, defer the work to the
 * currently executing one.
 */
collision = find_worker_executing_work(pool, work);--------------------查询当前work是否在worker_pool->busy_hash表中正在运行，如果在就移到当前work正在执行的worker->scheduled并退出当前处理。
if (unlikely(collision)) {
    move_linked_works(work, &collision->scheduled, NULL);
    return;
}

/* claim and dequeue */
debug_work_deactivate(work);
hash_add(pool->busy_hash, &worker->hentry, (unsigned long)work);
worker->current_work = work;
worker->current_func = work->func;
worker->current_pwq = pwq;
work_color = get_work_color(work);

list_del_init(&work->entry);

/*
 * CPU intensive works don't participate in concurrency management.
 * They're the scheduler's responsibility.  This takes @worker out
 * of concurrency management and the next code block will chain
 * execution of the pending work items.
 */
if (unlikely(cpu_intensive))
    worker_set_flags(worker, WORKER_CPU_INTENSIVE);--------------------设置当前工作线程flags，调度器就知道内核线程属性了，但实际上调度器暂时并没有做特殊处理。

/*
 * Wake up another worker if necessary.  The condition is always
 * false for normal per-cpu workers since nr_running would always
 * be >= 1 at this point.  This is used to chain execution of the
 * pending work items for WORKER_NOT_RUNNING workers such as the
 * UNBOUND and CPU_INTENSIVE ones.
 */
if (need_more_worker(pool))-----------------------判断是否需要唤醒更多工作线程，wake_up_worker()去唤醒worker_pool中第一个idle线程。对于bound型worker_pool此时一般nr_running>=1，所以条件不成立。
    wake_up_worker(pool);

/*
 * Record the last pool and clear PENDING which should be the last
 * update to @work.  Also, do this inside @pool->lock so that
 * PENDING and queued state changes happen together while IRQ is
 * disabled.
 */
set_work_pool_and_clear_pending(work, pool->id);---------------清除struct worker中data成员pending标志位，里面使用了smp_wmb保证了pending之前的写操作完成之后才清除pending。

spin_unlock_irq(&pool->lock);

lock_map_acquire_read(&pwq->wq->lockdep_map);
lock_map_acquire(&lockdep_map);
trace_workqueue_execute_start(work);
worker->current_func(work);------------------------------------真正执行work的回调函数
/*
 * While we must be careful to not use "work" after this, the trace
 * point will only record its address.
 */
trace_workqueue_execute_end(work);
lock_map_release(&lockdep_map);
lock_map_release(&pwq->wq->lockdep_map);

if (unlikely(in_atomic() || lockdep_depth(current) > 0)) {
    pr_err("BUG: workqueue leaked lock or atomic: %s/0x%08x/%d\n"
           "     last function: %pf\n",
           current->comm, preempt_count(), task_pid_nr(current),
           worker->current_func);
    debug_show_held_locks(current);
    dump_stack();
}

/*
 * The following prevents a kworker from hogging CPU on !PREEMPT
 * kernels, where a requeueing work item waiting for something to
 * happen could deadlock with stop_machine as such work item could
 * indefinitely requeue itself while all other CPUs are trapped in
 * stop_machine. At the same time, report a quiescent RCU state so
 * the same condition doesn't freeze RCU.
 */
cond_resched_rcu_qs();

spin_lock_irq(&pool->lock);

/* clear cpu intensive status */
if (unlikely(cpu_intensive))
    worker_clr_flags(worker, WORKER_CPU_INTENSIVE);

/* we're done with it, release */
hash_del(&worker->hentry);-----------------------------------work回调函数执行完成后的清理工作
worker->current_work = NULL;
worker->current_func = NULL;
worker->current_pwq = NULL;
worker->desc_valid = false;
pwq_dec_nr_in_flight(pwq, work_color);
```

}
~~~

### 2 创建工作队列

#### 2.1 各种创建工作队列API和flags

创建工作队列的API有很多，但最终都通过__alloc_workqueue_key()去实现。不同API之间的主要区别在于使用了不同的flag。

所以看一下这些flag，同时max_active决定每个CPU最多可有多少个work挂入一个工作队列。

如果bound类型工作队列，max_active最大可以是512；如果max_active为0，表示指定为256。

如果需要严格串行执行工作队列，使用max_active=1和WQ_UNBOUND组合。

```
/*

- Workqueue flags and constants.  For details, please refer to

- Documentation/workqueue.txt.
  */
  enum {
  WQ_NON_REENTRANT    = 1 << 0, /* guarantee non-reentrance */-----------确保工作在多个CPU上是不可重入的。
  WQ_UNBOUND        = 1 << 1, /* not bound to any cpu */-----------------工作任务会加入unbound工作队列中，unbound类型work不需要额外的同步管理，unbound工作线程池会尝试尽快执行它的work。
  WQ_FREEZABLE        = 1 << 2, /* freeze during suspend */--------------此标记工作队列会参与到系统suspend过程中，会让工作线程处理完成所有的work才完成进程冻结，并且这个过程不会再新开始一个work执行，直到进程被解冻。
  WQ_MEM_RECLAIM        = 1 << 3, /* may be used for memory reclaim */---当内存紧张时，创建新的工作线程可能会失败，系统还有一个recuer内核线程会去接管这种情况。
  WQ_HIGHPRI        = 1 << 4, /* high priority */------------------------工作队列的任务对应高优先级的worker_pool，即较低nice值。
  WQ_CPU_INTENSIVE    = 1 << 5, /* cpu instensive workqueue */-----------属于特别消耗CPU资源一类work，这类work会得到系统进程调度器的监管，排在这类work后面的non-cpu intensive类型work可能会推迟执行。
    WQ_SYSFS = 1 << 6, /* visible in sysfs, see wq_sysfs_register() */
  WQ_RESCUER        = 1 << 7, /* internal: workqueue has rescuer */
    __WQ_DRAINING = 1 << 16, /* internal: workqueue is draining */
    __WQ_ORDERED		= 1 << 17, /* internal: workqueue is ordered */-----------同一时间只能执行一个work item。

  WQ_MAX_ACTIVE        = 512,      /* I like 512, better ideas? */
  WQ_MAX_UNBOUND_PER_CPU    = 4,      /* 4 * #cpus for unbound wq */
  WQ_DFL_ACTIVE        = WQ_MAX_ACTIVE / 2,
  };
```

最常见的形式是alloc_workqueue()，其它都是对某些flag的封装。

```

#define alloc_workqueue(fmt, flags, max_active, args...)        \
    __alloc_workqueue_key((fmt), (flags), (max_active),        \
                  NULL, NULL, ##args)
#define alloc_ordered_workqueue(fmt, flags, args...)            \
    alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags), 1, ##args)

#define create_workqueue(name)                        \
    alloc_workqueue("%s", WQ_MEM_RECLAIM, 1, (name))
#define create_freezable_workqueue(name)                \
    alloc_workqueue("%s", WQ_FREEZABLE | WQ_UNBOUND | WQ_MEM_RECLAIM, \
            1, (name))
#define create_singlethread_workqueue(name)                \
    alloc_ordered_workqueue("%s", WQ_MEM_RECLAIM, name)
```

#### 2.2 __alloc_workqueue_key()

__alloc_workqueue_key分配一个workqueue_struct数据结构并进行初始化，和pool_workqueue进行关联等操作。

```
struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
                           unsigned int flags,
                           int max_active,
                           struct lock_class_key *key,
                           const char *lock_name, ...)
{
    size_t tbl_size = 0;
    va_list args;
    struct workqueue_struct *wq;
    struct pool_workqueue *pwq;

​```
/* see the comment above the definition of WQ_POWER_EFFICIENT */
if ((flags & WQ_POWER_EFFICIENT) && wq_power_efficient)----------设置unbound类型workqueue后，究竟选择哪个cpu上唤醒交由进程调度器决定。如果是bound类型就会让idle状态的CPU从idle状态唤醒，从而增加了功耗。
    flags |= WQ_UNBOUND;

/* allocate wq and format name */
if (flags & WQ_UNBOUND)
    tbl_size = nr_node_ids * sizeof(wq->numa_pwq_tbl[0]);

wq = kzalloc(sizeof(*wq) + tbl_size, GFP_KERNEL);
if (!wq)
    return NULL;

if (flags & WQ_UNBOUND) {
    wq->unbound_attrs = alloc_workqueue_attrs(GFP_KERNEL);
    if (!wq->unbound_attrs)
        goto err_free_wq;
}

va_start(args, lock_name);
vsnprintf(wq->name, sizeof(wq->name), fmt, args);
va_end(args);

max_active = max_active ?: WQ_DFL_ACTIVE;
max_active = wq_clamp_max_active(max_active, flags, wq->name);

/* init wq */
wq->flags = flags;
wq->saved_max_active = max_active;
mutex_init(&wq->mutex);
atomic_set(&wq->nr_pwqs_to_flush, 0);
INIT_LIST_HEAD(&wq->pwqs);
INIT_LIST_HEAD(&wq->flusher_queue);
INIT_LIST_HEAD(&wq->flusher_overflow);
INIT_LIST_HEAD(&wq->maydays);

lockdep_init_map(&wq->lockdep_map, lock_name, key, 0);
INIT_LIST_HEAD(&wq->list);

if (alloc_and_link_pwqs(wq) < 0)---------------------分配一个workqueue_struct数据结构并初始化
    goto err_free_wq;

/*
 * Workqueues which may be used during memory reclaim should
 * have a rescuer to guarantee forward progress.
 */
if (flags & WQ_MEM_RECLAIM) {
    struct worker *rescuer;

    rescuer = alloc_worker(NUMA_NO_NODE);
    if (!rescuer)
        goto err_destroy;

    rescuer->rescue_wq = wq;
    rescuer->task = kthread_create(rescuer_thread, rescuer, "%s",
                       wq->name);
    if (IS_ERR(rescuer->task)) {
        kfree(rescuer);
        goto err_destroy;
    }

    wq->rescuer = rescuer;
    rescuer->task->flags |= PF_NO_SETAFFINITY;
    wake_up_process(rescuer->task);
}

if ((wq->flags & WQ_SYSFS) && workqueue_sysfs_register(wq))
    goto err_destroy;

/*
 * wq_pool_mutex protects global freeze state and workqueues list.
 * Grab it, adjust max_active and add the new @wq to workqueues
 * list.
 */
mutex_lock(&wq_pool_mutex);

mutex_lock(&wq->mutex);
for_each_pwq(pwq, wq)
    pwq_adjust_max_active(pwq);
mutex_unlock(&wq->mutex);

list_add(&wq->list, &workqueues);

mutex_unlock(&wq_pool_mutex);

return wq;
​```

err_free_wq:
    free_workqueue_attrs(wq->unbound_attrs);
    kfree(wq);
    return NULL;
err_destroy:
    destroy_workqueue(wq);
    return NULL;
}
```

```
static int alloc_and_link_pwqs(struct workqueue_struct *wq)
{
    bool highpri = wq->flags & WQ_HIGHPRI;
    int cpu, ret;

​```
if (!(wq->flags & WQ_UNBOUND)) {------------------------处理bound类型workqueue
    wq->cpu_pwqs = alloc_percpu(struct pool_workqueue);-cpu_pwqs是一个per-cpu类型，为每个cpu分配一个pool_workqueue数据结构，是动态分配的。cpu_worker_pools是静态定义的per-cpu类型worker_pool数据结构。
    if (!wq->cpu_pwqs)
        return -ENOMEM;

    for_each_possible_cpu(cpu) {
        struct pool_workqueue *pwq =
            per_cpu_ptr(wq->cpu_pwqs, cpu);
        struct worker_pool *cpu_pools =
            per_cpu(cpu_worker_pools, cpu);

        init_pwq(pwq, wq, &cpu_pools[highpri]);--------init_pwq()将动态分配的cpu_pwqs和静态定义的cpu_worker_pools关联起来。

        mutex_lock(&wq->mutex);
        link_pwq(pwq);---------------------------------把pool_workqueue添加到workqueue_struct->pwqs链表中。
        mutex_unlock(&wq->mutex);
    }
    return 0;
} else if (wq->flags & __WQ_ORDERED) {-----------------处理ordered类型workqueue
    ret = apply_workqueue_attrs(wq, ordered_wq_attrs[highpri]);
    /* there should only be single pwq for ordering guarantee */
    WARN(!ret && (wq->pwqs.next != &wq->dfl_pwq->pwqs_node ||
              wq->pwqs.prev != &wq->dfl_pwq->pwqs_node),
         "ordering guarantee broken for workqueue %s\n", wq->name);
    return ret;
} else {-----------------------------------------------处理unbound类型workqueue
    return apply_workqueue_attrs(wq, unbound_std_wq_attrs[highpri]);
}
​```

}
```

```
int apply_workqueue_attrs(struct workqueue_struct *wq,
              const struct workqueue_attrs *attrs)
{
    struct workqueue_attrs *new_attrs, *tmp_attrs;
    struct pool_workqueue **pwq_tbl, *dfl_pwq;
    int node, ret;

​```
/* only unbound workqueues can change attributes */
if (WARN_ON(!(wq->flags & WQ_UNBOUND)))
    return -EINVAL;

/* creating multiple pwqs breaks ordering guarantee */
if (WARN_ON((wq->flags & __WQ_ORDERED) && !list_empty(&wq->pwqs)))
    return -EINVAL;

pwq_tbl = kzalloc(nr_node_ids * sizeof(pwq_tbl[0]), GFP_KERNEL);
new_attrs = alloc_workqueue_attrs(GFP_KERNEL);
tmp_attrs = alloc_workqueue_attrs(GFP_KERNEL);
if (!pwq_tbl || !new_attrs || !tmp_attrs)
    goto enomem;

/* make a copy of @attrs and sanitize it */
copy_workqueue_attrs(new_attrs, attrs);
cpumask_and(new_attrs->cpumask, new_attrs->cpumask, cpu_possible_mask);

/*
 * We may create multiple pwqs with differing cpumasks.  Make a
 * copy of @new_attrs which will be modified and used to obtain
 * pools.
 */
copy_workqueue_attrs(tmp_attrs, new_attrs);

/*
 * CPUs should stay stable across pwq creations and installations.
 * Pin CPUs, determine the target cpumask for each node and create
 * pwqs accordingly.
 */
get_online_cpus();

mutex_lock(&wq_pool_mutex);

/*
 * If something goes wrong during CPU up/down, we'll fall back to
 * the default pwq covering whole @attrs->cpumask.  Always create
 * it even if we don't use it immediately.
 */
dfl_pwq = alloc_unbound_pwq(wq, new_attrs);---------------------分配一个pool_workqueue数据结构
if (!dfl_pwq)
    goto enomem_pwq;

for_each_node(node) {
    if (wq_calc_node_cpumask(attrs, node, -1, tmp_attrs->cpumask)) {
        pwq_tbl[node] = alloc_unbound_pwq(wq, tmp_attrs);-------查找或者新建一个pool_workqueue
        if (!pwq_tbl[node])
            goto enomem_pwq;
    } else {
        dfl_pwq->refcnt++;
        pwq_tbl[node] = dfl_pwq;
    }
}

mutex_unlock(&wq_pool_mutex);

/* all pwqs have been created successfully, let's install'em */
mutex_lock(&wq->mutex);

copy_workqueue_attrs(wq->unbound_attrs, new_attrs);

/* save the previous pwq and install the new one */
for_each_node(node)
    pwq_tbl[node] = numa_pwq_tbl_install(wq, node, pwq_tbl[node]);

/* @dfl_pwq might not have been used, ensure it's linked */
link_pwq(dfl_pwq);
swap(wq->dfl_pwq, dfl_pwq);

mutex_unlock(&wq->mutex);

/* put the old pwqs */
for_each_node(node)
    put_pwq_unlocked(pwq_tbl[node]);
put_pwq_unlocked(dfl_pwq);

put_online_cpus();
ret = 0;
/* fall through */
​```

out_free:
    free_workqueue_attrs(tmp_attrs);
    free_workqueue_attrs(new_attrs);
    kfree(pwq_tbl);
    return ret;

enomem_pwq:
    free_unbound_pwq(dfl_pwq);
    for_each_node(node)
        if (pwq_tbl && pwq_tbl[node] != dfl_pwq)
            free_unbound_pwq(pwq_tbl[node]);
    mutex_unlock(&wq_pool_mutex);
    put_online_cpus();
enomem:
    ret = -ENOMEM;
    goto out_free;
}

static struct pool_workqueue *alloc_unbound_pwq(struct workqueue_struct *wq,
                    const struct workqueue_attrs *attrs)
{
    struct worker_pool *pool;
    struct pool_workqueue *pwq;

​```
lockdep_assert_held(&wq_pool_mutex);

pool = get_unbound_pool(attrs);----------------------------首先查找一个worker_pool，如果没有则创建一个新的worker_pool。
if (!pool)
    return NULL;

pwq = kmem_cache_alloc_node(pwq_cache, GFP_KERNEL, pool->node);-----分配一个pool_workqueue数据结构
if (!pwq) {
    put_unbound_pool(pool);
    return NULL;
}

init_pwq(pwq, wq, pool);
return pwq;
​```

}

static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
{
    u32 hash = wqattrs_hash(attrs);
    struct worker_pool *pool;
    int node;

​```
lockdep_assert_held(&wq_pool_mutex);

/* do we already have a matching pool? */
hash_for_each_possible(unbound_pool_hash, pool, hash_node, hash) {------系统定义了一个哈希表unbound_pool_hash，用于管理所有的unbound类型worker_pool
    if (wqattrs_equal(pool->attrs, attrs)) {----------------------------通过wqattrs_equal()判断系统中是否已经有个类型相关worker_pool
        pool->refcnt++;
        return pool;
    }
}

/* nope, create a new one */
pool = kzalloc(sizeof(*pool), GFP_KERNEL);------------------------------如果没有找到，重新分配和初始化一个worker_pool
if (!pool || init_worker_pool(pool) < 0)
    goto fail;
​```

...
    /* create and start the initial worker */
    if (!create_worker(pool))
        goto fail;

​```
/* install */
hash_add(unbound_pool_hash, &pool->hash_node, hash);

return pool;
​```

...
}

static void put_pwq(struct pool_workqueue *pwq)
{
    lockdep_assert_held(&pwq->pool->lock);
    if (likely(--pwq->refcnt))
        return;
    if (WARN_ON_ONCE(!(pwq->wq->flags & WQ_UNBOUND)))
        return;
    schedule_work(&pwq->unbound_release_work);
}

static void init_pwq(struct pool_workqueue *pwq, struct workqueue_struct *wq,
             struct worker_pool *pool)
{
    BUG_ON((unsigned long)pwq & WORK_STRUCT_FLAG_MASK);

​```
memset(pwq, 0, sizeof(*pwq));

pwq->pool = pool;-------------------------------------------pwq->pool指向worker_pool
pwq->wq = wq;-----------------------------------------------pwq->wq指向workqueue_struct
pwq->flush_color = -1;
pwq->refcnt = 1;
INIT_LIST_HEAD(&pwq->delayed_works);
INIT_LIST_HEAD(&pwq->pwqs_node);
INIT_LIST_HEAD(&pwq->mayday_node);
INIT_WORK(&pwq->unbound_release_work, pwq_unbound_release_workfn);------------用于释放pool_workqueue
​```

}

static void pwq_unbound_release_workfn(struct work_struct *work)
{
    struct pool_workqueue *pwq = container_of(work, struct pool_workqueue,
                          unbound_release_work);-----------从work找到pool_workqueue数据结构指针pwq
    struct workqueue_struct *wq = pwq->wq;
    struct worker_pool *pool = pwq->pool;
    bool is_last;

​```
if (WARN_ON_ONCE(!(wq->flags & WQ_UNBOUND)))
    return;

mutex_lock(&wq->mutex);
list_del_rcu(&pwq->pwqs_node);
is_last = list_empty(&wq->pwqs);
mutex_unlock(&wq->mutex);

mutex_lock(&wq_pool_mutex);
put_unbound_pool(pool);
mutex_unlock(&wq_pool_mutex);

call_rcu_sched(&pwq->rcu, rcu_free_pwq);

/*
 * If we're the last pwq going away, @wq is already dead and no one
 * is gonna access it anymore.  Free it.
 */
if (is_last) {
    free_workqueue_attrs(wq->unbound_attrs);
    kfree(wq);
}
​```

}
```

### 3. 调度一个work

 一般情况下使用默认的workqueue，首先需要初始化一个work，然后使用schedule_work()把work挂入默认的workqueue中。

#### 3.1 初始化一个work

初始化一个work的API有各种不同形式，但最终都调用__INIT_WORK()。

```
#define TIMER_DEFERRABLE 0x1LU
  #define TIMER_IRQSAFE			0x2LU

#define __INIT_WORK(_work, _func, _onstack)                \
    do {                                \
        __init_work((_work), _onstack);                \
        (_work)->data = (atomic_long_t) WORK_DATA_INIT();    \
        INIT_LIST_HEAD(&(_work)->entry);            \
        (_work)->func = (_func);                \
    } while (0)

#define INIT_WORK(_work, _func)                        \
    __INIT_WORK((_work), (_func), 0)

#define INIT_WORK_ONSTACK(_work, _func)                    \
    __INIT_WORK((_work), (_func), 1)

#define __INIT_DELAYED_WORK(_work, _func, _tflags)            \
    do {                                \
        INIT_WORK(&(_work)->work, (_func));            \
        __setup_timer(&(_work)->timer, delayed_work_timer_fn,    \
                  (unsigned long)(_work),            \
                  (_tflags) | TIMER_IRQSAFE);        \
    } while (0)

#define __INIT_DELAYED_WORK_ONSTACK(_work, _func, _tflags)        \
    do {                                \
        INIT_WORK_ONSTACK(&(_work)->work, (_func));        \
        __setup_timer_on_stack(&(_work)->timer,            \
                       delayed_work_timer_fn,        \
                       (unsigned long)(_work),        \
                       (_tflags) | TIMER_IRQSAFE);    \
    } while (0)

#define INIT_DELAYED_WORK(_work, _func)                    \
    __INIT_DELAYED_WORK(_work, _func, 0)

#define INIT_DELAYED_WORK_ONSTACK(_work, _func)                \
    __INIT_DELAYED_WORK_ONSTACK(_work, _func, 0)

#define INIT_DEFERRABLE_WORK(_work, _func)                \
    __INIT_DELAYED_WORK(_work, _func, TIMER_DEFERRABLE)

#define INIT_DEFERRABLE_WORK_ONSTACK(_work, _func)            \
    __INIT_DELAYED_WORK_ONSTACK(_work, _func, TIMER_DEFERRABLE)
```

当data字段包含WORK_STRUCT_PWQ_BIT标志位时，高位存放上一次pool_workqueue指针，低8位存放标志位；没有包含时，包比特位存放上次worker_pool的ID号，低5位存放标志位。

常见标志位如下：

```
enum {
    WORK_STRUCT_PENDING_BIT    = 0,    /* work item is pending execution */----表示该work正在pending执行。
    WORK_STRUCT_DELAYED_BIT    = 1,    /* work item is delayed */--------------表示该work被延迟执行了。
    WORK_STRUCT_PWQ_BIT    = 2,    /* data points to pwq */
    WORK_STRUCT_LINKED_BIT    = 3,    /* next work is linked to this one */----表示一个work连接到该work上。
#ifdef CONFIG_DEBUG_OBJECTS_WORK
    WORK_STRUCT_STATIC_BIT    = 4,    /* static initializer (debugobjects) */
    WORK_STRUCT_COLOR_SHIFT    = 5,    /* color for workqueue flushing */
#else
    WORK_STRUCT_COLOR_SHIFT    = 4,    /* color for workqueue flushing */
#endif
    WORK_STRUCT_COLOR_BITS    = 4,
...
}
```

#### 3.2 schedule_work

在初始化完work之后，调用schedule_work()函数把work挂入系统默认workqueue中。

schedule_work()的默认的工作队列是[system_wq](https://www.cnblogs.com/arnoldlu/p/8659988.html#system_wq)，最终将工作交给__queue_work()。

```
static inline bool schedule_work(struct work_struct *work)
{
    return queue_work(system_wq, work);
}

static inline bool queue_work(struct workqueue_struct *wq,
                  struct work_struct *work)
{
    return queue_work_on(WORK_CPU_UNBOUND, wq, work);------------WORK_CPU_UNBOUND不是表示unbound类型，而是CPU。
}

bool queue_work_on(int cpu, struct workqueue_struct *wq,
           struct work_struct *work)
{
    bool ret = false;
    unsigned long flags;

​```
local_irq_save(flags);---------------------------------------把work加入工作队列是在关本地中断下运行的。

if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {------------设置WORK_STRUCT_PENDING_BIT并返回旧值。
    __queue_work(cpu, wq, work);
    ret = true;
}

local_irq_restore(flags);
return ret;
​```

}

static void __queue_work(int cpu, struct workqueue_struct *wq,
             struct work_struct *work)
{
    struct pool_workqueue *pwq;
    struct worker_pool *last_pool;
    struct list_head *worklist;
    unsigned int work_flags;
    unsigned int req_cpu = cpu;

​```
WARN_ON_ONCE(!irqs_disabled());----------------------------是否处于关中断状态

debug_work_activate(work);

/* if draining, only works from the same workqueue are allowed */
if (unlikely(wq->flags & __WQ_DRAINING) &&
    WARN_ON_ONCE(!is_chained_work(wq)))--------------------__WQ_DRAINING表示要销毁workqueue，那么挂入workqueue中所有的work都要处理完毕才能把这个workqueue销毁。在销毁过程中，一般不允许再有新的work加入队列中。有一种特殊例外是正在清空work时触发了一个queue work操作，这种情况被称为chained work。
    return;
​```

retry:
    if (req_cpu == WORK_CPU_UNBOUND)
        cpu = raw_smp_processor_id();

​```
/* pwq which will be used unless @work is executing elsewhere */
if (!(wq->flags & WQ_UNBOUND))
    pwq = per_cpu_ptr(wq->cpu_pwqs, cpu);-----------------对于bound型的workqueue，直接使用本地CPU对应pool_workqueue。
else
    pwq = unbound_pwq_by_node(wq, cpu_to_node(cpu));------对于unbound型，调用unbound_pwq_by_node()寻找本地node节点对应的unbound类型的pool_workqueue。

/*
 * If @work was previously on a different pool, it might still be
 * running there, in which case the work needs to be queued on that
 * pool to guarantee non-reentrancy.
 */
last_pool = get_work_pool(work);--------------------------通过work_struct的成员data查询该work上一次是在哪个worker_pool中运行的。
if (last_pool && last_pool != pwq->pool) {----------------如果上次运行的worker_pool和本次不一致
    struct worker *worker;

    spin_lock(&last_pool->lock);

    worker = find_worker_executing_work(last_pool, work);--判断一个work是否正在last_pool上运行，也即不在当前worker_pool运行，如果是返回这个正在执行的工作线程worker

    if (worker && worker->current_pwq->wq == wq) {
        pwq = worker->current_pwq;-------------------------利用当前work正在执行的pool_workqueue，利用缓存热度，不进行调度。
    } else {
        /* meh... not running there, queue here */
        spin_unlock(&last_pool->lock);
        spin_lock(&pwq->pool->lock);
    }
} else {
    spin_lock(&pwq->pool->lock);
}

if (unlikely(!pwq->refcnt)) {
    if (wq->flags & WQ_UNBOUND) {-------------------对unbound类型pool_workqueue释放是异步的，当refcnt减少到0时，说明该pool_workqueue已经被释放，那么需要跳转到retry出重新选择pool_workqueue。
        spin_unlock(&pwq->pool->lock);
        cpu_relax();
        goto retry;
    }
    /* oops */
    WARN_ONCE(true, "workqueue: per-cpu pwq for %s on cpu%d has 0 refcnt",
          wq->name, cpu);
}

/* pwq determined, queue */
trace_workqueue_queue_work(req_cpu, pwq, work);

if (WARN_ON(!list_empty(&work->entry))) {
    spin_unlock(&pwq->pool->lock);
    return;
}

pwq->nr_in_flight[pwq->work_color]++;
work_flags = work_color_to_flags(pwq->work_color);

if (likely(pwq->nr_active < pwq->max_active)) {-------判断当前pool_workqueue的work活跃数量，如果少于最高限值，就加入pending状态链表worker_pool->worklist,否则加入delayed_works链表中。
    trace_workqueue_activate_work(work);
    pwq->nr_active++;
    worklist = &pwq->pool->worklist;
} else {
    work_flags |= WORK_STRUCT_DELAYED;
    worklist = &pwq->delayed_works;
}

insert_work(pwq, work, worklist, work_flags);---------将当前work加入到pool_workqueue->worklist尾部。

spin_unlock(&pwq->pool->lock);
​```

}
```

get_work_pool()通过work_struct找到该work上一次在哪个worker_pool中运行。

```
static struct worker_pool *get_work_pool(struct work_struct *work)
{
    unsigned long data = atomic_long_read(&work->data);
    int pool_id;

​```
assert_rcu_or_pool_mutex();

if (data & WORK_STRUCT_PWQ)----------------------------如果定义了WORK_STRUCT_PWQ，那么直接得到pool_workqueue地址，进而找到worker_pool。
    return ((struct pool_workqueue *)
        (data & WORK_STRUCT_WQ_DATA_MASK))->pool;

pool_id = data >> WORK_OFFQ_POOL_SHIFT;----------------如果没定义WORK_STRUCT_PWQ，那么可以得到对应的pool_id。
if (pool_id == WORK_OFFQ_POOL_NONE)
    return NULL;

return idr_find(&worker_pool_idr, pool_id);------------根据pool_id从worker_pool_idr中找到对应的worker_pool。
​```

}
```

insert_work()将work加入到worker_pool的列表中，

```
static void insert_work(struct pool_workqueue *pwq, struct work_struct *work,
            struct list_head *head, unsigned int extra_flags)
{
    struct worker_pool *pool = pwq->pool;

​```
/* we own @work, set data and link */
set_work_pwq(work, pwq, extra_flags);------------把pool_workqueue指针的值和一些flag设置到data成员中，方便下次调用queue_work()知道本次使用哪个pool_workqueue()。
list_add_tail(&work->entry, head);---------------将work加入到worker_pool->worklist尾部。
get_pwq(pwq);------------------------------------增加pool_workqueue->refcnt成员引用计数。

/*
 * Ensure either wq_worker_sleeping() sees the above
 * list_add_tail() or we see zero nr_running to avoid workers lying
 * around lazily while there are works to be processed.
 */
smp_mb();----------------------------------------保证wake_up_worker()唤醒worker时，在__schedule()->wq_worker_sleeping()时，这里的list_add_tail()已经完成。同时保证下面__need_more_worker()读取nr_running时list_add_tail()链表已经完成。

if (__need_more_worker(pool))--------------------如果当前nr_running为0，表示当前worker可能并没有处于运行状态。那么需要wake_up_worker()强行唤醒一次。
    wake_up_worker(pool);
​```

}

static void wake_up_worker(struct worker_pool *pool)
{
    struct worker *worker = first_idle_worker(pool);

​```
if (likely(worker))
    wake_up_process(worker->task);
​```

}
```

调用schedule_work()只是把work加入到workqueue中，，但并没有开始实质的调度工作。

- 加入workqueue的pending链表是关中断环境下进行的
- 设置work->data成员的WORK_STRUCT_PENDING_BIT标志位
- 寻找合适的pool_workqueue，优先选择本地CPU对应的pool_workqueue；如果该work正在另一个CPU工作线程池中运行，则优先选择此工作线程池。
- 找到pool_workqueue，就找到了对应的worker_pool和对应的pending链表

那么work真正执行的地方在哪里呢？参见[worker_thread](https://www.cnblogs.com/arnoldlu/p/8659988.html#worker_thread)()。

 

其它基于system_wq的变种还包括如下系列，_on表示指定某个CPU，_delayed表示延时工作。

```
int schedule_work_on(int cpu, struct work_struct *work)
{
    return queue_work_on(cpu, system_wq, work);
}

int schedule_delayed_work(struct delayed_work *dwork,
                    unsigned long delay)
{
    return queue_delayed_work(system_wq, dwork, delay);
}

int schedule_delayed_work_on(int cpu,
            struct delayed_work *dwork, unsigned long delay)
{
    return queue_delayed_work_on(cpu, system_wq, dwork, delay);
}
```

#### 3.3 其它系统默认workqueue

上面介绍了schedule_work()，其默认将work放入system_wq上。

系统还有其它很多默认workqueue，这些workqueue也都是通过[queue_work](https://www.cnblogs.com/arnoldlu/p/8659988.html#queue_work)()将work放入其上。

下面介绍一些其它系统全局workqueue的使用。

system_highpri_wq 和system_wq的区别在于WQ_HIGHPRI，这些work对应的工作线程位于cpu_worker_pool[1]中。工作线程的nice为-20，要比system_wq对应的工作线程优先级要高。

 system_long_wq和system_wq类似，但是一般system_long_wq用于执行时间较长的work，而system_wq放执行较短的work。

这两个workqueue没有明显的区别，更多的是靠使用者自觉。

 system_nrt_wq相对于system_wq使用了WQ_NON_REENTRANT。默认情况下工作队列只是确保在同一CPU不可重入，即工作在同一CPU上不会被多个工作线程并发执行，但容许在多个CPU上并发执行。

该标志表明在多个CPU上也是不可重入的，工作将在不可重入workqueue上，并确保至多在一个系统范围内的工作线程上执行。

 system_unbound_wq相对于system_wq的区别是被设置为WQ_UNBOUND，没有并发管理，且work最大活跃数不超过WQ_UNBOUND_MAX_ACTIVE，一般为WQ_MAX_ACTIVE=512。

system_unbound_wq对应的工作线程不会被绑定到特定CPU，所有排队的work会被立即执行，只要资源足够并且不超过最大活跃数。

 system_freezable_wq 相对于system_wq多了WQ_FREEZABLE标志，表示可以冻结workqueue参与系统的暂停操作，该workqueue的工作将被暂停，除非被唤醒，否者没有新的work被执行。

 system_power_efficient_wq相对于system_wq多了WQ_POWER_EFFICIENT标志，将工作队列表示为unbound已达到节省功耗的目的，并且还需要wq_power_efficient打开。否则和system_wq没啥区别。

 system_freezable_power_efficient_wq兼具system_freezable_wq的freezable和system_power_efficient_wq的power efficient两个特性。

### 4. 取消一个work

取消一个work的接口是cancel_work_sync()，该函数通常会取消一个work，但会等待该work执行完毕。

```
bool cancel_work_sync(struct work_struct *work)
{
    return __cancel_work_timer(work, false);
}

static bool __cancel_work_timer(struct work_struct *work, bool is_dwork)
{
    static DECLARE_WAIT_QUEUE_HEAD(cancel_waitq);---------------------等待队列cancel_waitq
    unsigned long flags;
    int ret;

​```
do {
    ret = try_to_grab_pending(work, is_dwork, &flags);------------判断当前work的状态，需要特殊处理-ENOENT情况。

    if (unlikely(ret == -ENOENT)) {
        struct cwt_wait cwait;

        init_wait(&cwait.wait);
        cwait.wait.func = cwt_wakefn;
        cwait.work = work;

        prepare_to_wait_exclusive(&cancel_waitq, &cwait.wait,
                      TASK_UNINTERRUPTIBLE);
        if (work_is_canceling(work))
            schedule();
        finish_wait(&cancel_waitq, &cwait.wait);
    }
} while (unlikely(ret < 0));

/* tell other tasks trying to grab @work to back off */
mark_work_canceling(work);
local_irq_restore(flags);

flush_work(work);-------------------------------------------------会去等待work执行完成
clear_work_data(work);--------------------------------------------清除work标志位

/*
 * Paired with prepare_to_wait() above so that either
 * waitqueue_active() is visible here or !work_is_canceling() is
 * visible there.
 */
smp_mb();
if (waitqueue_active(&cancel_waitq))
    __wake_up(&cancel_waitq, TASK_NORMAL, 1, work);

return ret;
​```

}
```

 try_to_grab_pending()判断当前的work可否被取消，返回不同状态。__cancel_work_timer()根据不同状态采取不同操作。

```
static int try_to_grab_pending(struct work_struct *work, bool is_dwork,
                   unsigned long *flags)
{
    struct worker_pool *pool;
    struct pool_workqueue *pwq;

​```
local_irq_save(*flags);-----------------------------------------------关本地中断，主要工作都在关中断下进行。

/* try to steal the timer if it exists */
if (is_dwork) {
    struct delayed_work *dwork = to_delayed_work(work);

    if (likely(del_timer(&dwork->timer)))
        return 1;
}

/* try to claim PENDING the normal way */
if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work)))----如果PENDING_BIT为0，说明该work处于idle状态，那么可以轻松的把work取出来。此处重新设置PENDING_BIT位，后续还需要等待该work执行完成。
    return 0;

/*
 * The queueing is in progress, or it is already queued. Try to
 * steal it from ->worklist without clearing WORK_STRUCT_PENDING.
 */----------------------------------------------------------------------下面的情况说明work正在被执行或者已经在worklist链表中，那么尝试去工作池中把work偷出来，成功后返回1.
pool = get_work_pool(work);
if (!pool)
    goto fail;

spin_lock(&pool->lock);

pwq = get_work_pwq(work);
if (pwq && pwq->pool == pool) {
    debug_work_deactivate(work);

    if (*work_data_bits(work) & WORK_STRUCT_DELAYED)
        pwq_activate_delayed_work(work);

    list_del_init(&work->entry);-----------------------------------------将当前work从worker_pool->worklist中移除
    pwq_dec_nr_in_flight(pwq, get_work_color(work));

    /* work->data points to pwq iff queued, point to pool */
    set_work_pool_and_keep_pending(work, pool->id);

    spin_unlock(&pool->lock);
    return 1;
}
spin_unlock(&pool->lock);
​```

fail:
    local_irq_restore(*flags);
    if (work_is_canceling(work))--------------------------通过该work->data判断该work正在被取消，返回-ENOENT。__cancel_work_timer()会睡眠等待并继续完成。
        return -ENOENT;
    cpu_relax();
    return -EAGAIN;---------------------------------------返回__cancel_work_timer()重试
}
```

 flush_work()等待work执行完成，返回false表示当前work并没有处于执行状态；返回true表示等到work执行完成。

```
bool flush_work(struct work_struct *work)
{
    struct wq_barrier barr;

​```
lock_map_acquire(&work->lockdep_map);
lock_map_release(&work->lockdep_map);

if (start_flush_work(work, &barr)) {
    wait_for_completion(&barr.done);
    destroy_work_on_stack(&barr.work);
    return true;
} else {
    return false;
}
​```

}

static bool start_flush_work(struct work_struct *work, struct wq_barrier *barr)
{
    struct worker *worker = NULL;
    struct worker_pool *pool;
    struct pool_workqueue *pwq;

​```
might_sleep();

local_irq_disable();
pool = get_work_pool(work);-----------------由work_struct找到worker_pool
if (!pool) {
    local_irq_enable();
    return false;
}

spin_lock(&pool->lock);
/* see the comment in try_to_grab_pending() with the same code */
pwq = get_work_pwq(work);-------------------由work_struct找到pool_workqueue
if (pwq) {
    if (unlikely(pwq->pool != pool))--------表示当前work已经被执行完
        goto already_gone;
} else {
    worker = find_worker_executing_work(pool, work);-----------返回正在执行work的worker，如果没有则返回NULL，表示已经被执行完毕。
    if (!worker)
        goto already_gone;
    pwq = worker->current_pwq;
}

insert_wq_barrier(pwq, barr, work, worker);
spin_unlock_irq(&pool->lock);

/*
 * If @max_active is 1 or rescuer is in use, flushing another work
 * item on the same workqueue may lead to deadlock.  Make sure the
 * flusher is not running on the same workqueue by verifying write
 * access.
 */
if (pwq->wq->saved_max_active == 1 || pwq->wq->rescuer)
    lock_map_acquire(&pwq->wq->lockdep_map);
else
    lock_map_acquire_read(&pwq->wq->lockdep_map);
lock_map_release(&pwq->wq->lockdep_map);

return true;
​```

already_gone:
    spin_unlock_irq(&pool->lock);
    return false;
}

static void insert_wq_barrier(struct pool_workqueue *pwq,
                  struct wq_barrier *barr,
                  struct work_struct *target, struct worker *worker)
{
    struct list_head *head;
    unsigned int linked = 0;

​```
/*
 * debugobject calls are safe here even with pool->lock locked
 * as we know for sure that this will not trigger any of the
 * checks and call back into the fixup functions where we
 * might deadlock.
 */
INIT_WORK_ONSTACK(&barr->work, wq_barrier_func);-----------------初始化一个新的barr->work，执行函数是wq_barrier_func，里面complete完成量barr->done。
__set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(&barr->work));
init_completion(&barr->done);------------------------------------初始化barr->done完成量

/*
 * If @target is currently being executed, schedule the
 * barrier to the worker; otherwise, put it after @target.
 */
if (worker)------------------------------------------------------当前work正在被执行，放在worker->scheduled.next之后
    head = worker->scheduled.next;
else {
    unsigned long *bits = work_data_bits(target);----------------否则放在target->entry.next

    head = target->entry.next;
    /* there can already be other linked works, inherit and set */
    linked = *bits & WORK_STRUCT_LINKED;
    __set_bit(WORK_STRUCT_LINKED_BIT, bits);
}

debug_work_activate(&barr->work);
insert_work(pwq, &barr->work, head,
        work_color_to_flags(WORK_NO_COLOR) | linked);------------将barr->work加入到head后
​```

}
```

关于PENDING_BIT何时被设置以及被清0：

- 当一个work已经加入到workqueue队列中，schedule_work()->queue_work()->queue_work_on()时被设置。
- 当一个work在工作线程里马上要执行，worker_thread()->process_on_work()->set_work_pool_and_clear_pend是清0。
- 上述设置和清0都是在关闭本地中断情况下执行的。

### 5. 和调度器的交互

假设某个work回调函数执行了睡眠操作，在wait_event_interruptible()中设置当前进程state为TASK_INTERRUPTIBLE，然后执行schedule()进行进程切换，调用轨迹是schedule()->__schedule()。

```
static void __sched __schedule(void)
{
    struct task_struct *prev, *next;
    unsigned long *switch_count;
    struct rq *rq;
    int cpu;

​```
preempt_disable();
cpu = smp_processor_id();
rq = cpu_rq(cpu);
rcu_note_context_switch();
prev = rq->curr;------------------------------------------------prev指当前进程，即执行work的工作线程，state状态为TASK_INTERRUPTIBLE。
​```

...
    if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {-------work回调函数中调度不是中断返回前抢占调度，preempt_count也没有设置PREEMPT_ACTIVE。
        if (unlikely(signal_pending_state(prev->state, prev))) {
            prev->state = TASK_RUNNING;
        } else {
            deactivate_task(rq, prev, DEQUEUE_SLEEP);
            prev->on_rq = 0;

​```
        /*
         * If a worker went to sleep, notify and ask workqueue
         * whether it wants to wake up a task to maintain
         * concurrency.
         */
        if (prev->flags & PF_WQ_WORKER) {
            struct task_struct *to_wakeup;

            to_wakeup = wq_worker_sleeping(prev, cpu);---------当一个工作线程要被调度器换出时，调用wq_worker_sleeping()看看是否需要唤醒同一个线程池中的其它内核线程。
            if (to_wakeup)
                try_to_wake_up_local(to_wakeup);---------------去唤醒to_wakeup线程
        }
    }
    switch_count = &prev->nvcsw;
}
​```

...
}
```

wq_worker_sleeping()检查当前工作线程池中是否有内核线程正准备睡眠。如果有则返回task_struct，否则返回NULL。

在wq_worker_sleeping()返回不为NULL的情况下，调用try_to_wake_up_local()。

try_to_wake_up_local()是执行唤醒进程的操作。

```
struct task_struct *wq_worker_sleeping(struct task_struct *task, int cpu)
{
    struct worker *worker = kthread_data(task), *to_wakeup = NULL;
    struct worker_pool *pool;

​```
/*
 * Rescuers, which may not have all the fields set up like normal
 * workers, also reach here, let's not access anything before
 * checking NOT_RUNNING.
 */
if (worker->flags & WORKER_NOT_RUNNING)
    return NULL;

pool = worker->pool;

/* this can only happen on the local cpu */
if (WARN_ON_ONCE(cpu != raw_smp_processor_id() || pool->cpu != cpu))
    return NULL;

/*
 * The counterpart of the following dec_and_test, implied mb,
 * worklist not empty test sequence is in insert_work().
 * Please read comment there.
 *
 * NOT_RUNNING is clear.  This means that we're bound to and
 * running on the local cpu w/ rq lock held and preemption
 * disabled, which in turn means that none else could be
 * manipulating idle_list, so dereferencing idle_list without pool
 * lock is safe.
 */
if (atomic_dec_and_test(&pool->nr_running) &&
    !list_empty(&pool->worklist))
    to_wakeup = first_idle_worker(pool);-------------------从worker_pool->idle_list中找到第一个worker工作线程。
return to_wakeup ? to_wakeup->task : NULL;
​```

}

static struct worker *first_idle_worker(struct worker_pool *pool)
{
    if (unlikely(list_empty(&pool->idle_list)))
        return NULL;

​```
return list_first_entry(&pool->idle_list, struct worker, entry);
​```

}

static void try_to_wake_up_local(struct task_struct *p)
{
    struct rq *rq = task_rq(p);

​```
if (WARN_ON_ONCE(rq != this_rq()) ||
    WARN_ON_ONCE(p == current))
    return;

lockdep_assert_held(&rq->lock);

if (!raw_spin_trylock(&p->pi_lock)) {
    raw_spin_unlock(&rq->lock);
    raw_spin_lock(&p->pi_lock);
    raw_spin_lock(&rq->lock);
}

if (!(p->state & TASK_NORMAL))
    goto out;

if (!task_on_rq_queued(p))
    ttwu_activate(rq, p, ENQUEUE_WAKEUP);

ttwu_do_wakeup(rq, p, 0);------------------------设置进程转改为TASK_RUNNING，并且调用sched_class->task_woken执行进程唤醒抢占操作。
ttwu_stat(p, smp_processor_id(), 0);
​```

out:
    raw_spin_unlock(&p->pi_lock);
}

static void ttwu_activate(struct rq *rq, struct task_struct *p, int en_flags)
{
    activate_task(rq, p, en_flags);
    p->on_rq = TASK_ON_RQ_QUEUED;

​```
/* if a worker is waking up, notify workqueue */
if (p->flags & PF_WQ_WORKER)
    wq_worker_waking_up(p, cpu_of(rq));---------------增加nr_running技术，表示有一个工作线程马上就会被唤醒。
​```

}
```

